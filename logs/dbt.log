

============================== 2022-03-21 18:08:36.288224 | 0633fd83-c442-4121-903f-83293091a0f8 ==============================
18:08:36.288224 [info ] [MainThread]: Running with dbt=1.0.3
18:08:36.289274 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:08:36.290730 [debug] [MainThread]: Tracking: tracking
18:08:36.325731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984D0B8FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984D0B8FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984D0B8C70>]}
18:08:36.365486 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
18:08:36.370285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0633fd83-c442-4121-903f-83293091a0f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984D0B5940>]}
18:08:37.218667 [debug] [MainThread]: Parsing macros\adapters.sql
18:08:37.323849 [debug] [MainThread]: Parsing macros\catalog.sql
18:08:37.323849 [debug] [MainThread]: Parsing macros\relations.sql
18:08:37.340255 [debug] [MainThread]: Parsing macros\materializations\snapshot_merge.sql
18:08:37.342300 [debug] [MainThread]: Parsing macros\adapters\columns.sql
18:08:37.344473 [debug] [MainThread]: Parsing macros\adapters\freshness.sql
18:08:37.344473 [debug] [MainThread]: Parsing macros\adapters\indexes.sql
18:08:37.344473 [debug] [MainThread]: Parsing macros\adapters\metadata.sql
18:08:37.362102 [debug] [MainThread]: Parsing macros\adapters\persist_docs.sql
18:08:37.362102 [debug] [MainThread]: Parsing macros\adapters\relation.sql
18:08:37.379264 [debug] [MainThread]: Parsing macros\adapters\schema.sql
18:08:37.381117 [debug] [MainThread]: Parsing macros\etc\datetime.sql
18:08:37.383461 [debug] [MainThread]: Parsing macros\etc\statement.sql
18:08:37.383461 [debug] [MainThread]: Parsing macros\generic_test_sql\accepted_values.sql
18:08:37.383461 [debug] [MainThread]: Parsing macros\generic_test_sql\not_null.sql
18:08:37.395926 [debug] [MainThread]: Parsing macros\generic_test_sql\relationships.sql
18:08:37.396910 [debug] [MainThread]: Parsing macros\generic_test_sql\unique.sql
18:08:37.398177 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_alias.sql
18:08:37.399159 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_database.sql
18:08:37.401618 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_schema.sql
18:08:37.403294 [debug] [MainThread]: Parsing macros\materializations\configs.sql
18:08:37.405747 [debug] [MainThread]: Parsing macros\materializations\hooks.sql
18:08:37.408243 [debug] [MainThread]: Parsing macros\materializations\models\incremental\column_helpers.sql
18:08:37.408243 [debug] [MainThread]: Parsing macros\materializations\models\incremental\incremental.sql
18:08:37.408243 [debug] [MainThread]: Parsing macros\materializations\models\incremental\is_incremental.sql
18:08:37.425522 [debug] [MainThread]: Parsing macros\materializations\models\incremental\merge.sql
18:08:37.427552 [debug] [MainThread]: Parsing macros\materializations\models\incremental\on_schema_change.sql
18:08:37.443318 [debug] [MainThread]: Parsing macros\materializations\models\table\create_table_as.sql
18:08:37.443318 [debug] [MainThread]: Parsing macros\materializations\models\table\table.sql
18:08:37.458943 [debug] [MainThread]: Parsing macros\materializations\models\view\create_or_replace_view.sql
18:08:37.458943 [debug] [MainThread]: Parsing macros\materializations\models\view\create_view_as.sql
18:08:37.458943 [debug] [MainThread]: Parsing macros\materializations\models\view\helpers.sql
18:08:37.458943 [debug] [MainThread]: Parsing macros\materializations\models\view\view.sql
18:08:37.467164 [debug] [MainThread]: Parsing macros\materializations\seeds\helpers.sql
18:08:37.482878 [debug] [MainThread]: Parsing macros\materializations\seeds\seed.sql
18:08:37.482878 [debug] [MainThread]: Parsing macros\materializations\snapshots\helpers.sql
18:08:37.498500 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot.sql
18:08:37.498500 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot_merge.sql
18:08:37.514882 [debug] [MainThread]: Parsing macros\materializations\snapshots\strategies.sql
18:08:37.531154 [debug] [MainThread]: Parsing macros\materializations\tests\helpers.sql
18:08:37.535788 [debug] [MainThread]: Parsing macros\materializations\tests\test.sql
18:08:37.542330 [debug] [MainThread]: Parsing macros\materializations\tests\where_subquery.sql
18:08:37.544332 [debug] [MainThread]: Parsing tests\generic\builtin.sql
18:08:37.769255 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
18:08:37.795988 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
18:08:37.825439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0633fd83-c442-4121-903f-83293091a0f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984CC71040>]}
18:08:37.906491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0633fd83-c442-4121-903f-83293091a0f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984CC71820>]}
18:08:37.908970 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:08:37.916176 [info ] [MainThread]: 
18:08:37.921044 [debug] [MainThread]: Acquiring new postgres connection "master"
18:08:37.927564 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:08:37.954808 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:08:37.955883 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:08:37.955883 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:08:38.022442 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.07 seconds
18:08:38.023439 [debug] [ThreadPool]: On list_recon-cortex: Close
18:08:38.029227 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:08:38.038510 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:08:38.046556 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:08:38.047813 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:08:38.110798 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
18:08:38.110798 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:08:38.111798 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:08:38.124847 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
18:08:38.127265 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:08:38.137533 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:08:38.154494 [debug] [MainThread]: Using postgres connection "master"
18:08:38.157597 [debug] [MainThread]: On master: BEGIN
18:08:38.158674 [debug] [MainThread]: Opening a new connection, currently in state init
18:08:38.206076 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
18:08:38.206076 [debug] [MainThread]: Using postgres connection "master"
18:08:38.207073 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:08:39.276507 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
18:08:39.286888 [debug] [MainThread]: On master: ROLLBACK
18:08:39.294235 [debug] [MainThread]: Using postgres connection "master"
18:08:39.295874 [debug] [MainThread]: On master: BEGIN
18:08:39.307917 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
18:08:39.309652 [debug] [MainThread]: On master: COMMIT
18:08:39.310896 [debug] [MainThread]: Using postgres connection "master"
18:08:39.312324 [debug] [MainThread]: On master: COMMIT
18:08:39.318802 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:08:39.320798 [debug] [MainThread]: On master: Close
18:08:39.324488 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:08:39.328447 [info ] [MainThread]: 
18:08:39.454598 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:08:39.455596 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:08:39.456600 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.457598 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:08:39.458596 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:08:39.472289 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:08:39.474345 [debug] [Thread-1  ]: finished collecting timing info
18:08:39.475346 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:08:39.579816 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.581025 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp233839552785"
  as (
    


with source_data as (

    select s.* from set2_hdfc_auto s 

),

filter_debit_source_data as (
    select s.*,  split_part(s."txt_txn_desc" , '-', 1)  as ref_agr1,
    split_part(s."txt_txn_desc" , '-',2)  as ref_agr2,
    split_part(s."txt_txn_desc" , '-', 3) as ref_agr3 from source_data s where s.cod_drcr = 'D'
),

filter_credit_source_data as (
    select s.*,  split_part(s."txt_txn_desc" , '-', 1)  as ref_agr1,
    split_part(s."txt_txn_desc" , '-',2)  as ref_agr2,
    split_part(s."txt_txn_desc" , '-', 3) as ref_agr3 from source_data s where s.cod_drcr = 'C'
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3 from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3 from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3 from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3 from filter_debit_matched_data fdm
)


select
    221 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    221 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    221 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    221 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:08:39.582033 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:08:39.639922 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.06 seconds
18:08:39.649921 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.650917 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
18:08:39.659118 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
18:08:39.659118 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.660123 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp233839552785'
        
      order by ordinal_position

  
18:08:39.714050 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.05 seconds
18:08:39.738914 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.743785 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
18:08:39.767354 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.02 seconds
18:08:39.806598 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.808165 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
18:08:39.819640 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
18:08:39.859398 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
18:08:39.871735 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.873738 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp233839552785"
    )
  
18:08:39.882487 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
18:08:39.915171 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
18:08:39.918761 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.919763 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
18:08:39.926268 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
18:08:39.927269 [debug] [Thread-1  ]: finished collecting timing info
18:08:39.927875 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:08:39.928892 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0633fd83-c442-4121-903f-83293091a0f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984CFBAD90>]}
18:08:39.930399 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.47s]
18:08:39.932398 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:08:39.934398 [debug] [MainThread]: Acquiring new postgres connection "master"
18:08:39.935399 [debug] [MainThread]: Using postgres connection "master"
18:08:39.935399 [debug] [MainThread]: On master: BEGIN
18:08:39.936399 [debug] [MainThread]: Opening a new connection, currently in state closed
18:08:40.018085 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
18:08:40.020094 [debug] [MainThread]: On master: COMMIT
18:08:40.021091 [debug] [MainThread]: Using postgres connection "master"
18:08:40.023154 [debug] [MainThread]: On master: COMMIT
18:08:40.030884 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
18:08:40.032129 [debug] [MainThread]: On master: Close
18:08:40.037231 [info ] [MainThread]: 
18:08:40.040838 [info ] [MainThread]: Finished running 1 incremental model in 2.12s.
18:08:40.042767 [debug] [MainThread]: Connection 'master' was properly closed.
18:08:40.044768 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:08:40.046078 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:08:40.046078 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:08:40.062182 [info ] [MainThread]: 
18:08:40.064182 [info ] [MainThread]: [32mCompleted successfully[0m
18:08:40.069522 [info ] [MainThread]: 
18:08:40.075039 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
18:08:40.078040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984E1D89D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984CFBA400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984E1F09A0>]}


============================== 2022-03-22 05:35:25.934080 | 678e94be-02c0-4dae-a098-9077f08e0daa ==============================
05:35:25.934080 [info ] [MainThread]: Running with dbt=1.0.3
05:35:25.944203 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
05:35:25.944203 [debug] [MainThread]: Tracking: tracking
05:35:26.029877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F2BC7C70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F2BC7FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F2BC70D0>]}
05:35:26.123066 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
05:35:26.123066 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
05:35:26.127496 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
05:35:26.138277 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
05:35:26.163897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '678e94be-02c0-4dae-a098-9077f08e0daa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F3CEB0D0>]}
05:35:26.170490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '678e94be-02c0-4dae-a098-9077f08e0daa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F3C23A30>]}
05:35:26.171490 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
05:35:26.173921 [info ] [MainThread]: 
05:35:26.174601 [debug] [MainThread]: Acquiring new postgres connection "master"
05:35:26.176605 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
05:35:26.183304 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
05:35:26.183304 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
05:35:26.188058 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:35:26.266760 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.08 seconds
05:35:26.268794 [debug] [ThreadPool]: On list_recon-cortex: Close
05:35:26.270794 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
05:35:26.278837 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:35:26.279154 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
05:35:26.279154 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:35:26.352791 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
05:35:26.352791 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:35:26.353836 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
05:35:26.363877 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
05:35:26.369269 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
05:35:26.374141 [debug] [ThreadPool]: On list_recon-cortex_public: Close
05:35:26.387172 [debug] [MainThread]: Using postgres connection "master"
05:35:26.388981 [debug] [MainThread]: On master: BEGIN
05:35:26.389171 [debug] [MainThread]: Opening a new connection, currently in state init
05:35:26.463503 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
05:35:26.468510 [debug] [MainThread]: Using postgres connection "master"
05:35:26.469632 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
05:35:27.525285 [debug] [MainThread]: SQL status: SELECT 0 in 1.06 seconds
05:35:27.539210 [debug] [MainThread]: On master: ROLLBACK
05:35:27.544173 [debug] [MainThread]: Using postgres connection "master"
05:35:27.544173 [debug] [MainThread]: On master: BEGIN
05:35:27.550645 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
05:35:27.552574 [debug] [MainThread]: On master: COMMIT
05:35:27.552574 [debug] [MainThread]: Using postgres connection "master"
05:35:27.553573 [debug] [MainThread]: On master: COMMIT
05:35:27.560271 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
05:35:27.561225 [debug] [MainThread]: On master: Close
05:35:27.562421 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
05:35:27.563426 [info ] [MainThread]: 
05:35:27.574611 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
05:35:27.575608 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
05:35:27.579961 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
05:35:27.581213 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
05:35:27.583607 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
05:35:27.597643 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
05:35:27.599605 [debug] [Thread-1  ]: finished collecting timing info
05:35:27.600613 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
05:35:27.718134 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:35:27.718134 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp110527693933"
  as (
    


with source_data as (

    select s.* from set2_hdfc_auto s 

),

filter_data_source_1 as (
    select s.*, right(s."txt_txn_desc", 22) as rtgs_utr_no from source_data s where s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),

filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_data_source_2 filter_data_source_2
     where fds1.amt_txn = fds2.disb_amt_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1, filter_data_source_2 filter_data_source_2
     where fds1.amt_txn = fds2.disb_amt_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_datasrc1_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.rtgs_utr_no from filter_data_source_1 fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.rtgs_utr_no from filter_matched_data_source_1 fcm
),
filter_datasrc2_unmatched_data as (
    select fds.utr,
        fds.app_id_c,
        fds.las_edit_d,
        fds.disb_amt_n,
        fds.disb_msg_gen_date from filter_data_source_2 fds 
    except select 
        fdm.utr,
        fdm.app_id_c,
        fdm.las_edit_d,
        fdm.disb_amt_n,
        fdm.disb_msg_gen_date from filter_matched_data_source_2 fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc1_unmatched_data
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amt_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc2_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amt_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
05:35:27.719136 [debug] [Thread-1  ]: Opening a new connection, currently in state init
05:35:27.824193 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "rtgs_utr_no"
LINE 186:     rtgs_utr_no as column13,
              ^

05:35:27.826728 [debug] [Thread-1  ]: finished collecting timing info
05:35:27.826728 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
05:35:27.828661 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  syntax error at or near "rtgs_utr_no"
  LINE 186:     rtgs_utr_no as column13,
                ^
05:35:27.828661 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '678e94be-02c0-4dae-a098-9077f08e0daa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F3C1A8B0>]}
05:35:27.829664 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.25s]
05:35:27.830257 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
05:35:27.832256 [debug] [MainThread]: Acquiring new postgres connection "master"
05:35:27.833259 [debug] [MainThread]: Using postgres connection "master"
05:35:27.834258 [debug] [MainThread]: On master: BEGIN
05:35:27.835261 [debug] [MainThread]: Opening a new connection, currently in state closed
05:35:27.911624 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
05:35:27.912371 [debug] [MainThread]: On master: COMMIT
05:35:27.912371 [debug] [MainThread]: Using postgres connection "master"
05:35:27.913256 [debug] [MainThread]: On master: COMMIT
05:35:27.917269 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
05:35:27.918011 [debug] [MainThread]: On master: Close
05:35:27.919259 [info ] [MainThread]: 
05:35:27.920414 [info ] [MainThread]: Finished running 1 incremental model in 1.74s.
05:35:27.921258 [debug] [MainThread]: Connection 'master' was properly closed.
05:35:27.922262 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
05:35:27.922262 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
05:35:27.923256 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
05:35:27.929257 [info ] [MainThread]: 
05:35:27.930263 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
05:35:27.934266 [info ] [MainThread]: 
05:35:27.937280 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
05:35:27.939258 [error] [MainThread]:   syntax error at or near "rtgs_utr_no"
05:35:27.940257 [error] [MainThread]:   LINE 186:     rtgs_utr_no as column13,
05:35:27.941259 [error] [MainThread]:                 ^
05:35:27.943313 [info ] [MainThread]: 
05:35:27.945259 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
05:35:27.946256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F3D51A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F3D49AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F3BA2C70>]}


============================== 2022-03-22 05:35:57.177189 | fe95a23f-0db9-4988-974b-224e4549c2f8 ==============================
05:35:57.177189 [info ] [MainThread]: Running with dbt=1.0.3
05:35:57.193162 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
05:35:57.194163 [debug] [MainThread]: Tracking: tracking
05:35:57.284010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB676884F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB67688FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB67688C70>]}
05:35:57.331298 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
05:35:57.338746 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
05:35:57.339748 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
05:35:57.350392 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
05:35:57.376413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fe95a23f-0db9-4988-974b-224e4549c2f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB687AB0D0>]}
05:35:57.383589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fe95a23f-0db9-4988-974b-224e4549c2f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB686E39A0>]}
05:35:57.383589 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
05:35:57.386407 [info ] [MainThread]: 
05:35:57.387606 [debug] [MainThread]: Acquiring new postgres connection "master"
05:35:57.389589 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
05:35:57.406588 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
05:35:57.407785 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
05:35:57.407785 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:35:57.478182 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.07 seconds
05:35:57.479895 [debug] [ThreadPool]: On list_recon-cortex: Close
05:35:57.481898 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
05:35:57.489002 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:35:57.490214 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
05:35:57.490214 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:35:57.548017 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
05:35:57.548656 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:35:57.549020 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
05:35:57.552272 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.0 seconds
05:35:57.563396 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
05:35:57.569154 [debug] [ThreadPool]: On list_recon-cortex_public: Close
05:35:57.584726 [debug] [MainThread]: Using postgres connection "master"
05:35:57.585726 [debug] [MainThread]: On master: BEGIN
05:35:57.586765 [debug] [MainThread]: Opening a new connection, currently in state init
05:35:57.703026 [debug] [MainThread]: SQL status: BEGIN in 0.12 seconds
05:35:57.704914 [debug] [MainThread]: Using postgres connection "master"
05:35:57.706288 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
05:35:58.767496 [debug] [MainThread]: SQL status: SELECT 0 in 1.06 seconds
05:35:58.775574 [debug] [MainThread]: On master: ROLLBACK
05:35:58.781156 [debug] [MainThread]: Using postgres connection "master"
05:35:58.787360 [debug] [MainThread]: On master: BEGIN
05:35:58.800138 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
05:35:58.801658 [debug] [MainThread]: On master: COMMIT
05:35:58.802656 [debug] [MainThread]: Using postgres connection "master"
05:35:58.804059 [debug] [MainThread]: On master: COMMIT
05:35:58.811303 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
05:35:58.811820 [debug] [MainThread]: On master: Close
05:35:58.813818 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
05:35:58.815423 [info ] [MainThread]: 
05:35:58.828253 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
05:35:58.829253 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
05:35:58.833425 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
05:35:58.835251 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
05:35:58.835251 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
05:35:58.847251 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
05:35:58.850491 [debug] [Thread-1  ]: finished collecting timing info
05:35:58.851259 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
05:35:58.963039 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:35:58.964199 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp110558942259"
  as (
    


with source_data as (

    select s.* from set2_hdfc_auto s 

),

filter_data_source_1 as (
    select s.*, right(s."txt_txn_desc", 22) as rtgs_utr_no from source_data s where s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),

filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_data_source_2 filter_data_source_2
     where fds1.amt_txn = fds2.disb_amt_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1, filter_data_source_2 filter_data_source_2
     where fds1.amt_txn = fds2.disb_amt_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_datasrc1_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.rtgs_utr_no from filter_data_source_1 fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.rtgs_utr_no from filter_matched_data_source_1 fcm
),
filter_datasrc2_unmatched_data as (
    select fds.utr,
        fds.app_id_c,
        fds.las_edit_d,
        fds.disb_amt_n,
        fds.disb_msg_gen_date from filter_data_source_2 fds 
    except select 
        fdm.utr,
        fdm.app_id_c,
        fdm.las_edit_d,
        fdm.disb_amt_n,
        fdm.disb_msg_gen_date from filter_matched_data_source_2 fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc1_unmatched_data
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amt_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc2_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amt_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
05:35:58.964199 [debug] [Thread-1  ]: Opening a new connection, currently in state init
05:35:59.034447 [debug] [Thread-1  ]: Postgres adapter: Postgres error: missing FROM-clause entry for table "fds2"
LINE 24:     select fds1.*, fds2.app_id_c as agreement_no from filter...
                            ^

05:35:59.034447 [debug] [Thread-1  ]: finished collecting timing info
05:35:59.035472 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
05:35:59.036623 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  missing FROM-clause entry for table "fds2"
  LINE 24:     select fds1.*, fds2.app_id_c as agreement_no from filter...
                              ^
05:35:59.037442 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fe95a23f-0db9-4988-974b-224e4549c2f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB67572100>]}
05:35:59.038444 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.21s]
05:35:59.040467 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
05:35:59.043448 [debug] [MainThread]: Acquiring new postgres connection "master"
05:35:59.044445 [debug] [MainThread]: Using postgres connection "master"
05:35:59.044445 [debug] [MainThread]: On master: BEGIN
05:35:59.045471 [debug] [MainThread]: Opening a new connection, currently in state closed
05:35:59.147450 [debug] [MainThread]: SQL status: BEGIN in 0.1 seconds
05:35:59.149452 [debug] [MainThread]: On master: COMMIT
05:35:59.150537 [debug] [MainThread]: Using postgres connection "master"
05:35:59.151503 [debug] [MainThread]: On master: COMMIT
05:35:59.159471 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
05:35:59.161466 [debug] [MainThread]: On master: Close
05:35:59.164468 [info ] [MainThread]: 
05:35:59.169574 [info ] [MainThread]: Finished running 1 incremental model in 1.78s.
05:35:59.173472 [debug] [MainThread]: Connection 'master' was properly closed.
05:35:59.174620 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
05:35:59.176463 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
05:35:59.177554 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
05:35:59.192449 [info ] [MainThread]: 
05:35:59.195454 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
05:35:59.199455 [info ] [MainThread]: 
05:35:59.201807 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
05:35:59.204457 [error] [MainThread]:   missing FROM-clause entry for table "fds2"
05:35:59.207264 [error] [MainThread]:   LINE 24:     select fds1.*, fds2.app_id_c as agreement_no from filter...
05:35:59.208447 [error] [MainThread]:                               ^
05:35:59.210446 [info ] [MainThread]: 
05:35:59.212444 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
05:35:59.215085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB68810A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB68808AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB68806400>]}


============================== 2022-03-22 05:37:38.679382 | 63386267-4680-465e-baf3-3b109d94481d ==============================
05:37:38.679382 [info ] [MainThread]: Running with dbt=1.0.3
05:37:38.690402 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
05:37:38.690402 [debug] [MainThread]: Tracking: tracking
05:37:38.719473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210C99E7520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210C99E7FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210C99E70D0>]}
05:37:38.854019 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
05:37:38.861125 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
05:37:38.863144 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
05:37:38.873695 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
05:37:38.898666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '63386267-4680-465e-baf3-3b109d94481d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210CAB0B0D0>]}
05:37:38.906628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '63386267-4680-465e-baf3-3b109d94481d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210CAA479A0>]}
05:37:38.906628 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
05:37:38.909110 [info ] [MainThread]: 
05:37:38.910451 [debug] [MainThread]: Acquiring new postgres connection "master"
05:37:38.912115 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
05:37:38.927109 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
05:37:38.928598 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
05:37:38.929139 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:37:38.998354 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.07 seconds
05:37:39.000101 [debug] [ThreadPool]: On list_recon-cortex: Close
05:37:39.002068 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
05:37:39.009098 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:37:39.010065 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
05:37:39.010065 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:37:39.091799 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
05:37:39.095977 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:37:39.096980 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
05:37:39.107284 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
05:37:39.110078 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
05:37:39.150751 [debug] [ThreadPool]: On list_recon-cortex_public: Close
05:37:39.165008 [debug] [MainThread]: Using postgres connection "master"
05:37:39.173012 [debug] [MainThread]: On master: BEGIN
05:37:39.174025 [debug] [MainThread]: Opening a new connection, currently in state init
05:37:39.257608 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
05:37:39.258642 [debug] [MainThread]: Using postgres connection "master"
05:37:39.258642 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
05:37:40.330199 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
05:37:40.333111 [debug] [MainThread]: On master: ROLLBACK
05:37:40.337734 [debug] [MainThread]: Using postgres connection "master"
05:37:40.341865 [debug] [MainThread]: On master: BEGIN
05:37:40.350884 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
05:37:40.351960 [debug] [MainThread]: On master: COMMIT
05:37:40.352879 [debug] [MainThread]: Using postgres connection "master"
05:37:40.352879 [debug] [MainThread]: On master: COMMIT
05:37:40.357860 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
05:37:40.359588 [debug] [MainThread]: On master: Close
05:37:40.362593 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
05:37:40.363579 [info ] [MainThread]: 
05:37:40.374584 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
05:37:40.376582 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
05:37:40.383582 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
05:37:40.385582 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
05:37:40.386585 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
05:37:40.397578 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
05:37:40.398714 [debug] [Thread-1  ]: finished collecting timing info
05:37:40.399582 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
05:37:40.516916 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:37:40.516916 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp110740493854"
  as (
    


with source_data as (

    select s.* from set2_hdfc_auto s 

),

filter_data_source_1 as (
    select s.*, right(s."txt_txn_desc", 22) as rtgs_utr_no from source_data s where s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),

filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_data_source_2 fds2
     where fds1.amt_txn = fds2.disb_amt_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1, filter_data_source_2 fds2
     where fds1.amt_txn = fds2.disb_amt_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_datasrc1_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.rtgs_utr_no from filter_data_source_1 fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.rtgs_utr_no from filter_matched_data_source_1 fcm
),
filter_datasrc2_unmatched_data as (
    select fds.utr,
        fds.app_id_c,
        fds.las_edit_d,
        fds.disb_amt_n,
        fds.disb_msg_gen_date from filter_data_source_2 fds 
    except select 
        fdm.utr,
        fdm.app_id_c,
        fdm.las_edit_d,
        fdm.disb_amt_n,
        fdm.disb_msg_gen_date from filter_matched_data_source_2 fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc1_unmatched_data
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amt_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc2_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amt_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
05:37:40.517912 [debug] [Thread-1  ]: Opening a new connection, currently in state init
05:37:40.578521 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column fds2.disb_amt_n does not exist
LINE 25:      where fds1.amt_txn = fds2.disb_amt_n
                                   ^
HINT:  Perhaps you meant to reference the column "fds2.disb_amount_n".

05:37:40.579517 [debug] [Thread-1  ]: finished collecting timing info
05:37:40.580519 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
05:37:40.582515 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  column fds2.disb_amt_n does not exist
  LINE 25:      where fds1.amt_txn = fds2.disb_amt_n
                                     ^
  HINT:  Perhaps you meant to reference the column "fds2.disb_amount_n".
05:37:40.583516 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '63386267-4680-465e-baf3-3b109d94481d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210CAA247F0>]}
05:37:40.584517 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.20s]
05:37:40.586514 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
05:37:40.589521 [debug] [MainThread]: Acquiring new postgres connection "master"
05:37:40.589521 [debug] [MainThread]: Using postgres connection "master"
05:37:40.590818 [debug] [MainThread]: On master: BEGIN
05:37:40.591519 [debug] [MainThread]: Opening a new connection, currently in state closed
05:37:40.636792 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
05:37:40.638522 [debug] [MainThread]: On master: COMMIT
05:37:40.638522 [debug] [MainThread]: Using postgres connection "master"
05:37:40.639528 [debug] [MainThread]: On master: COMMIT
05:37:40.644513 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
05:37:40.644513 [debug] [MainThread]: On master: Close
05:37:40.646515 [info ] [MainThread]: 
05:37:40.647514 [info ] [MainThread]: Finished running 1 incremental model in 1.74s.
05:37:40.648515 [debug] [MainThread]: Connection 'master' was properly closed.
05:37:40.648515 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
05:37:40.649515 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
05:37:40.649515 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
05:37:40.660516 [info ] [MainThread]: 
05:37:40.661518 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
05:37:40.664517 [info ] [MainThread]: 
05:37:40.666526 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
05:37:40.670517 [error] [MainThread]:   column fds2.disb_amt_n does not exist
05:37:40.673882 [error] [MainThread]:   LINE 25:      where fds1.amt_txn = fds2.disb_amt_n
05:37:40.675518 [error] [MainThread]:                                      ^
05:37:40.676515 [error] [MainThread]:   HINT:  Perhaps you meant to reference the column "fds2.disb_amount_n".
05:37:40.677515 [info ] [MainThread]: 
05:37:40.678516 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
05:37:40.679514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210CAB71A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210CAB69AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210CAB66E50>]}


============================== 2022-03-22 05:39:42.565931 | eb5b70c7-f911-4f63-b2a8-735997b047ae ==============================
05:39:42.565931 [info ] [MainThread]: Running with dbt=1.0.3
05:39:42.576413 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
05:39:42.576413 [debug] [MainThread]: Tracking: tracking
05:39:42.657776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF301F9A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF312B7C40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF312B7700>]}
05:39:42.706816 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
05:39:42.714530 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
05:39:42.716532 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
05:39:42.726991 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
05:39:42.750438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eb5b70c7-f911-4f63-b2a8-735997b047ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF3140B0D0>]}
05:39:42.759755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eb5b70c7-f911-4f63-b2a8-735997b047ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF31343A30>]}
05:39:42.761082 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
05:39:42.762737 [info ] [MainThread]: 
05:39:42.764749 [debug] [MainThread]: Acquiring new postgres connection "master"
05:39:42.766732 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
05:39:42.783734 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
05:39:42.783734 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
05:39:42.784737 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:39:42.847878 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.06 seconds
05:39:42.849765 [debug] [ThreadPool]: On list_recon-cortex: Close
05:39:42.852731 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
05:39:42.861727 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:39:42.861727 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
05:39:42.862730 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:39:42.924664 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
05:39:42.925828 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:39:42.925828 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
05:39:43.166684 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.24 seconds
05:39:43.169693 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
05:39:43.177155 [debug] [ThreadPool]: On list_recon-cortex_public: Close
05:39:43.185703 [debug] [MainThread]: Using postgres connection "master"
05:39:43.196051 [debug] [MainThread]: On master: BEGIN
05:39:43.197052 [debug] [MainThread]: Opening a new connection, currently in state init
05:39:43.287078 [debug] [MainThread]: SQL status: BEGIN in 0.09 seconds
05:39:43.289074 [debug] [MainThread]: Using postgres connection "master"
05:39:43.290213 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
05:39:44.356390 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
05:39:44.364810 [debug] [MainThread]: On master: ROLLBACK
05:39:44.389597 [debug] [MainThread]: Using postgres connection "master"
05:39:44.393738 [debug] [MainThread]: On master: BEGIN
05:39:44.400178 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
05:39:44.402652 [debug] [MainThread]: On master: COMMIT
05:39:44.402652 [debug] [MainThread]: Using postgres connection "master"
05:39:44.402652 [debug] [MainThread]: On master: COMMIT
05:39:44.407195 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
05:39:44.407195 [debug] [MainThread]: On master: Close
05:39:44.408195 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
05:39:44.409215 [info ] [MainThread]: 
05:39:44.420194 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
05:39:44.420194 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
05:39:44.423762 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
05:39:44.424991 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
05:39:44.426236 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
05:39:44.447251 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
05:39:44.449205 [debug] [Thread-1  ]: finished collecting timing info
05:39:44.449746 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
05:39:44.583061 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:39:44.583061 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp110944551478"
  as (
    


with source_data as (

    select s.* from set2_hdfc_auto s 

),

filter_data_source_1 as (
    select s.*, right(s."txt_txn_desc", 22) as rtgs_utr_no from source_data s where s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),

filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_data_source_2 fds2
     where fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1, filter_data_source_2 fds2
     where fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_datasrc1_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.rtgs_utr_no from filter_data_source_1 fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.rtgs_utr_no from filter_matched_data_source_1 fcm
),
filter_datasrc2_unmatched_data as (
    select fds.utr,
        fds.app_id_c,
        fds.las_edit_d,
        fds.disb_amount_n,
        fds.disb_msg_gen_date from filter_data_source_2 fds 
    except select 
        fdm.utr,
        fdm.app_id_c,
        fdm.las_edit_d,
        fdm.disb_amount_n,
        fdm.disb_msg_gen_date from filter_matched_data_source_2 fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc1_unmatched_data
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc2_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
05:39:44.584106 [debug] [Thread-1  ]: Opening a new connection, currently in state init
05:39:44.632749 [debug] [Thread-1  ]: Postgres adapter: Postgres error: UNION types double precision and character varying cannot be matched
LINE 127:     utr as column1,
              ^

05:39:44.632749 [debug] [Thread-1  ]: finished collecting timing info
05:39:44.633747 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
05:39:44.634745 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  UNION types double precision and character varying cannot be matched
  LINE 127:     utr as column1,
                ^
05:39:44.634745 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eb5b70c7-f911-4f63-b2a8-735997b047ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF3133A760>]}
05:39:44.635746 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.21s]
05:39:44.637511 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
05:39:44.639513 [debug] [MainThread]: Acquiring new postgres connection "master"
05:39:44.641127 [debug] [MainThread]: Using postgres connection "master"
05:39:44.641514 [debug] [MainThread]: On master: BEGIN
05:39:44.642512 [debug] [MainThread]: Opening a new connection, currently in state closed
05:39:44.699593 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
05:39:44.701699 [debug] [MainThread]: On master: COMMIT
05:39:44.702964 [debug] [MainThread]: Using postgres connection "master"
05:39:44.704590 [debug] [MainThread]: On master: COMMIT
05:39:44.711700 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
05:39:44.713591 [debug] [MainThread]: On master: Close
05:39:44.715586 [info ] [MainThread]: 
05:39:44.716765 [info ] [MainThread]: Finished running 1 incremental model in 1.95s.
05:39:44.718589 [debug] [MainThread]: Connection 'master' was properly closed.
05:39:44.719585 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
05:39:44.720590 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
05:39:44.721587 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
05:39:44.736609 [info ] [MainThread]: 
05:39:44.737586 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
05:39:44.740586 [info ] [MainThread]: 
05:39:44.741587 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
05:39:44.747597 [error] [MainThread]:   UNION types double precision and character varying cannot be matched
05:39:44.749743 [error] [MainThread]:   LINE 127:     utr as column1,
05:39:44.751591 [error] [MainThread]:                 ^
05:39:44.753587 [info ] [MainThread]: 
05:39:44.755587 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
05:39:44.756586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF3138CE80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF31343520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF31466B20>]}


============================== 2022-03-22 05:44:14.971699 | ad1d0260-74ad-4802-a4c0-96d6ffe63b18 ==============================
05:44:14.971699 [info ] [MainThread]: Running with dbt=1.0.3
05:44:14.980308 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
05:44:14.980308 [debug] [MainThread]: Tracking: tracking
05:44:15.018309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46AA59A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46AB48C40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46AB48700>]}
05:44:15.073384 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
05:44:15.077533 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
05:44:15.078537 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
05:44:15.090668 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
05:44:15.119162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ad1d0260-74ad-4802-a4c0-96d6ffe63b18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46BC6B0D0>]}
05:44:15.126681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ad1d0260-74ad-4802-a4c0-96d6ffe63b18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46BBA3A30>]}
05:44:15.126681 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
05:44:15.129376 [info ] [MainThread]: 
05:44:15.130422 [debug] [MainThread]: Acquiring new postgres connection "master"
05:44:15.132734 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
05:44:15.147769 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
05:44:15.148858 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
05:44:15.148858 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:44:15.240441 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.09 seconds
05:44:15.246251 [debug] [ThreadPool]: On list_recon-cortex: Close
05:44:15.249651 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
05:44:15.259845 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:44:15.261747 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
05:44:15.261747 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:44:15.353921 [debug] [ThreadPool]: SQL status: BEGIN in 0.09 seconds
05:44:15.361140 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:44:15.363148 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
05:44:15.372136 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
05:44:15.378139 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
05:44:15.383361 [debug] [ThreadPool]: On list_recon-cortex_public: Close
05:44:15.390393 [debug] [MainThread]: Using postgres connection "master"
05:44:15.394317 [debug] [MainThread]: On master: BEGIN
05:44:15.394317 [debug] [MainThread]: Opening a new connection, currently in state init
05:44:15.468779 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
05:44:15.470374 [debug] [MainThread]: Using postgres connection "master"
05:44:15.471370 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
05:44:16.525784 [debug] [MainThread]: SQL status: SELECT 0 in 1.05 seconds
05:44:16.544080 [debug] [MainThread]: On master: ROLLBACK
05:44:16.549628 [debug] [MainThread]: Using postgres connection "master"
05:44:16.549628 [debug] [MainThread]: On master: BEGIN
05:44:16.563170 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
05:44:16.563170 [debug] [MainThread]: On master: COMMIT
05:44:16.563170 [debug] [MainThread]: Using postgres connection "master"
05:44:16.564170 [debug] [MainThread]: On master: COMMIT
05:44:16.569069 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
05:44:16.570069 [debug] [MainThread]: On master: Close
05:44:16.571069 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
05:44:16.571069 [info ] [MainThread]: 
05:44:16.580658 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
05:44:16.581647 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
05:44:16.584659 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.586756 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
05:44:16.588719 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
05:44:16.598679 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
05:44:16.599688 [debug] [Thread-1  ]: finished collecting timing info
05:44:16.600648 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
05:44:16.726917 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.726917 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp111416705815"
  as (
    


with source_data as (

    select s.* from set2_hdfc_auto s 

),

filter_data_source_1 as (
    select s.*, right(s."txt_txn_desc", 22) as rtgs_utr_no from source_data s where s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),

filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_data_source_2 fds2
     where fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1, filter_data_source_2 fds2
     where fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_datasrc1_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.rtgs_utr_no from filter_data_source_1 fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.rtgs_utr_no from filter_matched_data_source_1 fcm
),
filter_datasrc2_unmatched_data as (
    select fds.utr,
        fds.app_id_c,
        fds.las_edit_d,
        fds.disb_amount_n,
        fds.disb_msg_gen_date from filter_data_source_2 fds 
    except select 
        fdm.utr,
        fdm.app_id_c,
        fdm.las_edit_d,
        fdm.disb_amount_n,
        fdm.disb_msg_gen_date from filter_matched_data_source_2 fdm
)


select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc1_unmatched_data
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc2_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
05:44:16.727894 [debug] [Thread-1  ]: Opening a new connection, currently in state init
05:44:16.826381 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.1 seconds
05:44:16.830993 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.840454 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
05:44:16.842650 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
05:44:16.849137 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.849137 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp111416705815'
        
      order by ordinal_position

  
05:44:16.870567 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.02 seconds
05:44:16.879567 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.880661 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
05:44:16.891362 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
05:44:16.903921 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.905103 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
05:44:16.914100 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
05:44:16.929775 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
05:44:16.931544 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.931544 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp111416705815"
    )
  
05:44:16.938256 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
05:44:16.940260 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
05:44:16.940260 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.948507 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
05:44:16.949774 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
05:44:16.956109 [debug] [Thread-1  ]: finished collecting timing info
05:44:16.956556 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
05:44:16.957575 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad1d0260-74ad-4802-a4c0-96d6ffe63b18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46BCC6A90>]}
05:44:16.958119 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.37s]
05:44:16.959554 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
05:44:16.961557 [debug] [MainThread]: Acquiring new postgres connection "master"
05:44:16.962570 [debug] [MainThread]: Using postgres connection "master"
05:44:16.962570 [debug] [MainThread]: On master: BEGIN
05:44:16.963556 [debug] [MainThread]: Opening a new connection, currently in state closed
05:44:17.024899 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
05:44:17.027133 [debug] [MainThread]: On master: COMMIT
05:44:17.027881 [debug] [MainThread]: Using postgres connection "master"
05:44:17.027987 [debug] [MainThread]: On master: COMMIT
05:44:17.032199 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
05:44:17.033156 [debug] [MainThread]: On master: Close
05:44:17.033215 [info ] [MainThread]: 
05:44:17.035211 [info ] [MainThread]: Finished running 1 incremental model in 1.90s.
05:44:17.036213 [debug] [MainThread]: Connection 'master' was properly closed.
05:44:17.037212 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
05:44:17.038459 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
05:44:17.039213 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
05:44:17.047403 [info ] [MainThread]: 
05:44:17.049221 [info ] [MainThread]: [32mCompleted successfully[0m
05:44:17.053219 [info ] [MainThread]: 
05:44:17.054214 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
05:44:17.056213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46BBA3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46BBEDA00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46A433AF0>]}


============================== 2022-03-22 08:30:43.747813 | 8e4cc3d8-313e-4997-8736-989a4a5eded8 ==============================
08:30:43.747813 [info ] [MainThread]: Running with dbt=1.0.3
08:30:43.790868 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:30:43.790868 [debug] [MainThread]: Tracking: tracking
08:30:43.904562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002566EF68FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002566EF68FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002566EF688E0>]}
08:30:43.954116 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:30:43.954116 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
08:30:43.967268 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
08:30:43.980926 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
08:30:44.000402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8e4cc3d8-313e-4997-8736-989a4a5eded8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002567008C0D0>]}
08:30:44.008107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8e4cc3d8-313e-4997-8736-989a4a5eded8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002566FFC3A30>]}
08:30:44.008107 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
08:30:44.011111 [info ] [MainThread]: 
08:30:44.013144 [debug] [MainThread]: Acquiring new postgres connection "master"
08:30:44.015141 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
08:30:44.028141 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
08:30:44.029145 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
08:30:44.029145 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:30:44.127844 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.1 seconds
08:30:44.132393 [debug] [ThreadPool]: On list_recon-cortex: Close
08:30:44.140171 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
08:30:44.146382 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
08:30:44.146382 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
08:30:44.158631 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:30:44.237073 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
08:30:44.238124 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
08:30:44.239078 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
08:30:44.253290 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
08:30:44.261977 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
08:30:44.265266 [debug] [ThreadPool]: On list_recon-cortex_public: Close
08:30:44.278481 [debug] [MainThread]: Using postgres connection "master"
08:30:44.279480 [debug] [MainThread]: On master: BEGIN
08:30:44.280479 [debug] [MainThread]: Opening a new connection, currently in state init
08:30:44.412419 [debug] [MainThread]: SQL status: BEGIN in 0.13 seconds
08:30:44.414203 [debug] [MainThread]: Using postgres connection "master"
08:30:44.415230 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
08:30:45.478349 [debug] [MainThread]: SQL status: SELECT 0 in 1.06 seconds
08:30:45.487480 [debug] [MainThread]: On master: ROLLBACK
08:30:45.493821 [debug] [MainThread]: Using postgres connection "master"
08:30:45.495365 [debug] [MainThread]: On master: BEGIN
08:30:45.504953 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
08:30:45.508843 [debug] [MainThread]: On master: COMMIT
08:30:45.510034 [debug] [MainThread]: Using postgres connection "master"
08:30:45.511035 [debug] [MainThread]: On master: COMMIT
08:30:45.516708 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
08:30:45.520981 [debug] [MainThread]: On master: Close
08:30:45.523044 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
08:30:45.525090 [info ] [MainThread]: 
08:30:45.653152 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
08:30:45.654153 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
08:30:45.655176 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.656375 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
08:30:45.656375 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
08:30:45.667156 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
08:30:45.669939 [debug] [Thread-1  ]: finished collecting timing info
08:30:45.670163 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
08:30:45.792134 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.793135 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp140045773024"
  as (
    


with source_data as (

    select s.* from set2_hdfc_auto s 

),

filter_data_source_1 as (
    select s.*, right(s."txt_txn_desc", 22) as rtgs_utr_no from source_data s where s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),

filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_datasrc1_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.rtgs_utr_no from filter_data_source_1 fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.rtgs_utr_no from filter_matched_data_source_1 fcm
),
filter_datasrc2_unmatched_data as (
    select fds.utr,
        fds.app_id_c,
        fds.las_edit_d,
        fds.disb_amount_n,
        fds.disb_msg_gen_date from filter_data_source_2 fds 
    except select 
        fdm.utr,
        fdm.app_id_c,
        fdm.las_edit_d,
        fdm.disb_amount_n,
        fdm.disb_msg_gen_date from filter_matched_data_source_2 fdm
)


select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc1_unmatched_data
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc2_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
08:30:45.793135 [debug] [Thread-1  ]: Opening a new connection, currently in state init
08:30:45.851342 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.06 seconds
08:30:45.860377 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.861348 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
08:30:45.865341 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
08:30:45.866338 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.866338 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp140045773024'
        
      order by ordinal_position

  
08:30:45.879652 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
08:30:45.888116 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.888116 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
08:30:45.898441 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
08:30:45.909588 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.910063 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
08:30:45.919910 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
08:30:45.927955 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
08:30:45.935968 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.935968 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp140045773024"
    )
  
08:30:45.943953 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
08:30:45.945887 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
08:30:45.945887 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.954008 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
08:30:45.960992 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
08:30:45.962607 [debug] [Thread-1  ]: finished collecting timing info
08:30:45.963608 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
08:30:45.963704 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e4cc3d8-313e-4997-8736-989a4a5eded8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256700E8EE0>]}
08:30:45.964742 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.31s]
08:30:45.965749 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
08:30:45.973271 [debug] [MainThread]: Acquiring new postgres connection "master"
08:30:45.976272 [debug] [MainThread]: Using postgres connection "master"
08:30:45.977281 [debug] [MainThread]: On master: BEGIN
08:30:45.978270 [debug] [MainThread]: Opening a new connection, currently in state closed
08:30:46.057261 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
08:30:46.058119 [debug] [MainThread]: On master: COMMIT
08:30:46.058119 [debug] [MainThread]: Using postgres connection "master"
08:30:46.058887 [debug] [MainThread]: On master: COMMIT
08:30:46.061147 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
08:30:46.064495 [debug] [MainThread]: On master: Close
08:30:46.065494 [info ] [MainThread]: 
08:30:46.066667 [info ] [MainThread]: Finished running 1 incremental model in 2.05s.
08:30:46.068043 [debug] [MainThread]: Connection 'master' was properly closed.
08:30:46.068669 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
08:30:46.069301 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
08:30:46.069702 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
08:30:46.077316 [info ] [MainThread]: 
08:30:46.078938 [info ] [MainThread]: [32mCompleted successfully[0m
08:30:46.081071 [info ] [MainThread]: 
08:30:46.081928 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
08:30:46.083935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002566FFC3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002567000DB50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256700D62B0>]}


============================== 2022-03-22 09:04:38.639483 | cd7b97c1-1fe7-4c94-b3cf-e7edec631cea ==============================
09:04:38.639483 [info ] [MainThread]: Running with dbt=1.0.3
09:04:38.640553 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:04:38.640553 [debug] [MainThread]: Tracking: tracking
09:04:38.697453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017536418B20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017536418FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000175364180D0>]}
09:04:38.748835 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:04:38.748835 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
09:04:38.761934 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
09:04:38.779599 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
09:04:38.797275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cd7b97c1-1fe7-4c94-b3cf-e7edec631cea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001753656B0D0>]}
09:04:38.804376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cd7b97c1-1fe7-4c94-b3cf-e7edec631cea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000175364A39A0>]}
09:04:38.804376 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:04:38.807158 [info ] [MainThread]: 
09:04:38.808072 [debug] [MainThread]: Acquiring new postgres connection "master"
09:04:38.810940 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:04:38.827944 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:04:38.828944 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:04:38.830963 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:04:38.917633 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.09 seconds
09:04:38.919682 [debug] [ThreadPool]: On list_recon-cortex: Close
09:04:38.921646 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:04:38.928821 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:04:38.929990 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:04:38.929990 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:04:38.982117 [debug] [ThreadPool]: SQL status: BEGIN in 0.05 seconds
09:04:38.984983 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:04:38.986002 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:04:38.996154 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:04:38.998201 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:04:39.012094 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:04:39.027485 [debug] [MainThread]: Using postgres connection "master"
09:04:39.028808 [debug] [MainThread]: On master: BEGIN
09:04:39.028808 [debug] [MainThread]: Opening a new connection, currently in state init
09:04:39.093590 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
09:04:39.094592 [debug] [MainThread]: Using postgres connection "master"
09:04:39.095582 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:04:40.162306 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
09:04:40.166628 [debug] [MainThread]: On master: ROLLBACK
09:04:40.171582 [debug] [MainThread]: Using postgres connection "master"
09:04:40.176994 [debug] [MainThread]: On master: BEGIN
09:04:40.186539 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:04:40.188314 [debug] [MainThread]: On master: COMMIT
09:04:40.189402 [debug] [MainThread]: Using postgres connection "master"
09:04:40.190406 [debug] [MainThread]: On master: COMMIT
09:04:40.197298 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:04:40.198336 [debug] [MainThread]: On master: Close
09:04:40.199818 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:04:40.201820 [info ] [MainThread]: 
09:04:40.215154 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:04:40.216155 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:04:40.218333 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:04:40.220153 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:04:40.220153 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:04:40.236157 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:04:40.237258 [debug] [Thread-1  ]: finished collecting timing info
09:04:40.238156 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:04:40.354255 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:04:40.355258 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp143440333396"
  as (
    


with filter_data_source_1 as (

    select s.* from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    where fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:04:40.355258 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:04:40.421339 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column fds1.rtgs_utr_no does not exist
LINE 21:      and fds1.rtgs_utr_no = fds2.utr
                  ^

09:04:40.422131 [debug] [Thread-1  ]: finished collecting timing info
09:04:40.422131 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:04:40.423139 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  column fds1.rtgs_utr_no does not exist
  LINE 21:      and fds1.rtgs_utr_no = fds2.utr
                    ^
09:04:40.424158 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cd7b97c1-1fe7-4c94-b3cf-e7edec631cea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001753650A1F0>]}
09:04:40.425160 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.21s]
09:04:40.426208 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:04:40.428363 [debug] [MainThread]: Acquiring new postgres connection "master"
09:04:40.429342 [debug] [MainThread]: Using postgres connection "master"
09:04:40.430114 [debug] [MainThread]: On master: BEGIN
09:04:40.430114 [debug] [MainThread]: Opening a new connection, currently in state closed
09:04:40.493160 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
09:04:40.494081 [debug] [MainThread]: On master: COMMIT
09:04:40.495078 [debug] [MainThread]: Using postgres connection "master"
09:04:40.497098 [debug] [MainThread]: On master: COMMIT
09:04:40.504713 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
09:04:40.505107 [debug] [MainThread]: On master: Close
09:04:40.506078 [info ] [MainThread]: 
09:04:40.508077 [info ] [MainThread]: Finished running 1 incremental model in 1.70s.
09:04:40.511093 [debug] [MainThread]: Connection 'master' was properly closed.
09:04:40.513142 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:04:40.514077 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:04:40.515075 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:04:40.523080 [info ] [MainThread]: 
09:04:40.524077 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
09:04:40.528088 [info ] [MainThread]: 
09:04:40.531078 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
09:04:40.535117 [error] [MainThread]:   column fds1.rtgs_utr_no does not exist
09:04:40.536079 [error] [MainThread]:   LINE 21:      and fds1.rtgs_utr_no = fds2.utr
09:04:40.538075 [error] [MainThread]:                     ^
09:04:40.539077 [info ] [MainThread]: 
09:04:40.539077 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
09:04:40.540075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000175365D1A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000175365C9AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017536414430>]}


============================== 2022-03-22 09:05:56.040193 | d5d11194-173b-4b8b-a5e8-aabc3709e66b ==============================
09:05:56.040193 [info ] [MainThread]: Running with dbt=1.0.3
09:05:56.051792 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:05:56.051792 [debug] [MainThread]: Tracking: tracking
09:05:56.082824 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D0D84C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D0D8FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D0D80D0>]}
09:05:56.197627 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:05:56.212460 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
09:05:56.214451 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
09:05:56.226471 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
09:05:56.250972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd5d11194-173b-4b8b-a5e8-aabc3709e66b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D22C0D0>]}
09:05:56.260531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd5d11194-173b-4b8b-a5e8-aabc3709e66b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D167A30>]}
09:05:56.260531 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:05:56.263145 [info ] [MainThread]: 
09:05:56.263624 [debug] [MainThread]: Acquiring new postgres connection "master"
09:05:56.265620 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:05:56.281620 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:05:56.282324 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:05:56.282620 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:05:56.342896 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.06 seconds
09:05:56.344616 [debug] [ThreadPool]: On list_recon-cortex: Close
09:05:56.346620 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:05:56.354619 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:05:56.355622 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:05:56.355622 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:05:56.407591 [debug] [ThreadPool]: SQL status: BEGIN in 0.05 seconds
09:05:56.412404 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:05:56.412404 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:05:56.415098 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.0 seconds
09:05:56.424875 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:05:56.451264 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:05:56.459069 [debug] [MainThread]: Using postgres connection "master"
09:05:56.461095 [debug] [MainThread]: On master: BEGIN
09:05:56.461095 [debug] [MainThread]: Opening a new connection, currently in state init
09:05:56.554830 [debug] [MainThread]: SQL status: BEGIN in 0.09 seconds
09:05:56.556020 [debug] [MainThread]: Using postgres connection "master"
09:05:56.557022 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:05:57.635168 [debug] [MainThread]: SQL status: SELECT 0 in 1.08 seconds
09:05:57.637276 [debug] [MainThread]: On master: ROLLBACK
09:05:57.641770 [debug] [MainThread]: Using postgres connection "master"
09:05:57.641770 [debug] [MainThread]: On master: BEGIN
09:05:57.650988 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:05:57.651993 [debug] [MainThread]: On master: COMMIT
09:05:57.651993 [debug] [MainThread]: Using postgres connection "master"
09:05:57.652991 [debug] [MainThread]: On master: COMMIT
09:05:57.656735 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:05:57.658548 [debug] [MainThread]: On master: Close
09:05:57.658548 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:05:57.659694 [info ] [MainThread]: 
09:05:57.669709 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:05:57.670698 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:05:57.674701 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:05:57.675698 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:05:57.676699 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:05:57.692694 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:05:57.693696 [debug] [Thread-1  ]: finished collecting timing info
09:05:57.694695 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:05:57.816687 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:05:57.817195 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp143557793911"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    where fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:05:57.817195 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:05:57.866016 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.05 seconds
09:05:57.875645 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:05:57.875645 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:05:57.883083 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
09:05:57.884083 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:05:57.884083 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp143557793911'
        
      order by ordinal_position

  
09:05:57.897014 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:05:57.907473 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:05:57.908315 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:05:57.916463 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:05:57.922056 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:05:57.922056 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:05:57.934344 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:05:57.950368 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:05:57.951362 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:05:57.951362 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp143557793911"
    )
  
09:05:57.982916 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.03 seconds
09:05:57.999036 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:05:57.999036 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:05:58.006109 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:05:58.010431 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
09:05:58.013918 [debug] [Thread-1  ]: finished collecting timing info
09:05:58.014956 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:05:58.016922 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5d11194-173b-4b8b-a5e8-aabc3709e66b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D289EE0>]}
09:05:58.017922 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.34s]
09:05:58.019916 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:05:58.021917 [debug] [MainThread]: Acquiring new postgres connection "master"
09:05:58.021917 [debug] [MainThread]: Using postgres connection "master"
09:05:58.022952 [debug] [MainThread]: On master: BEGIN
09:05:58.022952 [debug] [MainThread]: Opening a new connection, currently in state closed
09:05:58.088895 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
09:05:58.089790 [debug] [MainThread]: On master: COMMIT
09:05:58.090369 [debug] [MainThread]: Using postgres connection "master"
09:05:58.090786 [debug] [MainThread]: On master: COMMIT
09:05:58.096942 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
09:05:58.097896 [debug] [MainThread]: On master: Close
09:05:58.099853 [info ] [MainThread]: 
09:05:58.100786 [info ] [MainThread]: Finished running 1 incremental model in 1.84s.
09:05:58.101786 [debug] [MainThread]: Connection 'master' was properly closed.
09:05:58.101786 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:05:58.102790 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:05:58.102790 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:05:58.107785 [info ] [MainThread]: 
09:05:58.108822 [info ] [MainThread]: [32mCompleted successfully[0m
09:05:58.109785 [info ] [MainThread]: 
09:05:58.110792 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:05:58.111790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D167520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D1ACB50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D2771F0>]}


============================== 2022-03-22 09:06:47.221220 | 7e55d40c-ae85-490f-8293-99f6aa633d80 ==============================
09:06:47.221220 [info ] [MainThread]: Running with dbt=1.0.3
09:06:47.222912 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:06:47.222912 [debug] [MainThread]: Tracking: tracking
09:06:47.254912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A130548730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A130548FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A130548340>]}
09:06:47.312945 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:06:47.315106 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:06:47.318387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7e55d40c-ae85-490f-8293-99f6aa633d80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A13064B0D0>]}
09:06:47.325453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7e55d40c-ae85-490f-8293-99f6aa633d80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A1305D3B50>]}
09:06:47.326416 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:06:47.328567 [info ] [MainThread]: 
09:06:47.329515 [debug] [MainThread]: Acquiring new postgres connection "master"
09:06:47.331430 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:06:47.346426 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:06:47.347420 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:06:47.347420 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:06:47.437770 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.09 seconds
09:06:47.439563 [debug] [ThreadPool]: On list_recon-cortex: Close
09:06:47.442527 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:06:47.449718 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:06:47.450919 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:06:47.450919 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:06:47.533865 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
09:06:47.537294 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:06:47.538290 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:06:47.549058 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:06:47.554127 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:06:47.556959 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:06:47.568786 [debug] [MainThread]: Using postgres connection "master"
09:06:47.573303 [debug] [MainThread]: On master: BEGIN
09:06:47.573303 [debug] [MainThread]: Opening a new connection, currently in state init
09:06:47.639700 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
09:06:47.641789 [debug] [MainThread]: Using postgres connection "master"
09:06:47.643356 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:06:48.708455 [debug] [MainThread]: SQL status: SELECT 0 in 1.06 seconds
09:06:48.711654 [debug] [MainThread]: On master: ROLLBACK
09:06:48.717670 [debug] [MainThread]: Using postgres connection "master"
09:06:48.717670 [debug] [MainThread]: On master: BEGIN
09:06:48.731155 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:06:48.735486 [debug] [MainThread]: On master: COMMIT
09:06:48.736137 [debug] [MainThread]: Using postgres connection "master"
09:06:48.738147 [debug] [MainThread]: On master: COMMIT
09:06:48.742432 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:06:48.743702 [debug] [MainThread]: On master: Close
09:06:48.744703 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:06:48.745700 [info ] [MainThread]: 
09:06:48.754701 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:06:48.756701 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:06:48.760717 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:06:48.762771 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:06:48.763874 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:06:48.781700 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:06:48.782701 [debug] [Thread-1  ]: finished collecting timing info
09:06:48.782701 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:06:48.854700 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:06:48.855735 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp143648832700"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    where fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:06:48.855735 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:06:48.908251 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.05 seconds
09:06:48.918976 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:06:48.918976 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:06:48.923362 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
09:06:48.924359 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:06:48.925359 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp143648832700'
        
      order by ordinal_position

  
09:06:48.936994 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:06:48.947624 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:06:48.948627 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:06:48.982466 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.03 seconds
09:06:48.988614 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:06:48.992997 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:06:49.002515 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:06:49.015102 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:06:49.016143 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:06:49.017143 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp143648832700"
    )
  
09:06:49.021617 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.0 seconds
09:06:49.028079 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:06:49.028079 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:06:49.030842 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:06:49.035418 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
09:06:49.037085 [debug] [Thread-1  ]: finished collecting timing info
09:06:49.037085 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:06:49.038090 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e55d40c-ae85-490f-8293-99f6aa633d80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A1306F1820>]}
09:06:49.038090 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.28s]
09:06:49.040083 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:06:49.042113 [debug] [MainThread]: Acquiring new postgres connection "master"
09:06:49.043224 [debug] [MainThread]: Using postgres connection "master"
09:06:49.043224 [debug] [MainThread]: On master: BEGIN
09:06:49.043224 [debug] [MainThread]: Opening a new connection, currently in state closed
09:06:49.119149 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
09:06:49.119993 [debug] [MainThread]: On master: COMMIT
09:06:49.120147 [debug] [MainThread]: Using postgres connection "master"
09:06:49.120147 [debug] [MainThread]: On master: COMMIT
09:06:49.124981 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:06:49.125146 [debug] [MainThread]: On master: Close
09:06:49.127159 [info ] [MainThread]: 
09:06:49.128224 [info ] [MainThread]: Finished running 1 incremental model in 1.80s.
09:06:49.129145 [debug] [MainThread]: Connection 'master' was properly closed.
09:06:49.129145 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:06:49.130144 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:06:49.130144 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:06:49.135148 [info ] [MainThread]: 
09:06:49.136170 [info ] [MainThread]: [32mCompleted successfully[0m
09:06:49.139157 [info ] [MainThread]: 
09:06:49.143183 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:06:49.145691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A1305D35E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A130667580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A1306BF220>]}


============================== 2022-03-22 09:08:14.179111 | 42d947a9-d1d2-4767-b1cb-f1bba54b5d9c ==============================
09:08:14.179111 [info ] [MainThread]: Running with dbt=1.0.3
09:08:14.180460 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:08:14.180460 [debug] [MainThread]: Tracking: tracking
09:08:14.214678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E474698A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E475758C40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E475758700>]}
09:08:14.405241 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:08:14.405241 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
09:08:14.412195 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
09:08:14.433121 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
09:08:14.446242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '42d947a9-d1d2-4767-b1cb-f1bba54b5d9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E4758AC0D0>]}
09:08:14.454024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '42d947a9-d1d2-4767-b1cb-f1bba54b5d9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E4757E3A30>]}
09:08:14.455020 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:08:14.456700 [info ] [MainThread]: 
09:08:14.458700 [debug] [MainThread]: Acquiring new postgres connection "master"
09:08:14.460879 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:08:14.470730 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:08:14.471707 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:08:14.471707 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:08:14.544421 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.07 seconds
09:08:14.546360 [debug] [ThreadPool]: On list_recon-cortex: Close
09:08:14.548321 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:08:14.554355 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:08:14.554355 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:08:14.556925 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:08:14.628353 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
09:08:14.629689 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:08:14.630734 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:08:14.640244 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:08:14.648477 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:08:14.655866 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:08:14.667705 [debug] [MainThread]: Using postgres connection "master"
09:08:14.671046 [debug] [MainThread]: On master: BEGIN
09:08:14.672095 [debug] [MainThread]: Opening a new connection, currently in state init
09:08:14.771030 [debug] [MainThread]: SQL status: BEGIN in 0.1 seconds
09:08:14.772334 [debug] [MainThread]: Using postgres connection "master"
09:08:14.773340 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:08:15.840590 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
09:08:15.845758 [debug] [MainThread]: On master: ROLLBACK
09:08:15.852426 [debug] [MainThread]: Using postgres connection "master"
09:08:15.853425 [debug] [MainThread]: On master: BEGIN
09:08:15.861210 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:08:15.861210 [debug] [MainThread]: On master: COMMIT
09:08:15.862215 [debug] [MainThread]: Using postgres connection "master"
09:08:15.863207 [debug] [MainThread]: On master: COMMIT
09:08:15.867563 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:08:15.867798 [debug] [MainThread]: On master: Close
09:08:15.868897 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:08:15.869898 [info ] [MainThread]: 
09:08:15.879895 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:08:15.881907 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:08:15.887175 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:08:15.888902 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:08:15.889900 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:08:15.902910 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:08:15.904901 [debug] [Thread-1  ]: finished collecting timing info
09:08:15.906514 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:08:16.023619 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:16.024846 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp143816004158"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:08:16.024846 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:08:16.070255 [debug] [Thread-1  ]: SQL status: SELECT 5 in 0.05 seconds
09:08:16.082349 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:16.083571 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:08:16.087895 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
09:08:16.088897 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:16.088897 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp143816004158'
        
      order by ordinal_position

  
09:08:16.101566 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:08:16.109328 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:16.109328 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:08:16.118322 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:08:16.128209 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:16.129209 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:08:16.137483 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:08:16.148188 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:08:16.149187 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:16.149187 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp143816004158"
    )
  
09:08:16.156077 [debug] [Thread-1  ]: SQL status: INSERT 0 5 in 0.01 seconds
09:08:16.177316 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:08:16.178313 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:16.179318 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:08:16.185310 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
09:08:16.187311 [debug] [Thread-1  ]: finished collecting timing info
09:08:16.188327 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:08:16.189312 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42d947a9-d1d2-4767-b1cb-f1bba54b5d9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E475907A90>]}
09:08:16.190310 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 5[0m in 0.31s]
09:08:16.192310 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:08:16.194312 [debug] [MainThread]: Acquiring new postgres connection "master"
09:08:16.194312 [debug] [MainThread]: Using postgres connection "master"
09:08:16.195313 [debug] [MainThread]: On master: BEGIN
09:08:16.195313 [debug] [MainThread]: Opening a new connection, currently in state closed
09:08:16.271372 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
09:08:16.272377 [debug] [MainThread]: On master: COMMIT
09:08:16.272377 [debug] [MainThread]: Using postgres connection "master"
09:08:16.273096 [debug] [MainThread]: On master: COMMIT
09:08:16.277201 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:08:16.278194 [debug] [MainThread]: On master: Close
09:08:16.279093 [info ] [MainThread]: 
09:08:16.280096 [info ] [MainThread]: Finished running 1 incremental model in 1.82s.
09:08:16.282094 [debug] [MainThread]: Connection 'master' was properly closed.
09:08:16.282094 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:08:16.283095 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:08:16.284101 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:08:16.293105 [info ] [MainThread]: 
09:08:16.297106 [info ] [MainThread]: [32mCompleted successfully[0m
09:08:16.301097 [info ] [MainThread]: 
09:08:16.303561 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:08:16.307111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E4757E3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E47582CA00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E474073AF0>]}


============================== 2022-03-22 09:08:56.843215 | 09a7df9c-edca-4270-8aec-f29bc83224c4 ==============================
09:08:56.843215 [info ] [MainThread]: Running with dbt=1.0.3
09:08:56.858641 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:08:56.859669 [debug] [MainThread]: Tracking: tracking
09:08:56.888249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FED27C70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FED27FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FED278E0>]}
09:08:56.943284 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:08:56.943284 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:08:56.949283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '09a7df9c-edca-4270-8aec-f29bc83224c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FEE2C0D0>]}
09:08:56.955250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '09a7df9c-edca-4270-8aec-f29bc83224c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FEDAAB20>]}
09:08:56.955250 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:08:56.957883 [info ] [MainThread]: 
09:08:56.959249 [debug] [MainThread]: Acquiring new postgres connection "master"
09:08:56.961249 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:08:56.976800 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:08:56.977830 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:08:56.978798 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:08:57.050077 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.07 seconds
09:08:57.052640 [debug] [ThreadPool]: On list_recon-cortex: Close
09:08:57.055641 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:08:57.063795 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:08:57.063795 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:08:57.067941 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:08:57.134829 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
09:08:57.135827 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:08:57.136863 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:08:57.147908 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:08:57.150946 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:08:57.165423 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:08:57.174812 [debug] [MainThread]: Using postgres connection "master"
09:08:57.174812 [debug] [MainThread]: On master: BEGIN
09:08:57.181025 [debug] [MainThread]: Opening a new connection, currently in state init
09:08:57.262304 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
09:08:57.263300 [debug] [MainThread]: Using postgres connection "master"
09:08:57.264287 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:08:58.325095 [debug] [MainThread]: SQL status: SELECT 0 in 1.06 seconds
09:08:58.341434 [debug] [MainThread]: On master: ROLLBACK
09:08:58.348964 [debug] [MainThread]: Using postgres connection "master"
09:08:58.350703 [debug] [MainThread]: On master: BEGIN
09:08:58.362075 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:08:58.363111 [debug] [MainThread]: On master: COMMIT
09:08:58.364069 [debug] [MainThread]: Using postgres connection "master"
09:08:58.364069 [debug] [MainThread]: On master: COMMIT
09:08:58.371072 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
09:08:58.371072 [debug] [MainThread]: On master: Close
09:08:58.373069 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:08:58.374068 [info ] [MainThread]: 
09:08:58.385071 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:08:58.386070 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:08:58.390108 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.392161 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:08:58.393077 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:08:58.404113 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:08:58.405069 [debug] [Thread-1  ]: finished collecting timing info
09:08:58.405069 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:08:58.477068 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.478069 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp143858451071"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:08:58.479071 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:08:58.535570 [debug] [Thread-1  ]: SQL status: SELECT 5 in 0.06 seconds
09:08:58.542693 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.542693 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:08:58.549124 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
09:08:58.551122 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.551845 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp143858451071'
        
      order by ordinal_position

  
09:08:58.566900 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:08:58.585614 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.586612 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:08:58.596235 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:08:58.608397 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.608397 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:08:58.641096 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.03 seconds
09:08:58.656841 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:08:58.657848 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.658842 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp143858451071"
    )
  
09:08:58.666843 [debug] [Thread-1  ]: SQL status: INSERT 0 5 in 0.01 seconds
09:08:58.681890 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:08:58.681890 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.682844 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:08:58.688842 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
09:08:58.689846 [debug] [Thread-1  ]: finished collecting timing info
09:08:58.690851 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:08:58.693079 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09a7df9c-edca-4270-8aec-f29bc83224c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FEED85E0>]}
09:08:58.693842 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 5[0m in 0.31s]
09:08:58.694860 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:08:58.697860 [debug] [MainThread]: Acquiring new postgres connection "master"
09:08:58.697860 [debug] [MainThread]: Using postgres connection "master"
09:08:58.698842 [debug] [MainThread]: On master: BEGIN
09:08:58.698842 [debug] [MainThread]: Opening a new connection, currently in state closed
09:08:58.743303 [debug] [MainThread]: SQL status: BEGIN in 0.04 seconds
09:08:58.743725 [debug] [MainThread]: On master: COMMIT
09:08:58.743725 [debug] [MainThread]: Using postgres connection "master"
09:08:58.744729 [debug] [MainThread]: On master: COMMIT
09:08:58.748763 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:08:58.749995 [debug] [MainThread]: On master: Close
09:08:58.750724 [info ] [MainThread]: 
09:08:58.751419 [info ] [MainThread]: Finished running 1 incremental model in 1.79s.
09:08:58.751724 [debug] [MainThread]: Connection 'master' was properly closed.
09:08:58.752726 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:08:58.752726 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:08:58.752726 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:08:58.759477 [info ] [MainThread]: 
09:08:58.759727 [info ] [MainThread]: [32mCompleted successfully[0m
09:08:58.760726 [info ] [MainThread]: 
09:08:58.761819 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:08:58.763730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FEDAA5B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FEE47580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FEEA0310>]}


============================== 2022-03-22 09:12:54.061796 | 71452c59-bee6-4edf-b1a1-9848ac67228c ==============================
09:12:54.061796 [info ] [MainThread]: Running with dbt=1.0.3
09:12:54.066296 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:12:54.067363 [debug] [MainThread]: Tracking: tracking
09:12:54.109510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D6E8520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D6E8FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D6E80D0>]}
09:12:54.205786 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:12:54.205786 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
09:12:54.236147 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
09:12:54.279271 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
09:12:54.305469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '71452c59-bee6-4edf-b1a1-9848ac67228c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D83C0D0>]}
09:12:54.325947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '71452c59-bee6-4edf-b1a1-9848ac67228c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D7779A0>]}
09:12:54.326950 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:12:54.330409 [info ] [MainThread]: 
09:12:54.333195 [debug] [MainThread]: Acquiring new postgres connection "master"
09:12:54.337195 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:12:54.371587 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:12:54.374198 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:12:54.376207 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:12:54.446198 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.07 seconds
09:12:54.449198 [debug] [ThreadPool]: On list_recon-cortex: Close
09:12:54.453194 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:12:54.457622 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:12:54.457622 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:12:54.468424 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:12:54.530265 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
09:12:54.533671 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:12:54.534680 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:12:54.853279 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.32 seconds
09:12:54.854327 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:12:54.866971 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:12:54.876145 [debug] [MainThread]: Using postgres connection "master"
09:12:54.876145 [debug] [MainThread]: On master: BEGIN
09:12:54.892005 [debug] [MainThread]: Opening a new connection, currently in state init
09:12:54.967920 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
09:12:54.969635 [debug] [MainThread]: Using postgres connection "master"
09:12:54.970682 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:12:56.029961 [debug] [MainThread]: SQL status: SELECT 0 in 1.06 seconds
09:12:56.046956 [debug] [MainThread]: On master: ROLLBACK
09:12:56.050106 [debug] [MainThread]: Using postgres connection "master"
09:12:56.054228 [debug] [MainThread]: On master: BEGIN
09:12:56.065301 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:12:56.069043 [debug] [MainThread]: On master: COMMIT
09:12:56.070093 [debug] [MainThread]: Using postgres connection "master"
09:12:56.071049 [debug] [MainThread]: On master: COMMIT
09:12:56.073271 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:12:56.077942 [debug] [MainThread]: On master: Close
09:12:56.080158 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:12:56.083445 [info ] [MainThread]: 
09:12:56.096522 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:12:56.097527 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:12:56.102519 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.102519 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:12:56.103516 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:12:56.111518 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:12:56.112932 [debug] [Thread-1  ]: finished collecting timing info
09:12:56.113519 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:12:56.210462 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.210462 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp144256198520"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    CASE WHEN agreement_no is not null then 1
    ELSE
     1
    end as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:12:56.216546 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:12:56.273347 [debug] [Thread-1  ]: SQL status: SELECT 5 in 0.06 seconds
09:12:56.282206 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.282206 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:12:56.288206 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
09:12:56.289212 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.289212 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp144256198520'
        
      order by ordinal_position

  
09:12:56.304208 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:12:56.313209 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.314208 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:12:56.324253 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:12:56.331326 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.331326 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:12:56.349033 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:12:56.367800 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:12:56.369799 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.369799 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp144256198520"
    )
  
09:12:56.390753 [debug] [Thread-1  ]: SQL status: INSERT 0 5 in 0.02 seconds
09:12:56.399330 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:12:56.399330 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.400328 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:12:56.406768 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
09:12:56.408767 [debug] [Thread-1  ]: finished collecting timing info
09:12:56.409420 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:12:56.410416 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '71452c59-bee6-4edf-b1a1-9848ac67228c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D6E1280>]}
09:12:56.412445 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 5[0m in 0.31s]
09:12:56.414469 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:12:56.419470 [debug] [MainThread]: Acquiring new postgres connection "master"
09:12:56.420578 [debug] [MainThread]: Using postgres connection "master"
09:12:56.421447 [debug] [MainThread]: On master: BEGIN
09:12:56.422451 [debug] [MainThread]: Opening a new connection, currently in state closed
09:12:56.483461 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
09:12:56.485458 [debug] [MainThread]: On master: COMMIT
09:12:56.487449 [debug] [MainThread]: Using postgres connection "master"
09:12:56.487449 [debug] [MainThread]: On master: COMMIT
09:12:56.492446 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:12:56.493447 [debug] [MainThread]: On master: Close
09:12:56.495448 [info ] [MainThread]: 
09:12:56.497449 [info ] [MainThread]: Finished running 1 incremental model in 2.16s.
09:12:56.499451 [debug] [MainThread]: Connection 'master' was properly closed.
09:12:56.500478 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:12:56.502518 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:12:56.504476 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:12:56.515446 [info ] [MainThread]: 
09:12:56.518488 [info ] [MainThread]: [32mCompleted successfully[0m
09:12:56.522450 [info ] [MainThread]: 
09:12:56.524449 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:12:56.526451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D8A2A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D7BCEE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D6E9D90>]}


============================== 2022-03-22 09:13:32.217543 | e46e367e-6e09-4dae-b52b-0b7e6ba9e79b ==============================
09:13:32.217543 [info ] [MainThread]: Running with dbt=1.0.3
09:13:32.218956 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:13:32.218956 [debug] [MainThread]: Tracking: tracking
09:13:32.248752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4497784C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C449778FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4497780D0>]}
09:13:32.415969 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:13:32.415969 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
09:13:32.426220 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
09:13:32.440935 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
09:13:32.457856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e46e367e-6e09-4dae-b52b-0b7e6ba9e79b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4498CA0D0>]}
09:13:32.464569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e46e367e-6e09-4dae-b52b-0b7e6ba9e79b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C449803A30>]}
09:13:32.465568 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:13:32.467545 [info ] [MainThread]: 
09:13:32.468813 [debug] [MainThread]: Acquiring new postgres connection "master"
09:13:32.470806 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:13:32.485833 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:13:32.486881 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:13:32.486881 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:13:32.551727 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.06 seconds
09:13:32.552694 [debug] [ThreadPool]: On list_recon-cortex: Close
09:13:32.554693 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:13:32.560696 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:13:32.561696 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:13:32.562322 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:13:32.653446 [debug] [ThreadPool]: SQL status: BEGIN in 0.09 seconds
09:13:32.653446 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:13:32.654447 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:13:32.667405 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:13:32.669701 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:13:32.675694 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:13:32.685380 [debug] [MainThread]: Using postgres connection "master"
09:13:32.687611 [debug] [MainThread]: On master: BEGIN
09:13:32.688610 [debug] [MainThread]: Opening a new connection, currently in state init
09:13:32.773308 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
09:13:32.774904 [debug] [MainThread]: Using postgres connection "master"
09:13:32.776664 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:13:33.847588 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
09:13:33.851920 [debug] [MainThread]: On master: ROLLBACK
09:13:33.856451 [debug] [MainThread]: Using postgres connection "master"
09:13:33.857448 [debug] [MainThread]: On master: BEGIN
09:13:33.866683 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:13:33.867200 [debug] [MainThread]: On master: COMMIT
09:13:33.867200 [debug] [MainThread]: Using postgres connection "master"
09:13:33.867200 [debug] [MainThread]: On master: COMMIT
09:13:33.875351 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
09:13:33.876348 [debug] [MainThread]: On master: Close
09:13:33.877857 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:13:33.878388 [info ] [MainThread]: 
09:13:33.889403 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:13:33.890402 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:13:33.894844 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:13:33.895461 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:13:33.896626 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:13:33.912425 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:13:33.913390 [debug] [Thread-1  ]: finished collecting timing info
09:13:33.914391 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:13:34.034359 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:13:34.035704 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp144334013718"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    CASE WHEN agreement_no is not null then 1
    ELSE
     0
    end as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:13:34.035704 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:13:34.091566 [debug] [Thread-1  ]: SQL status: SELECT 5 in 0.06 seconds
09:13:34.103320 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:13:34.104321 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:13:34.108687 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
09:13:34.109687 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:13:34.109687 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp144334013718'
        
      order by ordinal_position

  
09:13:34.122739 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:13:34.130848 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:13:34.131816 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:13:34.140775 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:13:34.149951 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:13:34.149951 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:13:34.158807 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:13:34.170807 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:13:34.171352 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:13:34.171817 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp144334013718"
    )
  
09:13:34.180788 [debug] [Thread-1  ]: SQL status: INSERT 0 5 in 0.01 seconds
09:13:34.187816 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:13:34.187816 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:13:34.188625 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:13:34.195481 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
09:13:34.196492 [debug] [Thread-1  ]: finished collecting timing info
09:13:34.197306 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:13:34.198250 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e46e367e-6e09-4dae-b52b-0b7e6ba9e79b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C449928EE0>]}
09:13:34.198250 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 5[0m in 0.30s]
09:13:34.200776 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:13:34.202250 [debug] [MainThread]: Acquiring new postgres connection "master"
09:13:34.202250 [debug] [MainThread]: Using postgres connection "master"
09:13:34.203435 [debug] [MainThread]: On master: BEGIN
09:13:34.203435 [debug] [MainThread]: Opening a new connection, currently in state closed
09:13:34.267072 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
09:13:34.268075 [debug] [MainThread]: On master: COMMIT
09:13:34.268075 [debug] [MainThread]: Using postgres connection "master"
09:13:34.268075 [debug] [MainThread]: On master: COMMIT
09:13:34.274967 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
09:13:34.274967 [debug] [MainThread]: On master: Close
09:13:34.275920 [info ] [MainThread]: 
09:13:34.277201 [info ] [MainThread]: Finished running 1 incremental model in 1.81s.
09:13:34.277877 [debug] [MainThread]: Connection 'master' was properly closed.
09:13:34.277877 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:13:34.277877 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:13:34.278876 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:13:34.284877 [info ] [MainThread]: 
09:13:34.285880 [info ] [MainThread]: [32mCompleted successfully[0m
09:13:34.287879 [info ] [MainThread]: 
09:13:34.289900 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:13:34.294882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C449932A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C44992AAC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4486B81F0>]}


============================== 2022-03-22 09:18:01.497095 | 207d5547-71f4-4d22-b2c4-d4eacbd7c573 ==============================
09:18:01.497095 [info ] [MainThread]: Running with dbt=1.0.3
09:18:01.507772 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:18:01.507772 [debug] [MainThread]: Tracking: tracking
09:18:01.541777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C305F384C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C305F38FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C305F380D0>]}
09:18:01.599926 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:18:01.601813 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
09:18:01.603847 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
09:18:01.630810 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
09:18:01.645498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '207d5547-71f4-4d22-b2c4-d4eacbd7c573', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C30608A0D0>]}
09:18:01.651886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '207d5547-71f4-4d22-b2c4-d4eacbd7c573', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C305FC3A30>]}
09:18:01.651886 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:18:01.654582 [info ] [MainThread]: 
09:18:01.655245 [debug] [MainThread]: Acquiring new postgres connection "master"
09:18:01.657236 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:18:01.673281 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:18:01.673281 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:18:01.674229 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:18:01.761265 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.09 seconds
09:18:01.764286 [debug] [ThreadPool]: On list_recon-cortex: Close
09:18:01.766286 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:18:01.774442 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:18:01.774442 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:18:01.778321 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:18:01.852094 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
09:18:01.854103 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:18:01.855610 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:18:01.865071 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:18:01.868077 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:18:01.879686 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:18:01.889200 [debug] [MainThread]: Using postgres connection "master"
09:18:01.898745 [debug] [MainThread]: On master: BEGIN
09:18:01.898745 [debug] [MainThread]: Opening a new connection, currently in state init
09:18:01.985770 [debug] [MainThread]: SQL status: BEGIN in 0.09 seconds
09:18:01.987277 [debug] [MainThread]: Using postgres connection "master"
09:18:01.988768 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:18:03.084644 [debug] [MainThread]: SQL status: SELECT 0 in 1.09 seconds
09:18:03.091090 [debug] [MainThread]: On master: ROLLBACK
09:18:03.096396 [debug] [MainThread]: Using postgres connection "master"
09:18:03.099382 [debug] [MainThread]: On master: BEGIN
09:18:03.108672 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:18:03.109679 [debug] [MainThread]: On master: COMMIT
09:18:03.110554 [debug] [MainThread]: Using postgres connection "master"
09:18:03.110554 [debug] [MainThread]: On master: COMMIT
09:18:03.111575 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:18:03.116196 [debug] [MainThread]: On master: Close
09:18:03.117195 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:18:03.117640 [info ] [MainThread]: 
09:18:03.128640 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:18:03.129642 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:18:03.132684 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.133648 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:18:03.135642 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:18:03.145641 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:18:03.148649 [debug] [Thread-1  ]: finished collecting timing info
09:18:03.150639 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:18:03.272338 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.273339 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp144803251276"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.*, fds1.rtgs_utr_no as rtgs_utr_no from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    CASE WHEN agreement_no is not null then 1
    ELSE
     0
    end as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    CASE WHEN rtgs_utr_no is not null then 1
    ELSE
     0
    END as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:18:03.273339 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:18:03.328053 [debug] [Thread-1  ]: SQL status: SELECT 5 in 0.05 seconds
09:18:03.340041 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.340041 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:18:03.346579 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
09:18:03.347550 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.347550 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp144803251276'
        
      order by ordinal_position

  
09:18:03.360655 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:18:03.368459 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.369468 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:18:03.377834 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:18:03.379836 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.379836 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:18:03.705438 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.32 seconds
09:18:03.739892 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:18:03.741807 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.742713 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp144803251276"
    )
  
09:18:03.749224 [debug] [Thread-1  ]: SQL status: INSERT 0 5 in 0.01 seconds
09:18:03.751221 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:18:03.751221 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.759672 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:18:03.764981 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
09:18:03.766020 [debug] [Thread-1  ]: finished collecting timing info
09:18:03.766605 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:18:03.766605 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '207d5547-71f4-4d22-b2c4-d4eacbd7c573', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C3060E8EE0>]}
09:18:03.767634 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 5[0m in 0.63s]
09:18:03.768695 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:18:03.770700 [debug] [MainThread]: Acquiring new postgres connection "master"
09:18:03.771732 [debug] [MainThread]: Using postgres connection "master"
09:18:03.772073 [debug] [MainThread]: On master: BEGIN
09:18:03.772251 [debug] [MainThread]: Opening a new connection, currently in state closed
09:18:03.816335 [debug] [MainThread]: SQL status: BEGIN in 0.04 seconds
09:18:03.817710 [debug] [MainThread]: On master: COMMIT
09:18:03.817710 [debug] [MainThread]: Using postgres connection "master"
09:18:03.818366 [debug] [MainThread]: On master: COMMIT
09:18:03.822874 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:18:03.823568 [debug] [MainThread]: On master: Close
09:18:03.823884 [info ] [MainThread]: 
09:18:03.825117 [info ] [MainThread]: Finished running 1 incremental model in 2.17s.
09:18:03.825889 [debug] [MainThread]: Connection 'master' was properly closed.
09:18:03.825889 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:18:03.826884 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:18:03.826884 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:18:03.835921 [info ] [MainThread]: 
09:18:03.836891 [info ] [MainThread]: [32mCompleted successfully[0m
09:18:03.840046 [info ] [MainThread]: 
09:18:03.841894 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:18:03.842887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C305FC3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C30600CD60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C304B1C0D0>]}


============================== 2022-03-22 09:18:16.455305 | c58e0b34-4c3f-4459-b37a-6656d464d350 ==============================
09:18:16.455305 [info ] [MainThread]: Running with dbt=1.0.3
09:18:16.456305 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:18:16.456378 [debug] [MainThread]: Tracking: tracking
09:18:16.480115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029355BC91C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029355BC9220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029355BC9490>]}
09:18:16.542043 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:18:16.543034 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:18:16.549044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c58e0b34-4c3f-4459-b37a-6656d464d350', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029356D8C0D0>]}
09:18:16.554320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c58e0b34-4c3f-4459-b37a-6656d464d350', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029356D13AF0>]}
09:18:16.554320 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:18:16.556006 [info ] [MainThread]: 
09:18:16.557006 [debug] [MainThread]: Acquiring new postgres connection "master"
09:18:16.559006 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:18:16.573027 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:18:16.573027 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:18:16.573027 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:18:16.628416 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.06 seconds
09:18:16.631523 [debug] [ThreadPool]: On list_recon-cortex: Close
09:18:16.635443 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:18:16.644403 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:18:16.645920 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:18:16.645920 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:18:16.754198 [debug] [ThreadPool]: SQL status: BEGIN in 0.11 seconds
09:18:16.755596 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:18:16.756598 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:18:16.766232 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:18:16.768635 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:18:16.786535 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:18:16.804522 [debug] [MainThread]: Using postgres connection "master"
09:18:16.805274 [debug] [MainThread]: On master: BEGIN
09:18:16.805523 [debug] [MainThread]: Opening a new connection, currently in state init
09:18:16.869169 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
09:18:16.871394 [debug] [MainThread]: Using postgres connection "master"
09:18:16.872565 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:18:17.946934 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
09:18:17.954041 [debug] [MainThread]: On master: ROLLBACK
09:18:17.959289 [debug] [MainThread]: Using postgres connection "master"
09:18:17.960086 [debug] [MainThread]: On master: BEGIN
09:18:17.970680 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:18:17.971685 [debug] [MainThread]: On master: COMMIT
09:18:17.971685 [debug] [MainThread]: Using postgres connection "master"
09:18:17.972683 [debug] [MainThread]: On master: COMMIT
09:18:17.976313 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:18:17.977319 [debug] [MainThread]: On master: Close
09:18:17.978384 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:18:17.980224 [info ] [MainThread]: 
09:18:17.990255 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:18:17.991224 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:18:17.994245 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:18:17.996268 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:18:17.998234 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:18:18.014708 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:18:18.015223 [debug] [Thread-1  ]: finished collecting timing info
09:18:18.016220 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:18:18.092222 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:18.092222 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp144818070220"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.*, fds1.rtgs_utr_no as rtgs_utr_no from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    CASE WHEN agreement_no is not null then 1
    ELSE
     0
    end as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    CASE WHEN rtgs_utr_no is not null then 1
    ELSE
     0
    END as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:18:18.093245 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:18:18.148022 [debug] [Thread-1  ]: SQL status: SELECT 5 in 0.05 seconds
09:18:18.161053 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:18.161053 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:18:18.166665 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
09:18:18.167021 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:18.168021 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp144818070220'
        
      order by ordinal_position

  
09:18:18.179194 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:18:18.189316 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:18.189316 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:18:18.199387 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:18:18.211394 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:18.211394 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:18:18.239252 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.03 seconds
09:18:18.249494 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:18:18.250123 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:18.250123 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp144818070220"
    )
  
09:18:18.256083 [debug] [Thread-1  ]: SQL status: INSERT 0 5 in 0.01 seconds
09:18:18.263218 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:18:18.264237 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:18.264237 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:18:18.272602 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
09:18:18.273844 [debug] [Thread-1  ]: finished collecting timing info
09:18:18.274601 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:18:18.275591 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c58e0b34-4c3f-4459-b37a-6656d464d350', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029356E4E130>]}
09:18:18.276591 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 5[0m in 0.28s]
09:18:18.278610 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:18:18.280590 [debug] [MainThread]: Acquiring new postgres connection "master"
09:18:18.281591 [debug] [MainThread]: Using postgres connection "master"
09:18:18.281591 [debug] [MainThread]: On master: BEGIN
09:18:18.281591 [debug] [MainThread]: Opening a new connection, currently in state closed
09:18:18.346100 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
09:18:18.347047 [debug] [MainThread]: On master: COMMIT
09:18:18.347047 [debug] [MainThread]: Using postgres connection "master"
09:18:18.348048 [debug] [MainThread]: On master: COMMIT
09:18:18.351796 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:18:18.351796 [debug] [MainThread]: On master: Close
09:18:18.352599 [info ] [MainThread]: 
09:18:18.353574 [info ] [MainThread]: Finished running 1 incremental model in 1.80s.
09:18:18.354574 [debug] [MainThread]: Connection 'master' was properly closed.
09:18:18.354574 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:18:18.354574 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:18:18.355573 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:18:18.361576 [info ] [MainThread]: 
09:18:18.362575 [info ] [MainThread]: [32mCompleted successfully[0m
09:18:18.364581 [info ] [MainThread]: 
09:18:18.365577 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:18:18.367574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029356E384F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029356DA7250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029356E00A60>]}


============================== 2022-03-22 09:27:30.435870 | 9350ce1f-2a70-4433-8960-847362019676 ==============================
09:27:30.435870 [info ] [MainThread]: Running with dbt=1.0.3
09:27:30.447743 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:27:30.447743 [debug] [MainThread]: Tracking: tracking
09:27:30.483803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E708AD8B80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E708AD82E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E708AD8310>]}
09:27:30.634033 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:27:30.640790 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:27:30.642823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9350ce1f-2a70-4433-8960-847362019676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E708CCC0D0>]}
09:27:30.650547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9350ce1f-2a70-4433-8960-847362019676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E708C5AAC0>]}
09:27:30.651547 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:27:30.653677 [info ] [MainThread]: 
09:27:30.655151 [debug] [MainThread]: Acquiring new postgres connection "master"
09:27:30.656549 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:27:30.672545 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:27:30.673547 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:27:30.673547 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:27:30.753014 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.08 seconds
09:27:30.754756 [debug] [ThreadPool]: On list_recon-cortex: Close
09:27:30.756728 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:27:30.764723 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:27:30.765647 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:27:30.765721 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:27:30.842712 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
09:27:30.843415 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:27:30.845242 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:27:30.854439 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:27:30.861487 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:27:30.870264 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:27:30.881303 [debug] [MainThread]: Using postgres connection "master"
09:27:30.881303 [debug] [MainThread]: On master: BEGIN
09:27:30.885442 [debug] [MainThread]: Opening a new connection, currently in state init
09:27:31.316920 [debug] [MainThread]: SQL status: BEGIN in 0.43 seconds
09:27:31.318905 [debug] [MainThread]: Using postgres connection "master"
09:27:31.320585 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:27:32.280923 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
09:27:32.284326 [debug] [MainThread]: On master: ROLLBACK
09:27:32.313261 [debug] [MainThread]: Using postgres connection "master"
09:27:32.314340 [debug] [MainThread]: On master: BEGIN
09:27:32.323745 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:27:32.323745 [debug] [MainThread]: On master: COMMIT
09:27:32.324790 [debug] [MainThread]: Using postgres connection "master"
09:27:32.324790 [debug] [MainThread]: On master: COMMIT
09:27:32.353485 [debug] [MainThread]: SQL status: COMMIT in 0.03 seconds
09:27:32.354130 [debug] [MainThread]: On master: Close
09:27:32.354496 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:27:32.355496 [info ] [MainThread]: 
09:27:32.365502 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:27:32.368840 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:27:32.371616 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.371616 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:27:32.372496 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:27:32.383500 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:27:32.387510 [debug] [Thread-1  ]: finished collecting timing info
09:27:32.388502 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:27:32.463495 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.464506 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp145732440531"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.*, fds1.rtgs_utr_no as rtgs_utr_no from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    CASE WHEN agreement_no is not null then 1
    ELSE
     0
    end as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    CASE WHEN rtgs_utr_no is not null then 1
    ELSE
     0
    END as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:27:32.464506 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:27:32.514454 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.05 seconds
09:27:32.524063 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.525065 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:27:32.533736 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
09:27:32.534742 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.534742 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp145732440531'
        
      order by ordinal_position

  
09:27:32.546340 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:27:32.554621 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.554621 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:27:32.564286 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:27:32.577480 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.578468 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:27:32.589312 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:27:32.609122 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:27:32.611123 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.612124 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp145732440531"
    )
  
09:27:32.617575 [debug] [Thread-1  ]: SQL status: INSERT 0 2 in 0.01 seconds
09:27:32.626908 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:27:32.628046 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.628046 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:27:32.635792 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
09:27:32.635792 [debug] [Thread-1  ]: finished collecting timing info
09:27:32.636899 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:27:32.637901 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9350ce1f-2a70-4433-8960-847362019676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E709D5D370>]}
09:27:32.638901 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 2[0m in 0.27s]
09:27:32.639178 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:27:32.641264 [debug] [MainThread]: Acquiring new postgres connection "master"
09:27:32.641264 [debug] [MainThread]: Using postgres connection "master"
09:27:32.642263 [debug] [MainThread]: On master: BEGIN
09:27:32.642715 [debug] [MainThread]: Opening a new connection, currently in state closed
09:27:32.686417 [debug] [MainThread]: SQL status: BEGIN in 0.04 seconds
09:27:32.687373 [debug] [MainThread]: On master: COMMIT
09:27:32.689266 [debug] [MainThread]: Using postgres connection "master"
09:27:32.690265 [debug] [MainThread]: On master: COMMIT
09:27:32.695504 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:27:32.695504 [debug] [MainThread]: On master: Close
09:27:32.696263 [info ] [MainThread]: 
09:27:32.697262 [info ] [MainThread]: Finished running 1 incremental model in 2.04s.
09:27:32.698263 [debug] [MainThread]: Connection 'master' was properly closed.
09:27:32.698263 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:27:32.699262 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:27:32.699262 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:27:32.708266 [info ] [MainThread]: 
09:27:32.709267 [info ] [MainThread]: [32mCompleted successfully[0m
09:27:32.711263 [info ] [MainThread]: 
09:27:32.712289 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:27:32.713264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E709D48550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E709CB7220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E709D0F250>]}


============================== 2022-03-22 09:28:07.828095 | d2686654-fdae-4efd-a80d-1df3130b05ed ==============================
09:28:07.828095 [info ] [MainThread]: Running with dbt=1.0.3
09:28:07.836407 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:28:07.836407 [debug] [MainThread]: Tracking: tracking
09:28:08.565370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAAE7B20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAAE7FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAAE70D0>]}
09:28:08.600581 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:28:08.616172 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:28:08.619561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd2686654-fdae-4efd-a80d-1df3130b05ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BABEB0D0>]}
09:28:08.627244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd2686654-fdae-4efd-a80d-1df3130b05ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAB73B20>]}
09:28:08.627244 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:28:08.630243 [info ] [MainThread]: 
09:28:08.631521 [debug] [MainThread]: Acquiring new postgres connection "master"
09:28:08.633712 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:28:08.638810 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:28:08.638810 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:28:08.644479 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:28:08.719540 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.08 seconds
09:28:08.722536 [debug] [ThreadPool]: On list_recon-cortex: Close
09:28:08.723535 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:28:08.730655 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:28:08.731550 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:28:08.731550 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:28:08.829505 [debug] [ThreadPool]: SQL status: BEGIN in 0.1 seconds
09:28:08.830989 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:28:08.831984 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:28:08.851330 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.02 seconds
09:28:08.854474 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:28:08.864179 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:28:08.875437 [debug] [MainThread]: Using postgres connection "master"
09:28:08.875437 [debug] [MainThread]: On master: BEGIN
09:28:08.881362 [debug] [MainThread]: Opening a new connection, currently in state init
09:28:08.956862 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
09:28:08.960922 [debug] [MainThread]: Using postgres connection "master"
09:28:08.962411 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:28:09.880524 [debug] [MainThread]: SQL status: SELECT 0 in 0.92 seconds
09:28:09.884127 [debug] [MainThread]: On master: ROLLBACK
09:28:09.891692 [debug] [MainThread]: Using postgres connection "master"
09:28:09.899080 [debug] [MainThread]: On master: BEGIN
09:28:09.911128 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:28:09.912178 [debug] [MainThread]: On master: COMMIT
09:28:09.913750 [debug] [MainThread]: Using postgres connection "master"
09:28:09.914798 [debug] [MainThread]: On master: COMMIT
09:28:09.918788 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:28:09.922876 [debug] [MainThread]: On master: Close
09:28:09.925112 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:28:09.928943 [info ] [MainThread]: 
09:28:09.950088 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:28:09.953089 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:28:09.958086 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:28:09.960099 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:28:09.961082 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:28:09.977080 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:28:09.978079 [debug] [Thread-1  ]: finished collecting timing info
09:28:09.978079 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:28:10.043332 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:28:10.044082 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp145810022122"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.*, fds1.rtgs_utr_no as rtgs_utr_no from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    CASE WHEN agreement_no is not null then 1
    ELSE
     0
    end as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    CASE WHEN rtgs_utr_no is not null then 1
    ELSE
     0
    END as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:28:10.044082 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:28:11.121214 [debug] [Thread-1  ]: SQL status: SELECT 2 in 1.08 seconds
09:28:11.136065 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:28:11.136065 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:28:11.153735 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
09:28:11.154833 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:28:11.154833 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp145810022122'
        
      order by ordinal_position

  
09:28:11.166625 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:28:11.173806 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:28:11.173806 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:28:11.490757 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.31 seconds
09:28:11.496528 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:28:11.496528 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:28:11.519328 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.0 seconds
09:28:11.521331 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:28:11.535977 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:28:11.536977 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp145810022122"
    )
  
09:28:11.542525 [debug] [Thread-1  ]: SQL status: INSERT 0 2 in 0.01 seconds
09:28:11.546491 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:28:11.546491 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:28:11.552827 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:28:11.555089 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
09:28:11.561919 [debug] [Thread-1  ]: finished collecting timing info
09:28:11.563002 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:28:11.564040 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2686654-fdae-4efd-a80d-1df3130b05ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAC985E0>]}
09:28:11.564040 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 2[0m in 1.61s]
09:28:11.566000 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:28:11.569003 [debug] [MainThread]: Acquiring new postgres connection "master"
09:28:11.569609 [debug] [MainThread]: Using postgres connection "master"
09:28:11.570002 [debug] [MainThread]: On master: BEGIN
09:28:11.570002 [debug] [MainThread]: Opening a new connection, currently in state closed
09:28:11.616590 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
09:28:11.618092 [debug] [MainThread]: On master: COMMIT
09:28:11.618571 [debug] [MainThread]: Using postgres connection "master"
09:28:11.618571 [debug] [MainThread]: On master: COMMIT
09:28:11.624812 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
09:28:11.625830 [debug] [MainThread]: On master: Close
09:28:11.626828 [info ] [MainThread]: 
09:28:11.626828 [info ] [MainThread]: Finished running 1 incremental model in 3.00s.
09:28:11.630831 [debug] [MainThread]: Connection 'master' was properly closed.
09:28:11.631832 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:28:11.632835 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:28:11.633927 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:28:11.640829 [info ] [MainThread]: 
09:28:11.642262 [info ] [MainThread]: [32mCompleted successfully[0m
09:28:11.643851 [info ] [MainThread]: 
09:28:11.644852 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:28:11.648828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAB735B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAC07580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAC5FC70>]}


============================== 2022-03-29 18:34:03.789902 | 1dc7392b-8860-4812-9efc-0369286cf6eb ==============================
18:34:03.789902 [info ] [MainThread]: Running with dbt=1.0.3
18:34:03.812262 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:34:03.826079 [debug] [MainThread]: Tracking: tracking
18:34:03.863331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A72F60C700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A72F60CEB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A72F60C5B0>]}
18:34:03.917139 [info ] [MainThread]: Unable to do partial parsing because profile has changed
18:34:03.922798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1dc7392b-8860-4812-9efc-0369286cf6eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A72E607490>]}
18:34:04.029666 [debug] [MainThread]: Parsing macros\adapters.sql
18:34:04.065852 [debug] [MainThread]: Parsing macros\catalog.sql
18:34:04.069213 [debug] [MainThread]: Parsing macros\relations.sql
18:34:04.073028 [debug] [MainThread]: Parsing macros\materializations\snapshot_merge.sql
18:34:04.075284 [debug] [MainThread]: Parsing macros\adapters\columns.sql
18:34:04.094581 [debug] [MainThread]: Parsing macros\adapters\freshness.sql
18:34:04.094581 [debug] [MainThread]: Parsing macros\adapters\indexes.sql
18:34:04.111374 [debug] [MainThread]: Parsing macros\adapters\metadata.sql
18:34:04.111374 [debug] [MainThread]: Parsing macros\adapters\persist_docs.sql
18:34:04.127142 [debug] [MainThread]: Parsing macros\adapters\relation.sql
18:34:04.127142 [debug] [MainThread]: Parsing macros\adapters\schema.sql
18:34:04.127142 [debug] [MainThread]: Parsing macros\etc\datetime.sql
18:34:04.145395 [debug] [MainThread]: Parsing macros\etc\statement.sql
18:34:04.145395 [debug] [MainThread]: Parsing macros\generic_test_sql\accepted_values.sql
18:34:04.145395 [debug] [MainThread]: Parsing macros\generic_test_sql\not_null.sql
18:34:04.155123 [debug] [MainThread]: Parsing macros\generic_test_sql\relationships.sql
18:34:04.156149 [debug] [MainThread]: Parsing macros\generic_test_sql\unique.sql
18:34:04.156928 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_alias.sql
18:34:04.157911 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_database.sql
18:34:04.160278 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_schema.sql
18:34:04.163165 [debug] [MainThread]: Parsing macros\materializations\configs.sql
18:34:04.165775 [debug] [MainThread]: Parsing macros\materializations\hooks.sql
18:34:04.168126 [debug] [MainThread]: Parsing macros\materializations\models\incremental\column_helpers.sql
18:34:04.168126 [debug] [MainThread]: Parsing macros\materializations\models\incremental\incremental.sql
18:34:04.177418 [debug] [MainThread]: Parsing macros\materializations\models\incremental\is_incremental.sql
18:34:04.177418 [debug] [MainThread]: Parsing macros\materializations\models\incremental\merge.sql
18:34:04.186652 [debug] [MainThread]: Parsing macros\materializations\models\incremental\on_schema_change.sql
18:34:04.218028 [debug] [MainThread]: Parsing macros\materializations\models\table\create_table_as.sql
18:34:04.222481 [debug] [MainThread]: Parsing macros\materializations\models\table\table.sql
18:34:04.227609 [debug] [MainThread]: Parsing macros\materializations\models\view\create_or_replace_view.sql
18:34:04.239094 [debug] [MainThread]: Parsing macros\materializations\models\view\create_view_as.sql
18:34:04.242695 [debug] [MainThread]: Parsing macros\materializations\models\view\helpers.sql
18:34:04.261535 [debug] [MainThread]: Parsing macros\materializations\models\view\view.sql
18:34:04.296270 [debug] [MainThread]: Parsing macros\materializations\seeds\helpers.sql
18:34:04.317034 [debug] [MainThread]: Parsing macros\materializations\seeds\seed.sql
18:34:04.332620 [debug] [MainThread]: Parsing macros\materializations\snapshots\helpers.sql
18:34:04.339684 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot.sql
18:34:04.339684 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot_merge.sql
18:34:04.357059 [debug] [MainThread]: Parsing macros\materializations\snapshots\strategies.sql
18:34:04.359451 [debug] [MainThread]: Parsing macros\materializations\tests\helpers.sql
18:34:04.373853 [debug] [MainThread]: Parsing macros\materializations\tests\test.sql
18:34:04.375830 [debug] [MainThread]: Parsing macros\materializations\tests\where_subquery.sql
18:34:04.380530 [debug] [MainThread]: Parsing tests\generic\builtin.sql
18:34:04.580743 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
18:34:04.598119 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
18:34:04.634353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1dc7392b-8860-4812-9efc-0369286cf6eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A72F73AF40>]}
18:34:04.687583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1dc7392b-8860-4812-9efc-0369286cf6eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A72F73AAF0>]}
18:34:04.689111 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:34:04.693514 [info ] [MainThread]: 
18:34:04.694301 [debug] [MainThread]: Acquiring new postgres connection "master"
18:34:04.697281 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:34:04.709129 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:34:04.709129 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:34:04.712877 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:34:04.772827 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.06 seconds
18:34:04.777534 [debug] [ThreadPool]: On list_recon-cortex: Close
18:34:04.781377 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:34:04.794803 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:34:04.798172 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:34:04.798172 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:34:04.870387 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
18:34:04.875156 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:34:04.876162 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:34:04.885396 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
18:34:04.888033 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:34:04.893884 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:34:04.905153 [debug] [MainThread]: Using postgres connection "master"
18:34:04.905153 [debug] [MainThread]: On master: BEGIN
18:34:04.909949 [debug] [MainThread]: Opening a new connection, currently in state init
18:34:05.003694 [debug] [MainThread]: SQL status: BEGIN in 0.09 seconds
18:34:05.005515 [debug] [MainThread]: Using postgres connection "master"
18:34:05.006917 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:34:06.049677 [debug] [MainThread]: SQL status: SELECT 0 in 1.04 seconds
18:34:06.060904 [debug] [MainThread]: On master: ROLLBACK
18:34:06.065730 [debug] [MainThread]: Using postgres connection "master"
18:34:06.070626 [debug] [MainThread]: On master: BEGIN
18:34:06.133350 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
18:34:06.134362 [debug] [MainThread]: On master: COMMIT
18:34:06.136349 [debug] [MainThread]: Using postgres connection "master"
18:34:06.136796 [debug] [MainThread]: On master: COMMIT
18:34:06.144550 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
18:34:06.146383 [debug] [MainThread]: On master: Close
18:34:06.148917 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:34:06.152158 [info ] [MainThread]: 
18:34:06.168695 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:34:06.170694 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:34:06.174019 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:34:06.175018 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:34:06.176048 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:34:06.189340 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:34:06.189800 [debug] [Thread-1  ]: finished collecting timing info
18:34:06.189800 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:34:06.268769 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:34:06.269830 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp000406243114"
  as (
    


with filter_data_source_1 as (
    select s.*
    right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),
filter_data_source_2 as (
    select s.*, null as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_ref_file fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(s."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(s."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(s."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s 
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:34:06.270912 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:34:06.314439 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "right"
LINE 12:     right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_a...
             ^

18:34:06.315442 [debug] [Thread-1  ]: finished collecting timing info
18:34:06.315442 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:34:06.317440 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  syntax error at or near "right"
  LINE 12:     right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_a...
               ^
18:34:06.317440 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1dc7392b-8860-4812-9efc-0369286cf6eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A72F6836D0>]}
18:34:06.318439 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.14s]
18:34:06.320444 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:34:06.322443 [debug] [MainThread]: Acquiring new postgres connection "master"
18:34:06.322443 [debug] [MainThread]: Using postgres connection "master"
18:34:06.323481 [debug] [MainThread]: On master: BEGIN
18:34:06.323843 [debug] [MainThread]: Opening a new connection, currently in state closed
18:34:06.380289 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
18:34:06.381127 [debug] [MainThread]: On master: COMMIT
18:34:06.383124 [debug] [MainThread]: Using postgres connection "master"
18:34:06.384426 [debug] [MainThread]: On master: COMMIT
18:34:06.388677 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:34:06.389679 [debug] [MainThread]: On master: Close
18:34:06.390679 [info ] [MainThread]: 
18:34:06.391677 [info ] [MainThread]: Finished running 1 incremental model in 1.70s.
18:34:06.392708 [debug] [MainThread]: Connection 'master' was properly closed.
18:34:06.393710 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:34:06.395711 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:34:06.396371 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:34:06.410042 [info ] [MainThread]: 
18:34:06.411856 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
18:34:06.415853 [info ] [MainThread]: 
18:34:06.416864 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
18:34:06.419857 [error] [MainThread]:   syntax error at or near "right"
18:34:06.421884 [error] [MainThread]:   LINE 12:     right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_a...
18:34:06.423855 [error] [MainThread]:                ^
18:34:06.424929 [info ] [MainThread]: 
18:34:06.426933 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
18:34:06.430451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A72F7559A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A72F7558B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A72F73A280>]}


============================== 2022-03-29 18:34:27.086575 | e40dc2fa-a63e-47f4-8ec1-5be38472ccdd ==============================
18:34:27.086575 [info ] [MainThread]: Running with dbt=1.0.3
18:34:27.097200 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:34:27.097200 [debug] [MainThread]: Tracking: tracking
18:34:27.128804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021DA44CC280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021DA44CC970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021DA44CC1F0>]}
18:34:27.183799 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
18:34:27.183799 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
18:34:27.190231 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
18:34:27.208485 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
18:34:27.236224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e40dc2fa-a63e-47f4-8ec1-5be38472ccdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021DA46260D0>]}
18:34:27.244955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e40dc2fa-a63e-47f4-8ec1-5be38472ccdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021DA45936D0>]}
18:34:27.244955 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:34:27.247452 [info ] [MainThread]: 
18:34:27.248162 [debug] [MainThread]: Acquiring new postgres connection "master"
18:34:27.250164 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:34:27.259797 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:34:27.259797 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:34:27.263495 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:34:27.350734 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.09 seconds
18:34:27.359413 [debug] [ThreadPool]: On list_recon-cortex: Close
18:34:27.365466 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:34:27.383923 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:34:27.383923 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:34:27.389676 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:34:27.460829 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
18:34:27.462627 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:34:27.463905 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:34:27.473191 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
18:34:27.485005 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:34:27.491954 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:34:27.533636 [debug] [MainThread]: Using postgres connection "master"
18:34:27.533636 [debug] [MainThread]: On master: BEGIN
18:34:27.537162 [debug] [MainThread]: Opening a new connection, currently in state init
18:34:27.609588 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
18:34:27.611663 [debug] [MainThread]: Using postgres connection "master"
18:34:27.612601 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:34:28.556370 [debug] [MainThread]: SQL status: SELECT 0 in 0.94 seconds
18:34:28.565777 [debug] [MainThread]: On master: ROLLBACK
18:34:28.569995 [debug] [MainThread]: Using postgres connection "master"
18:34:28.575087 [debug] [MainThread]: On master: BEGIN
18:34:28.587158 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
18:34:28.589143 [debug] [MainThread]: On master: COMMIT
18:34:28.590139 [debug] [MainThread]: Using postgres connection "master"
18:34:28.591451 [debug] [MainThread]: On master: COMMIT
18:34:28.594128 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:34:28.597386 [debug] [MainThread]: On master: Close
18:34:28.597386 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:34:28.598419 [info ] [MainThread]: 
18:34:28.608554 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:34:28.609871 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:34:28.612665 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:34:28.613666 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:34:28.614678 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:34:28.622191 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:34:28.627924 [debug] [Thread-1  ]: finished collecting timing info
18:34:28.628924 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:34:28.681741 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:34:28.682437 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp000428662792"
  as (
    


with filter_data_source_1 as (
    select s.*,
    right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),
filter_data_source_2 as (
    select s.*, null as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_ref_file fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(s."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(s."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(s."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s 
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:34:28.682437 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:34:28.727933 [debug] [Thread-1  ]: Postgres adapter: Postgres error: missing FROM-clause entry for table "fds2"
LINE 32:     select fds2.*,  trim(regexp_replace(split_part(s."txt_tx...
                    ^

18:34:28.729001 [debug] [Thread-1  ]: finished collecting timing info
18:34:28.729001 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:34:28.731001 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  missing FROM-clause entry for table "fds2"
  LINE 32:     select fds2.*,  trim(regexp_replace(split_part(s."txt_tx...
                      ^
18:34:28.731550 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e40dc2fa-a63e-47f4-8ec1-5be38472ccdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021DA45F8280>]}
18:34:28.731550 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.12s]
18:34:28.733554 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:34:28.735551 [debug] [MainThread]: Acquiring new postgres connection "master"
18:34:28.735998 [debug] [MainThread]: Using postgres connection "master"
18:34:28.736553 [debug] [MainThread]: On master: BEGIN
18:34:28.736553 [debug] [MainThread]: Opening a new connection, currently in state closed
18:34:28.801751 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
18:34:28.801751 [debug] [MainThread]: On master: COMMIT
18:34:28.802753 [debug] [MainThread]: Using postgres connection "master"
18:34:28.802753 [debug] [MainThread]: On master: COMMIT
18:34:28.807105 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:34:28.808111 [debug] [MainThread]: On master: Close
18:34:28.809129 [info ] [MainThread]: 
18:34:28.810110 [info ] [MainThread]: Finished running 1 incremental model in 1.56s.
18:34:28.811108 [debug] [MainThread]: Connection 'master' was properly closed.
18:34:28.811108 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:34:28.812108 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:34:28.812108 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:34:28.819327 [info ] [MainThread]: 
18:34:28.820325 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
18:34:28.822321 [info ] [MainThread]: 
18:34:28.822583 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
18:34:28.824583 [error] [MainThread]:   missing FROM-clause entry for table "fds2"
18:34:28.826647 [error] [MainThread]:   LINE 32:     select fds2.*,  trim(regexp_replace(split_part(s."txt_tx...
18:34:28.827650 [error] [MainThread]:                       ^
18:34:28.828648 [info ] [MainThread]: 
18:34:28.830757 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
18:34:28.831764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021DA44B7100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021DA4668430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021DA44A7AC0>]}


============================== 2022-03-29 18:35:37.306692 | d2a80af1-7a68-4560-bc82-3d402113aaa5 ==============================
18:35:37.306692 [info ] [MainThread]: Running with dbt=1.0.3
18:35:37.316829 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:35:37.316829 [debug] [MainThread]: Tracking: tracking
18:35:37.344682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0CF82F640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0CF82F580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0CF82F5B0>]}
18:35:37.401264 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
18:35:37.404641 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
18:35:37.406673 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
18:35:37.419429 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
18:35:37.446058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd2a80af1-7a68-4560-bc82-3d402113aaa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0D09570D0>]}
18:35:37.453915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd2a80af1-7a68-4560-bc82-3d402113aaa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0D08C34F0>]}
18:35:37.453915 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:35:37.456876 [info ] [MainThread]: 
18:35:37.457905 [debug] [MainThread]: Acquiring new postgres connection "master"
18:35:37.459908 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:35:37.470216 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:35:37.471220 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:35:37.471220 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:35:37.551495 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.08 seconds
18:35:37.553838 [debug] [ThreadPool]: On list_recon-cortex: Close
18:35:37.558489 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:35:37.572070 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:35:37.572070 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:35:37.576557 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:35:37.650428 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
18:35:37.654274 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:35:37.655321 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:35:37.780701 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.12 seconds
18:35:37.783544 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:35:37.793009 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:35:37.859445 [debug] [MainThread]: Using postgres connection "master"
18:35:37.859445 [debug] [MainThread]: On master: BEGIN
18:35:37.860442 [debug] [MainThread]: Opening a new connection, currently in state init
18:35:37.915745 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
18:35:37.917516 [debug] [MainThread]: Using postgres connection "master"
18:35:37.918514 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:35:38.865629 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
18:35:38.873839 [debug] [MainThread]: On master: ROLLBACK
18:35:38.877964 [debug] [MainThread]: Using postgres connection "master"
18:35:38.877964 [debug] [MainThread]: On master: BEGIN
18:35:38.890589 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
18:35:38.896342 [debug] [MainThread]: On master: COMMIT
18:35:38.896342 [debug] [MainThread]: Using postgres connection "master"
18:35:38.897487 [debug] [MainThread]: On master: COMMIT
18:35:38.900728 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:35:38.906126 [debug] [MainThread]: On master: Close
18:35:38.908293 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:35:38.911049 [info ] [MainThread]: 
18:35:38.928853 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:35:38.929855 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:35:38.932849 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:35:38.933849 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:35:38.934856 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:35:38.973460 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:35:38.981756 [debug] [Thread-1  ]: finished collecting timing info
18:35:38.982987 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:35:39.031227 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:35:39.031227 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp000539024531"
  as (
    


with filter_data_source_1 as (
    select s.*,
    right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),
filter_data_source_2 as (
    select s.*, null as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_ref_file fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(s."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(s."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(s."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s 
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:35:39.043859 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:35:39.110334 [debug] [Thread-1  ]: Postgres adapter: Postgres error: missing FROM-clause entry for table "s"
LINE 32: ...   select fds2.*,  trim(regexp_replace(split_part(s."txt_txn...
                                                              ^

18:35:39.111330 [debug] [Thread-1  ]: finished collecting timing info
18:35:39.112338 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:35:39.112789 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  missing FROM-clause entry for table "s"
  LINE 32: ...   select fds2.*,  trim(regexp_replace(split_part(s."txt_txn...
                                                                ^
18:35:39.113824 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2a80af1-7a68-4560-bc82-3d402113aaa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0D08DB880>]}
18:35:39.114798 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.18s]
18:35:39.115787 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:35:39.117787 [debug] [MainThread]: Acquiring new postgres connection "master"
18:35:39.118801 [debug] [MainThread]: Using postgres connection "master"
18:35:39.119295 [debug] [MainThread]: On master: BEGIN
18:35:39.119295 [debug] [MainThread]: Opening a new connection, currently in state closed
18:35:39.167440 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
18:35:39.168441 [debug] [MainThread]: On master: COMMIT
18:35:39.169448 [debug] [MainThread]: Using postgres connection "master"
18:35:39.170486 [debug] [MainThread]: On master: COMMIT
18:35:39.176294 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:35:39.177615 [debug] [MainThread]: On master: Close
18:35:39.178616 [info ] [MainThread]: 
18:35:39.179615 [info ] [MainThread]: Finished running 1 incremental model in 1.72s.
18:35:39.181616 [debug] [MainThread]: Connection 'master' was properly closed.
18:35:39.183620 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:35:39.184621 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:35:39.184621 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:35:39.192648 [info ] [MainThread]: 
18:35:39.194650 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
18:35:39.199147 [info ] [MainThread]: 
18:35:39.201178 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
18:35:39.203151 [error] [MainThread]:   missing FROM-clause entry for table "s"
18:35:39.205150 [error] [MainThread]:   LINE 32: ...   select fds2.*,  trim(regexp_replace(split_part(s."txt_txn...
18:35:39.206223 [error] [MainThread]:                                                                 ^
18:35:39.208981 [info ] [MainThread]: 
18:35:39.211095 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
18:35:39.215699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0D08C3490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0D0997220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0CF8283D0>]}


============================== 2022-03-29 18:36:06.704069 | 7e1c708a-e3e7-4bbd-a711-ba865cc9922c ==============================
18:36:06.704069 [info ] [MainThread]: Running with dbt=1.0.3
18:36:06.713595 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:36:06.713595 [debug] [MainThread]: Tracking: tracking
18:36:06.745413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002553DFACC40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002553DFAC8B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002553DFAC610>]}
18:36:06.802131 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
18:36:06.802131 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
18:36:06.811365 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
18:36:06.817469 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
18:36:06.844407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7e1c708a-e3e7-4bbd-a711-ba865cc9922c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002553E1080D0>]}
18:36:06.850901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7e1c708a-e3e7-4bbd-a711-ba865cc9922c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002553CFC40D0>]}
18:36:06.851890 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:36:06.853898 [info ] [MainThread]: 
18:36:06.854890 [debug] [MainThread]: Acquiring new postgres connection "master"
18:36:06.856891 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:36:06.862512 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:36:06.862512 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:36:06.869395 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:36:06.960857 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.09 seconds
18:36:06.963797 [debug] [ThreadPool]: On list_recon-cortex: Close
18:36:06.971567 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:36:06.992234 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:36:06.993230 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:36:06.994230 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:36:07.077222 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
18:36:07.078265 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:36:07.079788 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:36:07.090450 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
18:36:07.092422 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:36:07.102913 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:36:07.158418 [debug] [MainThread]: Using postgres connection "master"
18:36:07.158418 [debug] [MainThread]: On master: BEGIN
18:36:07.165440 [debug] [MainThread]: Opening a new connection, currently in state init
18:36:07.243179 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
18:36:07.244980 [debug] [MainThread]: Using postgres connection "master"
18:36:07.246074 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:36:08.191376 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
18:36:08.199535 [debug] [MainThread]: On master: ROLLBACK
18:36:08.204430 [debug] [MainThread]: Using postgres connection "master"
18:36:08.204430 [debug] [MainThread]: On master: BEGIN
18:36:08.224287 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
18:36:08.226235 [debug] [MainThread]: On master: COMMIT
18:36:08.227232 [debug] [MainThread]: Using postgres connection "master"
18:36:08.228423 [debug] [MainThread]: On master: COMMIT
18:36:08.230798 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:36:08.235359 [debug] [MainThread]: On master: Close
18:36:08.237357 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:36:08.240161 [info ] [MainThread]: 
18:36:08.264454 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:36:08.267286 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:36:08.270519 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:36:08.272821 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:36:08.275337 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:36:08.294351 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:36:08.295126 [debug] [Thread-1  ]: finished collecting timing info
18:36:08.296124 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:36:08.361495 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:36:08.361495 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp000608344842"
  as (
    


with filter_data_source_1 as (
    select s.*,
    right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),
filter_data_source_2 as (
    select s.*, null as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_ref_file fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s 
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:36:08.405649 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:36:08.497585 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.09 seconds
18:36:08.510186 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:36:08.511183 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
18:36:08.518450 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
18:36:08.519358 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:36:08.519358 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp000608344842'
        
      order by ordinal_position

  
18:36:08.543166 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.02 seconds
18:36:08.546801 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:36:08.546801 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
18:36:08.567306 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.02 seconds
18:36:08.575832 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:36:08.575832 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
18:36:08.587523 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
18:36:08.588556 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
18:36:08.598442 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:36:08.599444 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp000608344842"
    )
  
18:36:08.605928 [debug] [Thread-1  ]: SQL status: INSERT 0 2 in 0.01 seconds
18:36:08.607946 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
18:36:08.607946 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:36:08.613711 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
18:36:08.624221 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
18:36:08.626060 [debug] [Thread-1  ]: finished collecting timing info
18:36:08.627344 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:36:08.628864 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e1c708a-e3e7-4bbd-a711-ba865cc9922c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002553E0ED700>]}
18:36:08.629869 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 2[0m in 0.36s]
18:36:08.631906 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:36:08.635959 [debug] [MainThread]: Acquiring new postgres connection "master"
18:36:08.636914 [debug] [MainThread]: Using postgres connection "master"
18:36:08.636914 [debug] [MainThread]: On master: BEGIN
18:36:08.637911 [debug] [MainThread]: Opening a new connection, currently in state closed
18:36:08.711696 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
18:36:08.712023 [debug] [MainThread]: On master: COMMIT
18:36:08.713420 [debug] [MainThread]: Using postgres connection "master"
18:36:08.713420 [debug] [MainThread]: On master: COMMIT
18:36:08.723789 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
18:36:08.724897 [debug] [MainThread]: On master: Close
18:36:08.726657 [info ] [MainThread]: 
18:36:08.728311 [info ] [MainThread]: Finished running 1 incremental model in 1.87s.
18:36:08.730478 [debug] [MainThread]: Connection 'master' was properly closed.
18:36:08.731865 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:36:08.732728 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:36:08.732728 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:36:08.749127 [info ] [MainThread]: 
18:36:08.750506 [info ] [MainThread]: [32mCompleted successfully[0m
18:36:08.753809 [info ] [MainThread]: 
18:36:08.755811 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
18:36:08.760106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002553DFA4FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002553DFA4C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002553CFAF7F0>]}


============================== 2022-03-29 18:37:27.036454 | 6c0f3cbe-f1ea-4fbc-ac82-ff082c6e8200 ==============================
18:37:27.036454 [info ] [MainThread]: Running with dbt=1.0.3
18:37:27.039346 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:37:27.039346 [debug] [MainThread]: Tracking: tracking
18:37:27.065134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011235FEC6D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011235FECC40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011235FEC5E0>]}
18:37:27.122210 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
18:37:27.122210 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
18:37:27.127273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6c0f3cbe-f1ea-4fbc-ac82-ff082c6e8200', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000112360DC0D0>]}
18:37:27.135777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6c0f3cbe-f1ea-4fbc-ac82-ff082c6e8200', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011236020BB0>]}
18:37:27.136777 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:37:27.138781 [info ] [MainThread]: 
18:37:27.139816 [debug] [MainThread]: Acquiring new postgres connection "master"
18:37:27.141823 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:37:27.148172 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:37:27.148172 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:37:27.155490 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:37:27.220958 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.07 seconds
18:37:27.228008 [debug] [ThreadPool]: On list_recon-cortex: Close
18:37:27.233688 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:37:27.244897 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:37:27.244897 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:37:27.251413 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:37:27.315228 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
18:37:27.316276 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:37:27.317288 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:37:27.327427 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
18:37:27.329442 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:37:27.339598 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:37:27.351162 [debug] [MainThread]: Using postgres connection "master"
18:37:27.351162 [debug] [MainThread]: On master: BEGIN
18:37:27.360901 [debug] [MainThread]: Opening a new connection, currently in state init
18:37:27.436272 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
18:37:27.438028 [debug] [MainThread]: Using postgres connection "master"
18:37:27.439073 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:37:28.389965 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
18:37:28.392570 [debug] [MainThread]: On master: ROLLBACK
18:37:28.398873 [debug] [MainThread]: Using postgres connection "master"
18:37:28.398873 [debug] [MainThread]: On master: BEGIN
18:37:28.432332 [debug] [MainThread]: SQL status: BEGIN in 0.03 seconds
18:37:28.437284 [debug] [MainThread]: On master: COMMIT
18:37:28.438753 [debug] [MainThread]: Using postgres connection "master"
18:37:28.440253 [debug] [MainThread]: On master: COMMIT
18:37:28.442437 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:37:28.447479 [debug] [MainThread]: On master: Close
18:37:28.449232 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:37:28.452174 [info ] [MainThread]: 
18:37:28.477388 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:37:28.481054 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:37:28.484136 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:37:28.485140 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:37:28.485140 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:37:28.500453 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:37:28.505448 [debug] [Thread-1  ]: finished collecting timing info
18:37:28.529710 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:37:28.600911 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:37:28.601786 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp000728575944"
  as (
    


with filter_data_source_1 as (
    select s.*,
    right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),
filter_data_source_2 as (
    select s.*, null as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_ref_file fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s 
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:37:28.601786 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:37:28.661777 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.06 seconds
18:37:28.666518 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:37:28.672359 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
18:37:28.676750 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
18:37:28.676750 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:37:28.677801 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp000728575944'
        
      order by ordinal_position

  
18:37:28.689188 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
18:37:28.739274 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:37:28.739274 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
18:37:28.748404 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
18:37:28.761070 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:37:28.761070 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
18:37:28.765990 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.0 seconds
18:37:28.783214 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
18:37:28.784205 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:37:28.785214 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp000728575944"
    )
  
18:37:28.791499 [debug] [Thread-1  ]: SQL status: INSERT 0 2 in 0.01 seconds
18:37:28.794542 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
18:37:28.794542 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:37:28.794542 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
18:37:28.801234 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
18:37:28.807161 [debug] [Thread-1  ]: finished collecting timing info
18:37:28.807161 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:37:28.808158 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c0f3cbe-f1ea-4fbc-ac82-ff082c6e8200', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000112361A83A0>]}
18:37:28.809159 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 2[0m in 0.32s]
18:37:28.810157 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:37:28.812159 [debug] [MainThread]: Acquiring new postgres connection "master"
18:37:28.812159 [debug] [MainThread]: Using postgres connection "master"
18:37:28.813314 [debug] [MainThread]: On master: BEGIN
18:37:28.813314 [debug] [MainThread]: Opening a new connection, currently in state closed
18:37:28.867086 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
18:37:28.868095 [debug] [MainThread]: On master: COMMIT
18:37:28.870086 [debug] [MainThread]: Using postgres connection "master"
18:37:28.870320 [debug] [MainThread]: On master: COMMIT
18:37:28.876673 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:37:28.878136 [debug] [MainThread]: On master: Close
18:37:28.880857 [info ] [MainThread]: 
18:37:28.883337 [info ] [MainThread]: Finished running 1 incremental model in 1.74s.
18:37:28.885617 [debug] [MainThread]: Connection 'master' was properly closed.
18:37:28.886619 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:37:28.887618 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:37:28.888709 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:37:28.905829 [info ] [MainThread]: 
18:37:28.909099 [info ] [MainThread]: [32mCompleted successfully[0m
18:37:28.913338 [info ] [MainThread]: 
18:37:28.915314 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
18:37:28.917356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000112361729A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011236172B20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011236172FD0>]}


============================== 2022-03-29 18:50:53.017461 | 9889b89c-0b11-4115-9dff-5c1466471bea ==============================
18:50:53.017461 [info ] [MainThread]: Running with dbt=1.0.3
18:50:53.021131 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:50:53.021131 [debug] [MainThread]: Tracking: tracking
18:50:53.052806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A5F54963D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A5F5496760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A5F54966D0>]}
18:50:53.100148 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
18:50:53.106179 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
18:50:53.114449 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
18:50:53.135159 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
18:50:53.148934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9889b89c-0b11-4115-9dff-5c1466471bea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A5F65F70D0>]}
18:50:53.154812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9889b89c-0b11-4115-9dff-5c1466471bea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A5F6563070>]}
18:50:53.155815 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:50:53.158059 [info ] [MainThread]: 
18:50:53.158812 [debug] [MainThread]: Acquiring new postgres connection "master"
18:50:53.161817 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:50:53.175344 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:50:53.176355 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:50:53.177408 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:50:53.274450 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.1 seconds
18:50:53.280464 [debug] [ThreadPool]: On list_recon-cortex: Close
18:50:53.286269 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:50:53.308118 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:50:53.313285 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:50:53.313285 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:50:53.383710 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
18:50:53.390494 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:50:53.392503 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:50:53.401690 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
18:50:53.403941 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:50:53.412974 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:50:53.471754 [debug] [MainThread]: Using postgres connection "master"
18:50:53.472758 [debug] [MainThread]: On master: BEGIN
18:50:53.473227 [debug] [MainThread]: Opening a new connection, currently in state init
18:50:53.546089 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
18:50:53.547861 [debug] [MainThread]: Using postgres connection "master"
18:50:53.548953 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:50:54.496324 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
18:50:54.498846 [debug] [MainThread]: On master: ROLLBACK
18:50:54.503072 [debug] [MainThread]: Using postgres connection "master"
18:50:54.507670 [debug] [MainThread]: On master: BEGIN
18:50:54.519560 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
18:50:54.521304 [debug] [MainThread]: On master: COMMIT
18:50:54.522617 [debug] [MainThread]: Using postgres connection "master"
18:50:54.523608 [debug] [MainThread]: On master: COMMIT
18:50:54.527272 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:50:54.530424 [debug] [MainThread]: On master: Close
18:50:54.530424 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:50:54.531913 [info ] [MainThread]: 
18:50:54.538941 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:50:54.540033 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:50:54.541032 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:50:54.541451 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:50:54.541451 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:50:54.552059 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:50:54.553342 [debug] [Thread-1  ]: finished collecting timing info
18:50:54.553342 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:50:54.607815 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:50:54.608850 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp002054586509"
  as (
    


with filter_data_source_1 as (
    select s.*,
    right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.*, null as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_ref_file fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and s.txt_txn_desc like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s 
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:50:54.608850 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:50:54.693472 [debug] [Thread-1  ]: Postgres adapter: Postgres error: missing FROM-clause entry for table "s"
LINE 30:     and s.txt_txn_desc like 'RTGS%'
                 ^

18:50:54.694745 [debug] [Thread-1  ]: finished collecting timing info
18:50:54.695984 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:50:54.697621 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  missing FROM-clause entry for table "s"
  LINE 30:     and s.txt_txn_desc like 'RTGS%'
                   ^
18:50:54.698621 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9889b89c-0b11-4115-9dff-5c1466471bea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A5F65F7580>]}
18:50:54.699620 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.16s]
18:50:54.703093 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:50:54.706765 [debug] [MainThread]: Acquiring new postgres connection "master"
18:50:54.707774 [debug] [MainThread]: Using postgres connection "master"
18:50:54.707774 [debug] [MainThread]: On master: BEGIN
18:50:54.709037 [debug] [MainThread]: Opening a new connection, currently in state closed
18:50:54.773603 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
18:50:54.774607 [debug] [MainThread]: On master: COMMIT
18:50:54.776541 [debug] [MainThread]: Using postgres connection "master"
18:50:54.777542 [debug] [MainThread]: On master: COMMIT
18:50:54.782295 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:50:54.783337 [debug] [MainThread]: On master: Close
18:50:54.784167 [info ] [MainThread]: 
18:50:54.786665 [info ] [MainThread]: Finished running 1 incremental model in 1.63s.
18:50:54.787638 [debug] [MainThread]: Connection 'master' was properly closed.
18:50:54.788647 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:50:54.789695 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:50:54.790638 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:50:54.801070 [info ] [MainThread]: 
18:50:54.804322 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
18:50:54.806323 [info ] [MainThread]: 
18:50:54.808326 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
18:50:54.810951 [error] [MainThread]:   missing FROM-clause entry for table "s"
18:50:54.811952 [error] [MainThread]:   LINE 30:     and s.txt_txn_desc like 'RTGS%'
18:50:54.812949 [error] [MainThread]:                    ^
18:50:54.814978 [info ] [MainThread]: 
18:50:54.816015 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
18:50:54.817030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A5F6638310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A5F66385E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A5F5482DC0>]}


============================== 2022-03-29 18:51:12.483612 | 6679ad67-5b22-4a83-95cc-15b10de88db9 ==============================
18:51:12.483612 [info ] [MainThread]: Running with dbt=1.0.3
18:51:12.485553 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:51:12.485553 [debug] [MainThread]: Tracking: tracking
18:51:12.513975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015143959370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001514396C640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001514396C5B0>]}
18:51:12.566894 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
18:51:12.572487 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
18:51:12.581574 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
18:51:12.601017 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
18:51:12.618615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6679ad67-5b22-4a83-95cc-15b10de88db9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015143AC80D0>]}
18:51:12.626160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6679ad67-5b22-4a83-95cc-15b10de88db9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000151439634F0>]}
18:51:12.626160 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:51:12.629160 [info ] [MainThread]: 
18:51:12.630407 [debug] [MainThread]: Acquiring new postgres connection "master"
18:51:12.632414 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:51:12.649258 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:51:12.650548 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:51:12.650548 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:51:12.719027 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.07 seconds
18:51:12.725664 [debug] [ThreadPool]: On list_recon-cortex: Close
18:51:12.730680 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:51:12.739233 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:51:12.749198 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:51:12.749198 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:51:12.824641 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
18:51:12.828009 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:51:12.828009 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:51:12.841146 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
18:51:12.841146 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:51:12.850945 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:51:12.901011 [debug] [MainThread]: Using postgres connection "master"
18:51:12.908178 [debug] [MainThread]: On master: BEGIN
18:51:12.908178 [debug] [MainThread]: Opening a new connection, currently in state init
18:51:12.999280 [debug] [MainThread]: SQL status: BEGIN in 0.09 seconds
18:51:13.001223 [debug] [MainThread]: Using postgres connection "master"
18:51:13.002375 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:51:14.075292 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
18:51:14.084223 [debug] [MainThread]: On master: ROLLBACK
18:51:14.090440 [debug] [MainThread]: Using postgres connection "master"
18:51:14.097178 [debug] [MainThread]: On master: BEGIN
18:51:14.106874 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
18:51:14.108725 [debug] [MainThread]: On master: COMMIT
18:51:14.109719 [debug] [MainThread]: Using postgres connection "master"
18:51:14.110719 [debug] [MainThread]: On master: COMMIT
18:51:14.114020 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:51:14.117764 [debug] [MainThread]: On master: Close
18:51:14.119870 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:51:14.122236 [info ] [MainThread]: 
18:51:14.146019 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:51:14.148005 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:51:14.151453 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:51:14.152671 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:51:14.153496 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:51:14.175204 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:51:14.175594 [debug] [Thread-1  ]: finished collecting timing info
18:51:14.176599 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:51:14.232325 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:51:14.232325 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp002114217115"
  as (
    


with filter_data_source_1 as (
    select s.*,
    right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.*, null as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_ref_file fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.txt_txn_desc like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s 
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:51:14.241077 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:51:14.318241 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.08 seconds
18:51:14.339982 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:51:14.341680 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
18:51:14.348594 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
18:51:14.349624 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:51:14.350627 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp002114217115'
        
      order by ordinal_position

  
18:51:14.363883 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
18:51:14.375004 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:51:14.378224 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
18:51:14.385950 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
18:51:14.393277 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:51:14.393277 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
18:51:14.407026 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
18:51:14.418388 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
18:51:14.419387 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:51:14.420389 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp002114217115"
    )
  
18:51:14.427128 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
18:51:14.438146 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
18:51:14.438880 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:51:14.439183 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
18:51:14.446229 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
18:51:14.447229 [debug] [Thread-1  ]: finished collecting timing info
18:51:14.447229 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:51:14.448229 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6679ad67-5b22-4a83-95cc-15b10de88db9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015142892F40>]}
18:51:14.449292 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.30s]
18:51:14.451294 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:51:14.452293 [debug] [MainThread]: Acquiring new postgres connection "master"
18:51:14.453803 [debug] [MainThread]: Using postgres connection "master"
18:51:14.453885 [debug] [MainThread]: On master: BEGIN
18:51:14.454294 [debug] [MainThread]: Opening a new connection, currently in state closed
18:51:14.502629 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
18:51:14.502629 [debug] [MainThread]: On master: COMMIT
18:51:14.503640 [debug] [MainThread]: Using postgres connection "master"
18:51:14.503640 [debug] [MainThread]: On master: COMMIT
18:51:14.505662 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:51:14.505662 [debug] [MainThread]: On master: Close
18:51:14.508735 [info ] [MainThread]: 
18:51:14.509733 [info ] [MainThread]: Finished running 1 incremental model in 1.88s.
18:51:14.510755 [debug] [MainThread]: Connection 'master' was properly closed.
18:51:14.511734 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:51:14.513769 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:51:14.515964 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:51:14.527806 [info ] [MainThread]: 
18:51:14.530879 [info ] [MainThread]: [32mCompleted successfully[0m
18:51:14.533582 [info ] [MainThread]: 
18:51:14.535833 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
18:51:14.536846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000151424DD070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000151424E7940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015143968220>]}


============================== 2022-03-29 18:55:20.067804 | 5eb79be6-446e-45c4-976a-97b35d53f1b8 ==============================
18:55:20.067804 [info ] [MainThread]: Running with dbt=1.0.3
18:55:20.078843 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:55:20.079868 [debug] [MainThread]: Tracking: tracking
18:55:20.108027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013B2BCFC6D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013B2BCFCAF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013B2BCFC5E0>]}
18:55:20.163651 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
18:55:20.167537 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
18:55:20.172585 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
18:55:20.182282 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
18:55:20.208702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5eb79be6-446e-45c4-976a-97b35d53f1b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013B2BE5B0D0>]}
18:55:20.216829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5eb79be6-446e-45c4-976a-97b35d53f1b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013B2BDC34C0>]}
18:55:20.216829 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:55:20.219148 [info ] [MainThread]: 
18:55:20.219831 [debug] [MainThread]: Acquiring new postgres connection "master"
18:55:20.221829 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:55:20.234694 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:55:20.235502 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:55:20.235502 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:55:20.325043 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.09 seconds
18:55:20.329288 [debug] [ThreadPool]: On list_recon-cortex: Close
18:55:20.335529 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:55:20.345474 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:55:20.361599 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:55:20.362598 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:55:20.470259 [debug] [ThreadPool]: SQL status: BEGIN in 0.11 seconds
18:55:20.471319 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:55:20.473101 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:55:20.529903 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.06 seconds
18:55:20.532851 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:55:20.542010 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:55:20.608112 [debug] [MainThread]: Using postgres connection "master"
18:55:20.608112 [debug] [MainThread]: On master: BEGIN
18:55:20.610931 [debug] [MainThread]: Opening a new connection, currently in state init
18:55:20.728359 [debug] [MainThread]: SQL status: BEGIN in 0.12 seconds
18:55:20.730879 [debug] [MainThread]: Using postgres connection "master"
18:55:20.732377 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:55:21.700657 [debug] [MainThread]: SQL status: SELECT 0 in 0.97 seconds
18:55:21.703151 [debug] [MainThread]: On master: ROLLBACK
18:55:21.707633 [debug] [MainThread]: Using postgres connection "master"
18:55:21.723743 [debug] [MainThread]: On master: BEGIN
18:55:21.731948 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
18:55:21.735641 [debug] [MainThread]: On master: COMMIT
18:55:21.737330 [debug] [MainThread]: Using postgres connection "master"
18:55:21.737330 [debug] [MainThread]: On master: COMMIT
18:55:21.740580 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:55:21.744789 [debug] [MainThread]: On master: Close
18:55:21.747091 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:55:21.749104 [info ] [MainThread]: 
18:55:21.774710 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:55:21.777339 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:55:21.780339 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:55:21.781342 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:55:21.782343 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:55:21.798057 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:55:21.799591 [debug] [Thread-1  ]: finished collecting timing info
18:55:21.800595 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:55:21.862247 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:55:21.862247 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp002521848862"
  as (
    


with filter_data_source_1 as (
    select s.*,
    right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.*, null as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    CASE WHEN fds1.txt_txn_desc like 'RTGS%' THEN
        fds2.app_id_c as ref_agr1,
        fds2.app_id_c as ref_agr2,
        fds2.app_id_c as ref_agr3,
        fds2.app_id_c as agreement_no
    ELSE
        trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
        trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
        trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
        null as agreement_no
    end
     from filter_data_source_1 fds1 left outer join filter_ref_file fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.txt_txn_desc like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s 
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:55:21.869802 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:55:21.932880 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "as"
LINE 25:         fds2.app_id_c as ref_agr1,
                               ^

18:55:21.933890 [debug] [Thread-1  ]: finished collecting timing info
18:55:21.934382 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:55:21.935392 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  syntax error at or near "as"
  LINE 25:         fds2.app_id_c as ref_agr1,
                                 ^
18:55:21.936386 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5eb79be6-446e-45c4-976a-97b35d53f1b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013B2BE5B220>]}
18:55:21.936386 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.16s]
18:55:21.938408 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:55:21.941409 [debug] [MainThread]: Acquiring new postgres connection "master"
18:55:21.942412 [debug] [MainThread]: Using postgres connection "master"
18:55:21.942412 [debug] [MainThread]: On master: BEGIN
18:55:21.943408 [debug] [MainThread]: Opening a new connection, currently in state closed
18:55:21.994477 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
18:55:21.995456 [debug] [MainThread]: On master: COMMIT
18:55:21.996455 [debug] [MainThread]: Using postgres connection "master"
18:55:21.997182 [debug] [MainThread]: On master: COMMIT
18:55:22.002250 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:55:22.003422 [debug] [MainThread]: On master: Close
18:55:22.004414 [info ] [MainThread]: 
18:55:22.005409 [info ] [MainThread]: Finished running 1 incremental model in 1.78s.
18:55:22.007410 [debug] [MainThread]: Connection 'master' was properly closed.
18:55:22.007410 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:55:22.008419 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:55:22.008419 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:55:22.017880 [info ] [MainThread]: 
18:55:22.018881 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
18:55:22.024297 [info ] [MainThread]: 
18:55:22.025299 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
18:55:22.028434 [error] [MainThread]:   syntax error at or near "as"
18:55:22.030435 [error] [MainThread]:   LINE 25:         fds2.app_id_c as ref_agr1,
18:55:22.031434 [error] [MainThread]:                                  ^
18:55:22.032573 [info ] [MainThread]: 
18:55:22.034574 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
18:55:22.036583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013B2BE37910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013B2BCF9460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013B2ABDFE50>]}


============================== 2022-03-29 18:57:04.624057 | 5f3c3de6-66ef-43f9-8279-d3f435ee9f49 ==============================
18:57:04.624057 [info ] [MainThread]: Running with dbt=1.0.3
18:57:04.640309 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:57:04.641008 [debug] [MainThread]: Tracking: tracking
18:57:04.671615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFA4B5F310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFA4B5F8E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFA4B5FA00>]}
18:57:04.731020 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
18:57:04.732334 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
18:57:04.741687 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
18:57:04.764595 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
18:57:04.780370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5f3c3de6-66ef-43f9-8279-d3f435ee9f49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFA5C870D0>]}
18:57:04.787880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5f3c3de6-66ef-43f9-8279-d3f435ee9f49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFA5BF4910>]}
18:57:04.787880 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:57:04.790085 [info ] [MainThread]: 
18:57:04.791002 [debug] [MainThread]: Acquiring new postgres connection "master"
18:57:04.793187 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:57:04.804068 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:57:04.804068 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:57:04.806826 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:57:04.856824 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.05 seconds
18:57:04.865344 [debug] [ThreadPool]: On list_recon-cortex: Close
18:57:04.870773 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:57:04.880051 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:57:04.888349 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:57:04.888349 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:57:04.953298 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
18:57:04.957149 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:57:04.957149 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:57:05.191009 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.23 seconds
18:57:05.197332 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:57:05.206317 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:57:05.262490 [debug] [MainThread]: Using postgres connection "master"
18:57:05.268693 [debug] [MainThread]: On master: BEGIN
18:57:05.268693 [debug] [MainThread]: Opening a new connection, currently in state init
18:57:05.348910 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
18:57:05.351365 [debug] [MainThread]: Using postgres connection "master"
18:57:05.352734 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:57:06.293547 [debug] [MainThread]: SQL status: SELECT 0 in 0.94 seconds
18:57:06.310687 [debug] [MainThread]: On master: ROLLBACK
18:57:06.315708 [debug] [MainThread]: Using postgres connection "master"
18:57:06.323336 [debug] [MainThread]: On master: BEGIN
18:57:06.333505 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
18:57:06.335164 [debug] [MainThread]: On master: COMMIT
18:57:06.336211 [debug] [MainThread]: Using postgres connection "master"
18:57:06.337213 [debug] [MainThread]: On master: COMMIT
18:57:06.339162 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:57:06.346900 [debug] [MainThread]: On master: Close
18:57:06.349800 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:57:06.351264 [info ] [MainThread]: 
18:57:06.376472 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:57:06.378449 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:57:06.382250 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:57:06.383247 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:57:06.383247 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:57:06.399170 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:57:06.402056 [debug] [Thread-1  ]: finished collecting timing info
18:57:06.403061 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:57:06.468608 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:57:06.468608 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp002706433897"
  as (
    


with filter_data_source_1 as (
    select s.*,
    right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.*, null as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_ref_file fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
      where s.txt_txn_desc like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s 
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:57:06.471025 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:57:06.521220 [debug] [Thread-1  ]: Postgres adapter: Postgres error: missing FROM-clause entry for table "s"
LINE 30:       where s.txt_txn_desc like 'RTGS%'
                     ^

18:57:06.522224 [debug] [Thread-1  ]: finished collecting timing info
18:57:06.523231 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:57:06.524224 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  missing FROM-clause entry for table "s"
  LINE 30:       where s.txt_txn_desc like 'RTGS%'
                       ^
18:57:06.525228 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f3c3de6-66ef-43f9-8279-d3f435ee9f49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFA5C59730>]}
18:57:06.526255 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.14s]
18:57:06.527226 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:57:06.530222 [debug] [MainThread]: Acquiring new postgres connection "master"
18:57:06.530222 [debug] [MainThread]: Using postgres connection "master"
18:57:06.531227 [debug] [MainThread]: On master: BEGIN
18:57:06.531227 [debug] [MainThread]: Opening a new connection, currently in state closed
18:57:06.579641 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
18:57:06.579919 [debug] [MainThread]: On master: COMMIT
18:57:06.580921 [debug] [MainThread]: Using postgres connection "master"
18:57:06.580921 [debug] [MainThread]: On master: COMMIT
18:57:06.584963 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:57:06.585964 [debug] [MainThread]: On master: Close
18:57:06.587965 [info ] [MainThread]: 
18:57:06.589965 [info ] [MainThread]: Finished running 1 incremental model in 1.80s.
18:57:06.591972 [debug] [MainThread]: Connection 'master' was properly closed.
18:57:06.592966 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:57:06.593984 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:57:06.595517 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:57:06.604339 [info ] [MainThread]: 
18:57:06.605581 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
18:57:06.607585 [info ] [MainThread]: 
18:57:06.608580 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
18:57:06.611582 [error] [MainThread]:   missing FROM-clause entry for table "s"
18:57:06.613581 [error] [MainThread]:   LINE 30:       where s.txt_txn_desc like 'RTGS%'
18:57:06.615636 [error] [MainThread]:                        ^
18:57:06.616858 [info ] [MainThread]: 
18:57:06.617859 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
18:57:06.620911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFA4A05D30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFA5BF4580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFA4B3CF10>]}


============================== 2022-03-29 18:57:24.146054 | 08d9e601-e4af-44c1-a753-aef2aebcf5f8 ==============================
18:57:24.146054 [info ] [MainThread]: Running with dbt=1.0.3
18:57:24.156194 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:57:24.156194 [debug] [MainThread]: Tracking: tracking
18:57:24.182827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000238F494C910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000238F494CEB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000238F494CA00>]}
18:57:24.236579 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
18:57:24.241718 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
18:57:24.248802 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
18:57:24.257812 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
18:57:24.286441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '08d9e601-e4af-44c1-a753-aef2aebcf5f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000238F4AA90D0>]}
18:57:24.293337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '08d9e601-e4af-44c1-a753-aef2aebcf5f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000238F49A89A0>]}
18:57:24.294335 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:57:24.296335 [info ] [MainThread]: 
18:57:24.297332 [debug] [MainThread]: Acquiring new postgres connection "master"
18:57:24.299008 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:57:24.309421 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:57:24.309421 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:57:24.314524 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:57:24.385992 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.07 seconds
18:57:24.394657 [debug] [ThreadPool]: On list_recon-cortex: Close
18:57:24.399981 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:57:24.420887 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:57:24.428561 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:57:24.429674 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:57:24.500207 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
18:57:24.508098 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:57:24.510072 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:57:24.519656 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
18:57:24.526580 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:57:24.531957 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:57:24.585231 [debug] [MainThread]: Using postgres connection "master"
18:57:24.591080 [debug] [MainThread]: On master: BEGIN
18:57:24.591080 [debug] [MainThread]: Opening a new connection, currently in state init
18:57:24.673784 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
18:57:24.674990 [debug] [MainThread]: Using postgres connection "master"
18:57:24.676040 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:57:25.624454 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
18:57:25.636567 [debug] [MainThread]: On master: ROLLBACK
18:57:25.641179 [debug] [MainThread]: Using postgres connection "master"
18:57:25.646268 [debug] [MainThread]: On master: BEGIN
18:57:25.658170 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
18:57:25.659923 [debug] [MainThread]: On master: COMMIT
18:57:25.661177 [debug] [MainThread]: Using postgres connection "master"
18:57:25.661177 [debug] [MainThread]: On master: COMMIT
18:57:25.665248 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:57:25.669162 [debug] [MainThread]: On master: Close
18:57:25.670938 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:57:25.674363 [info ] [MainThread]: 
18:57:25.696033 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:57:25.699414 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:57:25.703066 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:57:25.704087 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:57:25.705566 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:57:25.720481 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:57:25.721270 [debug] [Thread-1  ]: finished collecting timing info
18:57:25.722270 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:57:25.786363 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:57:25.786847 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp002725761440"
  as (
    


with filter_data_source_1 as (
    select s.*,
    right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.*, null as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_ref_file fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
      where fds1.txt_txn_desc like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s 
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:57:25.786847 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:57:25.860435 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.07 seconds
18:57:25.868833 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:57:25.870131 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
18:57:25.874324 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
18:57:25.874324 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:57:25.874324 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp002725761440'
        
      order by ordinal_position

  
18:57:25.887344 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
18:57:25.894955 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:57:25.894955 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
18:57:25.904905 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
18:57:25.919120 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:57:25.920090 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
18:57:25.930279 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
18:57:25.945382 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
18:57:25.946382 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:57:25.947381 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp002725761440"
    )
  
18:57:25.953359 [debug] [Thread-1  ]: SQL status: INSERT 0 2 in 0.01 seconds
18:57:25.963251 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
18:57:25.963251 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:57:25.964252 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
18:57:25.969280 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
18:57:25.970242 [debug] [Thread-1  ]: finished collecting timing info
18:57:25.970242 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:57:25.971245 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '08d9e601-e4af-44c1-a753-aef2aebcf5f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000238F494CD30>]}
18:57:25.972279 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 2[0m in 0.27s]
18:57:25.973253 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:57:25.976244 [debug] [MainThread]: Acquiring new postgres connection "master"
18:57:25.976816 [debug] [MainThread]: Using postgres connection "master"
18:57:25.977718 [debug] [MainThread]: On master: BEGIN
18:57:25.978120 [debug] [MainThread]: Opening a new connection, currently in state closed
18:57:26.033528 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
18:57:26.034571 [debug] [MainThread]: On master: COMMIT
18:57:26.035574 [debug] [MainThread]: Using postgres connection "master"
18:57:26.036606 [debug] [MainThread]: On master: COMMIT
18:57:26.039638 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:57:26.044802 [debug] [MainThread]: On master: Close
18:57:26.045860 [info ] [MainThread]: 
18:57:26.047251 [info ] [MainThread]: Finished running 1 incremental model in 1.75s.
18:57:26.050265 [debug] [MainThread]: Connection 'master' was properly closed.
18:57:26.051589 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:57:26.051589 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:57:26.053065 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:57:26.064636 [info ] [MainThread]: 
18:57:26.067219 [info ] [MainThread]: [32mCompleted successfully[0m
18:57:26.070217 [info ] [MainThread]: 
18:57:26.072857 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
18:57:26.075725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000238F34FFEE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000238F34C74F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000238F4947880>]}


============================== 2022-03-29 18:58:49.501061 | 58a2079c-6199-4e13-9c9b-9279196668dd ==============================
18:58:49.501061 [info ] [MainThread]: Running with dbt=1.0.3
18:58:49.510526 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:58:49.510526 [debug] [MainThread]: Tracking: tracking
18:58:49.541026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B3841C670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B3841CA90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B3841C5E0>]}
18:58:49.592390 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
18:58:49.592390 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
18:58:49.599852 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
18:58:49.629278 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
18:58:49.642491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '58a2079c-6199-4e13-9c9b-9279196668dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B3857A0D0>]}
18:58:49.650184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '58a2079c-6199-4e13-9c9b-9279196668dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B384E34C0>]}
18:58:49.651202 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:58:49.653398 [info ] [MainThread]: 
18:58:49.654187 [debug] [MainThread]: Acquiring new postgres connection "master"
18:58:49.656193 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:58:49.668021 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:58:49.668021 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:58:49.669838 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:58:49.753392 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.08 seconds
18:58:49.762786 [debug] [ThreadPool]: On list_recon-cortex: Close
18:58:49.769028 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:58:49.781532 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:58:49.791812 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:58:49.792848 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:58:49.863824 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
18:58:49.866850 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:58:49.867886 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:58:49.876096 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
18:58:49.878607 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:58:49.892345 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:58:49.938706 [debug] [MainThread]: Using postgres connection "master"
18:58:49.938706 [debug] [MainThread]: On master: BEGIN
18:58:49.944155 [debug] [MainThread]: Opening a new connection, currently in state init
18:58:50.023681 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
18:58:50.024677 [debug] [MainThread]: Using postgres connection "master"
18:58:50.026676 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:58:50.985336 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
18:58:50.988467 [debug] [MainThread]: On master: ROLLBACK
18:58:50.995018 [debug] [MainThread]: Using postgres connection "master"
18:58:50.995018 [debug] [MainThread]: On master: BEGIN
18:58:51.009152 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
18:58:51.011253 [debug] [MainThread]: On master: COMMIT
18:58:51.012586 [debug] [MainThread]: Using postgres connection "master"
18:58:51.013911 [debug] [MainThread]: On master: COMMIT
18:58:51.016431 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:58:51.021045 [debug] [MainThread]: On master: Close
18:58:51.022667 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:58:51.026254 [info ] [MainThread]: 
18:58:51.050266 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:58:51.051277 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:58:51.055400 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:58:51.056610 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:58:51.057664 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:58:51.071493 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:58:51.077104 [debug] [Thread-1  ]: finished collecting timing info
18:58:51.078106 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:58:51.141305 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:58:51.143461 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp002851119596"
  as (
    


with filter_data_source_1 as (
    select s.*,
    right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.*, null as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_ref_file fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
      where fds1.txt_txn_desc like 'RTGS%'
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_1 fds2
    where fds1.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s 
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:58:51.143461 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:58:51.204692 [debug] [Thread-1  ]: Postgres adapter: Postgres error: missing FROM-clause entry for table "fds1"
LINE 35:     where fds1.txt_txn_desc not like 'RTGS%'
                   ^

18:58:51.205691 [debug] [Thread-1  ]: finished collecting timing info
18:58:51.206693 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:58:51.207692 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  missing FROM-clause entry for table "fds1"
  LINE 35:     where fds1.txt_txn_desc not like 'RTGS%'
                     ^
18:58:51.207692 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '58a2079c-6199-4e13-9c9b-9279196668dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B3850A040>]}
18:58:51.208892 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.15s]
18:58:51.211157 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:58:51.213192 [debug] [MainThread]: Acquiring new postgres connection "master"
18:58:51.213192 [debug] [MainThread]: Using postgres connection "master"
18:58:51.213192 [debug] [MainThread]: On master: BEGIN
18:58:51.214156 [debug] [MainThread]: Opening a new connection, currently in state closed
18:58:51.258409 [debug] [MainThread]: SQL status: BEGIN in 0.04 seconds
18:58:51.259410 [debug] [MainThread]: On master: COMMIT
18:58:51.259410 [debug] [MainThread]: Using postgres connection "master"
18:58:51.259410 [debug] [MainThread]: On master: COMMIT
18:58:51.264417 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:58:51.265413 [debug] [MainThread]: On master: Close
18:58:51.267957 [info ] [MainThread]: 
18:58:51.269316 [info ] [MainThread]: Finished running 1 incremental model in 1.61s.
18:58:51.270316 [debug] [MainThread]: Connection 'master' was properly closed.
18:58:51.271323 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:58:51.271323 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:58:51.272444 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:58:51.279919 [info ] [MainThread]: 
18:58:51.280918 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
18:58:51.282754 [info ] [MainThread]: 
18:58:51.284809 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
18:58:51.286782 [error] [MainThread]:   missing FROM-clause entry for table "fds1"
18:58:51.291035 [error] [MainThread]:   LINE 35:     where fds1.txt_txn_desc not like 'RTGS%'
18:58:51.293027 [error] [MainThread]:                      ^
18:58:51.294591 [info ] [MainThread]: 
18:58:51.297182 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
18:58:51.300356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B36F8C070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B38556520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029B383D2CA0>]}


============================== 2022-03-29 18:59:07.433533 | e258cf33-fcb8-4fd8-a31a-e46782fdc33c ==============================
18:59:07.433533 [info ] [MainThread]: Running with dbt=1.0.3
18:59:07.438832 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:59:07.438832 [debug] [MainThread]: Tracking: tracking
18:59:07.477731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA12E7C2B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA12E7C910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA12E7C820>]}
18:59:07.532843 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
18:59:07.533280 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
18:59:07.539154 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
18:59:07.563903 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
18:59:07.576112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e258cf33-fcb8-4fd8-a31a-e46782fdc33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA12FD90D0>]}
18:59:07.583051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e258cf33-fcb8-4fd8-a31a-e46782fdc33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA12F43730>]}
18:59:07.583051 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:59:07.585668 [info ] [MainThread]: 
18:59:07.587049 [debug] [MainThread]: Acquiring new postgres connection "master"
18:59:07.588351 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:59:07.596548 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:59:07.601781 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:59:07.601781 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:59:07.672512 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.07 seconds
18:59:07.675286 [debug] [ThreadPool]: On list_recon-cortex: Close
18:59:07.677452 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:59:07.686951 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:59:07.686951 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:59:07.686951 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:59:07.755194 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
18:59:07.756206 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:59:07.757078 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:59:07.767411 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
18:59:07.770445 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:59:07.775818 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:59:07.807984 [debug] [MainThread]: Using postgres connection "master"
18:59:07.807984 [debug] [MainThread]: On master: BEGIN
18:59:07.817694 [debug] [MainThread]: Opening a new connection, currently in state init
18:59:07.890170 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
18:59:07.891580 [debug] [MainThread]: Using postgres connection "master"
18:59:07.892938 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:59:08.849996 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
18:59:08.852610 [debug] [MainThread]: On master: ROLLBACK
18:59:08.856893 [debug] [MainThread]: Using postgres connection "master"
18:59:08.861344 [debug] [MainThread]: On master: BEGIN
18:59:08.880129 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
18:59:08.881818 [debug] [MainThread]: On master: COMMIT
18:59:08.882880 [debug] [MainThread]: Using postgres connection "master"
18:59:08.883173 [debug] [MainThread]: On master: COMMIT
18:59:08.887296 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:59:08.891319 [debug] [MainThread]: On master: Close
18:59:08.893251 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:59:08.896844 [info ] [MainThread]: 
18:59:08.914852 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:59:08.917878 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:59:08.921084 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:59:08.922084 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:59:08.923089 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:59:08.938128 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:59:08.981923 [debug] [Thread-1  ]: finished collecting timing info
18:59:08.982927 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:59:09.050852 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:59:09.050852 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp002909027270"
  as (
    


with filter_data_source_1 as (
    select s.*,
    right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.*, null as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_ref_file fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
      where fds1.txt_txn_desc like 'RTGS%'
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s 
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:59:09.051854 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:59:09.109023 [debug] [Thread-1  ]: Postgres adapter: Postgres error: each UNION query must have the same number of columns
LINE 32:    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_...
                   ^

18:59:09.109023 [debug] [Thread-1  ]: finished collecting timing info
18:59:09.110024 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:59:09.110142 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  each UNION query must have the same number of columns
  LINE 32:    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_...
                     ^
18:59:09.111144 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e258cf33-fcb8-4fd8-a31a-e46782fdc33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA12F741C0>]}
18:59:09.111144 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.19s]
18:59:09.113149 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:59:09.115142 [debug] [MainThread]: Acquiring new postgres connection "master"
18:59:09.115142 [debug] [MainThread]: Using postgres connection "master"
18:59:09.116144 [debug] [MainThread]: On master: BEGIN
18:59:09.116144 [debug] [MainThread]: Opening a new connection, currently in state closed
18:59:09.172507 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
18:59:09.173507 [debug] [MainThread]: On master: COMMIT
18:59:09.175847 [debug] [MainThread]: Using postgres connection "master"
18:59:09.175847 [debug] [MainThread]: On master: COMMIT
18:59:09.182259 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
18:59:09.183259 [debug] [MainThread]: On master: Close
18:59:09.184267 [info ] [MainThread]: 
18:59:09.185269 [info ] [MainThread]: Finished running 1 incremental model in 1.60s.
18:59:09.187263 [debug] [MainThread]: Connection 'master' was properly closed.
18:59:09.188264 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:59:09.189275 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:59:09.190267 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:59:09.199996 [info ] [MainThread]: 
18:59:09.202700 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
18:59:09.206470 [info ] [MainThread]: 
18:59:09.208465 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
18:59:09.210513 [error] [MainThread]:   each UNION query must have the same number of columns
18:59:09.212029 [error] [MainThread]:   LINE 32:    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_...
18:59:09.214027 [error] [MainThread]:                      ^
18:59:09.215029 [info ] [MainThread]: 
18:59:09.217064 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
18:59:09.220065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA130178B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA130173A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA12F9DFA0>]}


============================== 2022-03-29 18:59:34.183623 | 47c339ae-0c33-4db3-a7e5-62832a753f6c ==============================
18:59:34.183623 [info ] [MainThread]: Running with dbt=1.0.3
18:59:34.193379 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:59:34.193379 [debug] [MainThread]: Tracking: tracking
18:59:34.231862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B294F38670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B294F38520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B294F387C0>]}
18:59:34.284312 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
18:59:34.284312 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
18:59:34.294294 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
18:59:34.323349 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
18:59:34.340905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '47c339ae-0c33-4db3-a7e5-62832a753f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B2960990D0>]}
18:59:34.351874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '47c339ae-0c33-4db3-a7e5-62832a753f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B296004070>]}
18:59:34.351874 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:59:34.354508 [info ] [MainThread]: 
18:59:34.356212 [debug] [MainThread]: Acquiring new postgres connection "master"
18:59:34.358019 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:59:34.372571 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:59:34.372571 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:59:34.374360 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:59:34.455236 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.08 seconds
18:59:34.461186 [debug] [ThreadPool]: On list_recon-cortex: Close
18:59:34.465651 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:59:34.469371 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:59:34.482314 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:59:34.482314 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:59:34.556230 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
18:59:34.558014 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:59:34.559242 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:59:34.568133 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
18:59:34.571392 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:59:34.581793 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:59:34.629524 [debug] [MainThread]: Using postgres connection "master"
18:59:34.629524 [debug] [MainThread]: On master: BEGIN
18:59:34.632980 [debug] [MainThread]: Opening a new connection, currently in state init
18:59:34.708197 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
18:59:34.710466 [debug] [MainThread]: Using postgres connection "master"
18:59:34.711714 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:59:35.666253 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
18:59:35.674938 [debug] [MainThread]: On master: ROLLBACK
18:59:35.679667 [debug] [MainThread]: Using postgres connection "master"
18:59:35.679667 [debug] [MainThread]: On master: BEGIN
18:59:35.694571 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
18:59:35.696021 [debug] [MainThread]: On master: COMMIT
18:59:35.697064 [debug] [MainThread]: Using postgres connection "master"
18:59:35.698069 [debug] [MainThread]: On master: COMMIT
18:59:35.701253 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:59:35.706284 [debug] [MainThread]: On master: Close
18:59:35.708718 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:59:35.710764 [info ] [MainThread]: 
18:59:35.735467 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:59:35.737474 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:59:35.741284 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:59:35.743504 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:59:35.744904 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:59:35.758408 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:59:35.761516 [debug] [Thread-1  ]: finished collecting timing info
18:59:35.761516 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:59:35.823822 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:59:35.823822 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp002935801417"
  as (
    


with filter_data_source_1 as (
    select s.*,
    right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.*, null as rtgs_utr_no from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_ref_file fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
      where fds1.txt_txn_desc like 'RTGS%'
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s 
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:59:35.824814 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:59:35.876737 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.05 seconds
18:59:35.882870 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:59:35.882870 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
18:59:35.890405 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
18:59:35.891405 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:59:35.891405 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp002935801417'
        
      order by ordinal_position

  
18:59:35.902701 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
18:59:35.910497 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:59:35.910497 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
18:59:35.948216 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.04 seconds
18:59:35.962902 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:59:35.962902 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
18:59:35.968945 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
18:59:35.984949 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
18:59:35.985951 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:59:35.987038 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp002935801417"
    )
  
18:59:35.993466 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
18:59:36.003862 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
18:59:36.004926 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:59:36.004926 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
18:59:36.010861 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
18:59:36.012034 [debug] [Thread-1  ]: finished collecting timing info
18:59:36.012034 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:59:36.013207 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47c339ae-0c33-4db3-a7e5-62832a753f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B294F3D220>]}
18:59:36.014037 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.27s]
18:59:36.016037 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:59:36.017037 [debug] [MainThread]: Acquiring new postgres connection "master"
18:59:36.018484 [debug] [MainThread]: Using postgres connection "master"
18:59:36.018590 [debug] [MainThread]: On master: BEGIN
18:59:36.018590 [debug] [MainThread]: Opening a new connection, currently in state closed
18:59:36.081907 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
18:59:36.082304 [debug] [MainThread]: On master: COMMIT
18:59:36.083309 [debug] [MainThread]: Using postgres connection "master"
18:59:36.084309 [debug] [MainThread]: On master: COMMIT
18:59:36.086447 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:59:36.090074 [debug] [MainThread]: On master: Close
18:59:36.091069 [info ] [MainThread]: 
18:59:36.093076 [info ] [MainThread]: Finished running 1 incremental model in 1.74s.
18:59:36.094077 [debug] [MainThread]: Connection 'master' was properly closed.
18:59:36.095070 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:59:36.097071 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:59:36.097071 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:59:36.109201 [info ] [MainThread]: 
18:59:36.111180 [info ] [MainThread]: [32mCompleted successfully[0m
18:59:36.114316 [info ] [MainThread]: 
18:59:36.116310 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
18:59:36.119313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B294E1FE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B294E1FF70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B294F3DF10>]}


============================== 2022-03-29 19:06:08.438719 | c387e684-2fc8-41a6-87c7-399f710db823 ==============================
19:06:08.438719 [info ] [MainThread]: Running with dbt=1.0.3
19:06:08.440183 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
19:06:08.441197 [debug] [MainThread]: Tracking: tracking
19:06:08.467890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA25BC2E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA25BC8E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA25BCCA0>]}
19:06:08.528407 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
19:06:08.529014 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
19:06:08.535602 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
19:06:08.555617 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
19:06:08.572703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c387e684-2fc8-41a6-87c7-399f710db823', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA36EB0D0>]}
19:06:08.580353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c387e684-2fc8-41a6-87c7-399f710db823', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA3653730>]}
19:06:08.580353 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
19:06:08.582890 [info ] [MainThread]: 
19:06:08.584322 [debug] [MainThread]: Acquiring new postgres connection "master"
19:06:08.585318 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
19:06:08.596812 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
19:06:08.598216 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
19:06:08.598533 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:06:08.696923 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.1 seconds
19:06:08.702602 [debug] [ThreadPool]: On list_recon-cortex: Close
19:06:08.707944 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
19:06:08.729058 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:06:08.729058 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
19:06:08.733639 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:06:08.794663 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
19:06:08.795999 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:06:08.797008 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
19:06:08.805747 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
19:06:08.812270 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
19:06:08.818891 [debug] [ThreadPool]: On list_recon-cortex_public: Close
19:06:08.866675 [debug] [MainThread]: Using postgres connection "master"
19:06:08.867676 [debug] [MainThread]: On master: BEGIN
19:06:08.867676 [debug] [MainThread]: Opening a new connection, currently in state init
19:06:08.944985 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
19:06:08.945988 [debug] [MainThread]: Using postgres connection "master"
19:06:08.947026 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
19:06:09.891815 [debug] [MainThread]: SQL status: SELECT 0 in 0.94 seconds
19:06:09.896339 [debug] [MainThread]: On master: ROLLBACK
19:06:09.904728 [debug] [MainThread]: Using postgres connection "master"
19:06:09.909655 [debug] [MainThread]: On master: BEGIN
19:06:09.920971 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
19:06:09.922988 [debug] [MainThread]: On master: COMMIT
19:06:09.924478 [debug] [MainThread]: Using postgres connection "master"
19:06:09.925535 [debug] [MainThread]: On master: COMMIT
19:06:09.931622 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:06:09.933864 [debug] [MainThread]: On master: Close
19:06:09.936440 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
19:06:09.940071 [info ] [MainThread]: 
19:06:09.966567 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
19:06:09.967667 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
19:06:09.971188 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
19:06:09.973188 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
19:06:09.974193 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
19:06:09.987938 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
19:06:09.988922 [debug] [Thread-1  ]: finished collecting timing info
19:06:09.989921 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
19:06:10.040477 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:06:10.047269 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp003610027615"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no,
    right(s.txt_txn_desc,22) as rtgs_utr_no from filter_data_source_1 fds1 left outer join filter_ref_file fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
      where fds1.txt_txn_desc like 'RTGS%'
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no,
    null as rtgs_utr_no from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s 
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
19:06:10.047269 [debug] [Thread-1  ]: Opening a new connection, currently in state init
19:06:10.147430 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column fds1.rtgs_utr_no does not exist
LINE 29:      and fds1.rtgs_utr_no = fds2.utr
                  ^

19:06:10.150644 [debug] [Thread-1  ]: finished collecting timing info
19:06:10.152032 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
19:06:10.155091 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  column fds1.rtgs_utr_no does not exist
  LINE 29:      and fds1.rtgs_utr_no = fds2.utr
                    ^
19:06:10.156855 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c387e684-2fc8-41a6-87c7-399f710db823', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA36EB3A0>]}
19:06:10.159287 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.19s]
19:06:10.165006 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
19:06:10.170754 [debug] [MainThread]: Acquiring new postgres connection "master"
19:06:10.172081 [debug] [MainThread]: Using postgres connection "master"
19:06:10.174627 [debug] [MainThread]: On master: BEGIN
19:06:10.176682 [debug] [MainThread]: Opening a new connection, currently in state closed
19:06:10.227916 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
19:06:10.229193 [debug] [MainThread]: On master: COMMIT
19:06:10.229193 [debug] [MainThread]: Using postgres connection "master"
19:06:10.230632 [debug] [MainThread]: On master: COMMIT
19:06:10.235438 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:06:10.236447 [debug] [MainThread]: On master: Close
19:06:10.238024 [info ] [MainThread]: 
19:06:10.240063 [info ] [MainThread]: Finished running 1 incremental model in 1.65s.
19:06:10.242263 [debug] [MainThread]: Connection 'master' was properly closed.
19:06:10.243261 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
19:06:10.244259 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
19:06:10.244259 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
19:06:10.254857 [info ] [MainThread]: 
19:06:10.255860 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
19:06:10.259640 [info ] [MainThread]: 
19:06:10.262611 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
19:06:10.264647 [error] [MainThread]:   column fds1.rtgs_utr_no does not exist
19:06:10.265650 [error] [MainThread]:   LINE 29:      and fds1.rtgs_utr_no = fds2.utr
19:06:10.266706 [error] [MainThread]:                     ^
19:06:10.268710 [info ] [MainThread]: 
19:06:10.271875 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
19:06:10.272839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA37297C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA37299D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA36EB760>]}


============================== 2022-03-29 19:12:58.992683 | 3e7ef32d-04f3-4120-b985-707102f53149 ==============================
19:12:58.992683 [info ] [MainThread]: Running with dbt=1.0.3
19:12:59.004236 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
19:12:59.005236 [debug] [MainThread]: Tracking: tracking
19:12:59.031951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002363129F640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002363129FBE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002363129F580>]}
19:12:59.096193 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
19:12:59.098698 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
19:12:59.107259 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
19:12:59.123635 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
19:12:59.143506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3e7ef32d-04f3-4120-b985-707102f53149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000236313FB0D0>]}
19:12:59.150899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3e7ef32d-04f3-4120-b985-707102f53149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000236313644F0>]}
19:12:59.150899 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
19:12:59.152906 [info ] [MainThread]: 
19:12:59.153902 [debug] [MainThread]: Acquiring new postgres connection "master"
19:12:59.155899 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
19:12:59.169607 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
19:12:59.169607 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
19:12:59.170611 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:12:59.251667 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.08 seconds
19:12:59.254618 [debug] [ThreadPool]: On list_recon-cortex: Close
19:12:59.261255 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
19:12:59.273882 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:12:59.273882 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
19:12:59.279920 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:12:59.352215 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
19:12:59.353318 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:12:59.353318 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
19:12:59.363127 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
19:12:59.365232 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
19:12:59.371509 [debug] [ThreadPool]: On list_recon-cortex_public: Close
19:12:59.420233 [debug] [MainThread]: Using postgres connection "master"
19:12:59.420233 [debug] [MainThread]: On master: BEGIN
19:12:59.423739 [debug] [MainThread]: Opening a new connection, currently in state init
19:12:59.493842 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
19:12:59.495853 [debug] [MainThread]: Using postgres connection "master"
19:12:59.497015 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
19:13:00.437876 [debug] [MainThread]: SQL status: SELECT 0 in 0.94 seconds
19:13:00.450951 [debug] [MainThread]: On master: ROLLBACK
19:13:00.457314 [debug] [MainThread]: Using postgres connection "master"
19:13:00.460838 [debug] [MainThread]: On master: BEGIN
19:13:00.478128 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
19:13:00.479174 [debug] [MainThread]: On master: COMMIT
19:13:00.481124 [debug] [MainThread]: Using postgres connection "master"
19:13:00.482269 [debug] [MainThread]: On master: COMMIT
19:13:00.485623 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:13:00.491956 [debug] [MainThread]: On master: Close
19:13:00.494260 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
19:13:00.497383 [info ] [MainThread]: 
19:13:00.520464 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
19:13:00.522466 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
19:13:00.525799 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
19:13:00.527071 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
19:13:00.528724 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
19:13:00.543064 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
19:13:00.544174 [debug] [Thread-1  ]: finished collecting timing info
19:13:00.545175 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
19:13:00.598473 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:13:00.599521 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp004300579646"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(s.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no,
    null as rtgs_utr_no from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
19:13:00.600477 [debug] [Thread-1  ]: Opening a new connection, currently in state init
19:13:00.685122 [debug] [Thread-1  ]: Postgres adapter: Postgres error: missing FROM-clause entry for table "s"
LINE 29:      and trim(right(s.txt_txn_desc,22)) = trim(fds2.utr)
                             ^

19:13:00.686142 [debug] [Thread-1  ]: finished collecting timing info
19:13:00.687109 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
19:13:00.688112 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  missing FROM-clause entry for table "s"
  LINE 29:      and trim(right(s.txt_txn_desc,22)) = trim(fds2.utr)
                               ^
19:13:00.689112 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e7ef32d-04f3-4120-b985-707102f53149', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002363137B6A0>]}
19:13:00.689112 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.16s]
19:13:00.692245 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
19:13:00.695240 [debug] [MainThread]: Acquiring new postgres connection "master"
19:13:00.695240 [debug] [MainThread]: Using postgres connection "master"
19:13:00.696237 [debug] [MainThread]: On master: BEGIN
19:13:00.697274 [debug] [MainThread]: Opening a new connection, currently in state closed
19:13:00.763247 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
19:13:00.764251 [debug] [MainThread]: On master: COMMIT
19:13:00.764564 [debug] [MainThread]: Using postgres connection "master"
19:13:00.764564 [debug] [MainThread]: On master: COMMIT
19:13:00.768687 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:13:00.769692 [debug] [MainThread]: On master: Close
19:13:00.770741 [info ] [MainThread]: 
19:13:00.771784 [info ] [MainThread]: Finished running 1 incremental model in 1.62s.
19:13:00.772799 [debug] [MainThread]: Connection 'master' was properly closed.
19:13:00.773786 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
19:13:00.774853 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
19:13:00.775858 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
19:13:00.785070 [info ] [MainThread]: 
19:13:00.787087 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
19:13:00.789650 [info ] [MainThread]: 
19:13:00.791647 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
19:13:00.793650 [error] [MainThread]:   missing FROM-clause entry for table "s"
19:13:00.794644 [error] [MainThread]:   LINE 29:      and trim(right(s.txt_txn_desc,22)) = trim(fds2.utr)
19:13:00.795645 [error] [MainThread]:                                ^
19:13:00.796647 [info ] [MainThread]: 
19:13:00.799089 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
19:13:00.802034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023631364490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023631437FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000236312983D0>]}


============================== 2022-03-29 19:13:28.693021 | 50dacc05-28eb-47ef-9edd-bb75df0fc7b3 ==============================
19:13:28.693021 [info ] [MainThread]: Running with dbt=1.0.3
19:13:28.695960 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
19:13:28.695960 [debug] [MainThread]: Tracking: tracking
19:13:28.721723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E94B4F640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E94B4FCA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E94B4F580>]}
19:13:28.776947 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
19:13:28.781218 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
19:13:28.783255 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
19:13:28.795678 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
19:13:28.821206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '50dacc05-28eb-47ef-9edd-bb75df0fc7b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E95C790D0>]}
19:13:28.829205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '50dacc05-28eb-47ef-9edd-bb75df0fc7b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E95BE34F0>]}
19:13:28.829205 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
19:13:28.831424 [info ] [MainThread]: 
19:13:28.832565 [debug] [MainThread]: Acquiring new postgres connection "master"
19:13:28.834709 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
19:13:28.848067 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
19:13:28.848067 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
19:13:28.849067 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:13:28.970952 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.12 seconds
19:13:28.972977 [debug] [ThreadPool]: On list_recon-cortex: Close
19:13:28.974392 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
19:13:28.980771 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:13:28.980771 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
19:13:28.983189 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:13:29.046256 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
19:13:29.047899 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:13:29.047899 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
19:13:29.060304 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
19:13:29.064657 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
19:13:29.071814 [debug] [ThreadPool]: On list_recon-cortex_public: Close
19:13:29.119775 [debug] [MainThread]: Using postgres connection "master"
19:13:29.119775 [debug] [MainThread]: On master: BEGIN
19:13:29.125154 [debug] [MainThread]: Opening a new connection, currently in state init
19:13:29.199930 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
19:13:29.200942 [debug] [MainThread]: Using postgres connection "master"
19:13:29.202584 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
19:13:30.156058 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
19:13:30.156058 [debug] [MainThread]: On master: ROLLBACK
19:13:30.169062 [debug] [MainThread]: Using postgres connection "master"
19:13:30.173351 [debug] [MainThread]: On master: BEGIN
19:13:30.180600 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
19:13:30.188248 [debug] [MainThread]: On master: COMMIT
19:13:30.189231 [debug] [MainThread]: Using postgres connection "master"
19:13:30.190240 [debug] [MainThread]: On master: COMMIT
19:13:30.193421 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:13:30.197298 [debug] [MainThread]: On master: Close
19:13:30.199753 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
19:13:30.201099 [info ] [MainThread]: 
19:13:30.214934 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
19:13:30.217940 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
19:13:30.218967 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
19:13:30.218967 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
19:13:30.219933 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
19:13:30.230101 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
19:13:30.231073 [debug] [Thread-1  ]: finished collecting timing info
19:13:30.231073 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
19:13:30.297697 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:13:30.297966 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp004330261251"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no,
    null as rtgs_utr_no from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        rtgs_utr_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    rtgs_utr_no as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
19:13:30.297966 [debug] [Thread-1  ]: Opening a new connection, currently in state init
19:13:30.366958 [debug] [Thread-1  ]: Postgres adapter: Postgres error: each UNION query must have the same number of columns
LINE 31:    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_...
                   ^

19:13:30.367734 [debug] [Thread-1  ]: finished collecting timing info
19:13:30.367734 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
19:13:30.368732 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  each UNION query must have the same number of columns
  LINE 31:    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_...
                     ^
19:13:30.369734 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '50dacc05-28eb-47ef-9edd-bb75df0fc7b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E95BFAA60>]}
19:13:30.369734 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.15s]
19:13:30.371732 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
19:13:30.373738 [debug] [MainThread]: Acquiring new postgres connection "master"
19:13:30.374271 [debug] [MainThread]: Using postgres connection "master"
19:13:30.374739 [debug] [MainThread]: On master: BEGIN
19:13:30.375733 [debug] [MainThread]: Opening a new connection, currently in state closed
19:13:30.461536 [debug] [MainThread]: SQL status: BEGIN in 0.09 seconds
19:13:30.461839 [debug] [MainThread]: On master: COMMIT
19:13:30.461839 [debug] [MainThread]: Using postgres connection "master"
19:13:30.462838 [debug] [MainThread]: On master: COMMIT
19:13:30.469512 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
19:13:30.469512 [debug] [MainThread]: On master: Close
19:13:30.470549 [info ] [MainThread]: 
19:13:30.471628 [info ] [MainThread]: Finished running 1 incremental model in 1.64s.
19:13:30.473581 [debug] [MainThread]: Connection 'master' was properly closed.
19:13:30.473902 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
19:13:30.474899 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
19:13:30.475454 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
19:13:30.482345 [info ] [MainThread]: 
19:13:30.483345 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
19:13:30.485348 [info ] [MainThread]: 
19:13:30.486347 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
19:13:30.487348 [error] [MainThread]:   each UNION query must have the same number of columns
19:13:30.489347 [error] [MainThread]:   LINE 31:    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_...
19:13:30.490346 [error] [MainThread]:                      ^
19:13:30.492705 [info ] [MainThread]: 
19:13:30.493706 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
19:13:30.495781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E95BE3490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E95CB6A00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E94B483D0>]}


============================== 2022-03-29 19:15:51.437962 | 48956c4d-1371-4f60-9712-fde0df0729b1 ==============================
19:15:51.437962 [info ] [MainThread]: Running with dbt=1.0.3
19:15:51.448659 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
19:15:51.449658 [debug] [MainThread]: Tracking: tracking
19:15:51.478095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A063EC2B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A063EC8B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A063EC7F0>]}
19:15:51.527357 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
19:15:51.535640 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
19:15:51.545787 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
19:15:51.550498 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
19:15:51.577417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '48956c4d-1371-4f60-9712-fde0df0729b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A0654A0D0>]}
19:15:51.585744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48956c4d-1371-4f60-9712-fde0df0729b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A06463730>]}
19:15:51.585744 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
19:15:51.588042 [info ] [MainThread]: 
19:15:51.589040 [debug] [MainThread]: Acquiring new postgres connection "master"
19:15:51.590067 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
19:15:51.604434 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
19:15:51.606277 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
19:15:51.606277 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:15:51.676145 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.07 seconds
19:15:51.684117 [debug] [ThreadPool]: On list_recon-cortex: Close
19:15:51.691263 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
19:15:51.710904 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:15:51.711736 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
19:15:51.711736 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:15:51.781312 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
19:15:51.788035 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:15:51.789206 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
19:15:51.798460 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
19:15:51.801676 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
19:15:51.809890 [debug] [ThreadPool]: On list_recon-cortex_public: Close
19:15:51.857765 [debug] [MainThread]: Using postgres connection "master"
19:15:51.872222 [debug] [MainThread]: On master: BEGIN
19:15:51.872222 [debug] [MainThread]: Opening a new connection, currently in state init
19:15:51.944359 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
19:15:51.945376 [debug] [MainThread]: Using postgres connection "master"
19:15:51.947479 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
19:15:52.909225 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
19:15:52.912118 [debug] [MainThread]: On master: ROLLBACK
19:15:52.917299 [debug] [MainThread]: Using postgres connection "master"
19:15:52.922642 [debug] [MainThread]: On master: BEGIN
19:15:52.934136 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
19:15:52.936141 [debug] [MainThread]: On master: COMMIT
19:15:52.937786 [debug] [MainThread]: Using postgres connection "master"
19:15:52.939207 [debug] [MainThread]: On master: COMMIT
19:15:52.942289 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:15:52.946595 [debug] [MainThread]: On master: Close
19:15:52.948591 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
19:15:52.950229 [info ] [MainThread]: 
19:15:52.958914 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
19:15:52.959913 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
19:15:52.963235 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
19:15:52.964292 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
19:15:52.964292 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
19:15:52.973166 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
19:15:52.975175 [debug] [Thread-1  ]: finished collecting timing info
19:15:52.976175 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
19:15:53.041789 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:15:53.043324 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp004553009408"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
19:15:53.043324 [debug] [Thread-1  ]: Opening a new connection, currently in state init
19:15:53.099698 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.06 seconds
19:15:53.112874 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:15:53.113868 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
19:15:53.118865 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
19:15:53.120887 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:15:53.121867 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp004553009408'
        
      order by ordinal_position

  
19:15:53.135513 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
19:15:53.143870 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:15:53.143870 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
19:15:53.154847 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
19:15:53.173229 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:15:53.174455 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
19:15:53.182296 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
19:15:53.203307 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
19:15:53.205276 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:15:53.205276 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp004553009408"
    )
  
19:15:53.212113 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
19:15:53.225358 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
19:15:53.226355 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:15:53.227354 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
19:15:53.234545 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
19:15:53.235548 [debug] [Thread-1  ]: finished collecting timing info
19:15:53.235548 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
19:15:53.236830 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48956c4d-1371-4f60-9712-fde0df0729b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A05312D00>]}
19:15:53.237834 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.28s]
19:15:53.239381 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
19:15:53.241381 [debug] [MainThread]: Acquiring new postgres connection "master"
19:15:53.242382 [debug] [MainThread]: Using postgres connection "master"
19:15:53.243381 [debug] [MainThread]: On master: BEGIN
19:15:53.244386 [debug] [MainThread]: Opening a new connection, currently in state closed
19:15:53.299259 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
19:15:53.299259 [debug] [MainThread]: On master: COMMIT
19:15:53.300260 [debug] [MainThread]: Using postgres connection "master"
19:15:53.300260 [debug] [MainThread]: On master: COMMIT
19:15:53.306267 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
19:15:53.306585 [debug] [MainThread]: On master: Close
19:15:53.307589 [info ] [MainThread]: 
19:15:53.309584 [info ] [MainThread]: Finished running 1 incremental model in 1.72s.
19:15:53.310589 [debug] [MainThread]: Connection 'master' was properly closed.
19:15:53.311589 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
19:15:53.312585 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
19:15:53.312585 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
19:15:53.322484 [info ] [MainThread]: 
19:15:53.324484 [info ] [MainThread]: [32mCompleted successfully[0m
19:15:53.326505 [info ] [MainThread]: 
19:15:53.328507 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
19:15:53.331054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A052F2AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A052F2490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A052F2E80>]}


============================== 2022-03-29 19:20:26.829617 | c5ff9647-44d2-43f3-9818-f0be67321acb ==============================
19:20:26.829617 [info ] [MainThread]: Running with dbt=1.0.3
19:20:26.839465 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
19:20:26.839465 [debug] [MainThread]: Tracking: tracking
19:20:26.865613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F5C91FC70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F5C91F8B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F5C91F6D0>]}
19:20:26.915702 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
19:20:26.923551 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
19:20:26.934818 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
19:20:26.953242 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
19:20:26.964788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c5ff9647-44d2-43f3-9818-f0be67321acb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F5CA780D0>]}
19:20:26.973047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c5ff9647-44d2-43f3-9818-f0be67321acb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F5C914940>]}
19:20:26.974048 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
19:20:26.976097 [info ] [MainThread]: 
19:20:26.976733 [debug] [MainThread]: Acquiring new postgres connection "master"
19:20:26.978733 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
19:20:26.988955 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
19:20:26.988955 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
19:20:26.992089 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:20:27.046080 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.05 seconds
19:20:27.048243 [debug] [ThreadPool]: On list_recon-cortex: Close
19:20:27.052911 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
19:20:27.063600 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:20:27.071707 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
19:20:27.072594 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:20:27.132203 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
19:20:27.139244 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:20:27.140258 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
19:20:27.149194 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
19:20:27.151164 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
19:20:27.174904 [debug] [ThreadPool]: On list_recon-cortex_public: Close
19:20:27.216909 [debug] [MainThread]: Using postgres connection "master"
19:20:27.232485 [debug] [MainThread]: On master: BEGIN
19:20:27.232485 [debug] [MainThread]: Opening a new connection, currently in state init
19:20:27.306857 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
19:20:27.307906 [debug] [MainThread]: Using postgres connection "master"
19:20:27.308888 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
19:20:28.256657 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
19:20:28.266706 [debug] [MainThread]: On master: ROLLBACK
19:20:28.271532 [debug] [MainThread]: Using postgres connection "master"
19:20:28.271532 [debug] [MainThread]: On master: BEGIN
19:20:28.320105 [debug] [MainThread]: SQL status: BEGIN in 0.04 seconds
19:20:28.321532 [debug] [MainThread]: On master: COMMIT
19:20:28.321532 [debug] [MainThread]: Using postgres connection "master"
19:20:28.322801 [debug] [MainThread]: On master: COMMIT
19:20:28.328038 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:20:28.331302 [debug] [MainThread]: On master: Close
19:20:28.333265 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
19:20:28.336534 [info ] [MainThread]: 
19:20:28.359388 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
19:20:28.361378 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
19:20:28.364330 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
19:20:28.365331 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
19:20:28.366591 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
19:20:28.380214 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
19:20:28.382871 [debug] [Thread-1  ]: finished collecting timing info
19:20:28.383883 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
19:20:28.449076 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:20:28.450076 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp005028428043"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
19:20:28.450076 [debug] [Thread-1  ]: Opening a new connection, currently in state init
19:20:28.503209 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column "cod_drcr" does not exist
LINE 175:     cod_drcr as column17,
              ^

19:20:28.504216 [debug] [Thread-1  ]: finished collecting timing info
19:20:28.504216 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
19:20:28.505214 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  column "cod_drcr" does not exist
  LINE 175:     cod_drcr as column17,
                ^
19:20:28.505214 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c5ff9647-44d2-43f3-9818-f0be67321acb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F5CACF040>]}
19:20:28.530053 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.14s]
19:20:28.532054 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
19:20:28.534053 [debug] [MainThread]: Acquiring new postgres connection "master"
19:20:28.534053 [debug] [MainThread]: Using postgres connection "master"
19:20:28.535053 [debug] [MainThread]: On master: BEGIN
19:20:28.535053 [debug] [MainThread]: Opening a new connection, currently in state closed
19:20:28.608035 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
19:20:28.609030 [debug] [MainThread]: On master: COMMIT
19:20:28.609030 [debug] [MainThread]: Using postgres connection "master"
19:20:28.610032 [debug] [MainThread]: On master: COMMIT
19:20:28.616673 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
19:20:28.617860 [debug] [MainThread]: On master: Close
19:20:28.619005 [info ] [MainThread]: 
19:20:28.620005 [info ] [MainThread]: Finished running 1 incremental model in 1.64s.
19:20:28.621005 [debug] [MainThread]: Connection 'master' was properly closed.
19:20:28.622005 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
19:20:28.623007 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
19:20:28.623007 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
19:20:28.629558 [info ] [MainThread]: 
19:20:28.630554 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
19:20:28.632928 [info ] [MainThread]: 
19:20:28.635718 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
19:20:28.638124 [error] [MainThread]:   column "cod_drcr" does not exist
19:20:28.639484 [error] [MainThread]:   LINE 175:     cod_drcr as column17,
19:20:28.640496 [error] [MainThread]:                 ^
19:20:28.641485 [info ] [MainThread]: 
19:20:28.642487 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
19:20:28.644654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F5B7C8F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F5C984400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F5B9283A0>]}


============================== 2022-03-29 19:21:35.308346 | aa877f19-a048-43e5-a9dd-f4871fc10f83 ==============================
19:21:35.308346 [info ] [MainThread]: Running with dbt=1.0.3
19:21:35.310080 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
19:21:35.310080 [debug] [MainThread]: Tracking: tracking
19:21:35.334295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F418A2C730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F418A2C520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F418A2C5E0>]}
19:21:35.382570 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
19:21:35.382570 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
19:21:35.386957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aa877f19-a048-43e5-a9dd-f4871fc10f83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F418B1C0D0>]}
19:21:35.396354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aa877f19-a048-43e5-a9dd-f4871fc10f83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F418A60BB0>]}
19:21:35.396354 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
19:21:35.397742 [info ] [MainThread]: 
19:21:35.398835 [debug] [MainThread]: Acquiring new postgres connection "master"
19:21:35.400846 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
19:21:35.405946 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
19:21:35.413934 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
19:21:35.414932 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:21:35.676554 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.26 seconds
19:21:35.680696 [debug] [ThreadPool]: On list_recon-cortex: Close
19:21:35.682159 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
19:21:35.686356 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:21:35.686356 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
19:21:35.689520 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:21:35.777161 [debug] [ThreadPool]: SQL status: BEGIN in 0.09 seconds
19:21:35.778846 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:21:35.780184 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
19:21:35.789956 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
19:21:35.792703 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
19:21:35.800861 [debug] [ThreadPool]: On list_recon-cortex_public: Close
19:21:35.812288 [debug] [MainThread]: Using postgres connection "master"
19:21:35.823430 [debug] [MainThread]: On master: BEGIN
19:21:35.824426 [debug] [MainThread]: Opening a new connection, currently in state init
19:21:35.936007 [debug] [MainThread]: SQL status: BEGIN in 0.11 seconds
19:21:35.936007 [debug] [MainThread]: Using postgres connection "master"
19:21:35.940998 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
19:21:36.887527 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
19:21:36.892009 [debug] [MainThread]: On master: ROLLBACK
19:21:36.896208 [debug] [MainThread]: Using postgres connection "master"
19:21:36.900540 [debug] [MainThread]: On master: BEGIN
19:21:36.910052 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
19:21:36.911068 [debug] [MainThread]: On master: COMMIT
19:21:36.913117 [debug] [MainThread]: Using postgres connection "master"
19:21:36.914130 [debug] [MainThread]: On master: COMMIT
19:21:36.916126 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:21:36.921251 [debug] [MainThread]: On master: Close
19:21:36.923437 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
19:21:36.926311 [info ] [MainThread]: 
19:21:36.949264 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
19:21:36.950269 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
19:21:36.953266 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
19:21:36.953266 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
19:21:36.954264 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
19:21:36.971753 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
19:21:37.014857 [debug] [Thread-1  ]: finished collecting timing info
19:21:37.024253 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
19:21:37.097673 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:21:37.097673 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp005137061721"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
19:21:37.110313 [debug] [Thread-1  ]: Opening a new connection, currently in state init
19:21:37.189495 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column "cod_drcr" does not exist
LINE 175:     cod_drcr as column17,
              ^

19:21:37.190497 [debug] [Thread-1  ]: finished collecting timing info
19:21:37.191498 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
19:21:37.192497 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  column "cod_drcr" does not exist
  LINE 175:     cod_drcr as column17,
                ^
19:21:37.193499 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa877f19-a048-43e5-a9dd-f4871fc10f83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F418BE74C0>]}
19:21:37.193499 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.24s]
19:21:37.195503 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
19:21:37.197495 [debug] [MainThread]: Acquiring new postgres connection "master"
19:21:37.198680 [debug] [MainThread]: Using postgres connection "master"
19:21:37.198680 [debug] [MainThread]: On master: BEGIN
19:21:37.198680 [debug] [MainThread]: Opening a new connection, currently in state closed
19:21:37.253952 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
19:21:37.254992 [debug] [MainThread]: On master: COMMIT
19:21:37.254992 [debug] [MainThread]: Using postgres connection "master"
19:21:37.255993 [debug] [MainThread]: On master: COMMIT
19:21:37.259996 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:21:37.261024 [debug] [MainThread]: On master: Close
19:21:37.264330 [info ] [MainThread]: 
19:21:37.266327 [info ] [MainThread]: Finished running 1 incremental model in 1.87s.
19:21:37.267356 [debug] [MainThread]: Connection 'master' was properly closed.
19:21:37.268425 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
19:21:37.269429 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
19:21:37.270697 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
19:21:37.287038 [info ] [MainThread]: 
19:21:37.288033 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
19:21:37.290223 [info ] [MainThread]: 
19:21:37.292365 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
19:21:37.294365 [error] [MainThread]:   column "cod_drcr" does not exist
19:21:37.298310 [error] [MainThread]:   LINE 175:     cod_drcr as column17,
19:21:37.302720 [error] [MainThread]:                 ^
19:21:37.303719 [info ] [MainThread]: 
19:21:37.305915 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
19:21:37.306969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F418BB2CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F418BB2CA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F418BCA5B0>]}


============================== 2022-03-29 19:23:05.111859 | 5163b304-8590-4064-9eed-dbeb9236f146 ==============================
19:23:05.111859 [info ] [MainThread]: Running with dbt=1.0.3
19:23:05.118056 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
19:23:05.118056 [debug] [MainThread]: Tracking: tracking
19:23:05.144289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFC23EF640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFC23EFBB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFC23EF580>]}
19:23:05.197360 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
19:23:05.198325 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
19:23:05.203345 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
19:23:05.227489 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
19:23:05.239704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5163b304-8590-4064-9eed-dbeb9236f146', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFC25490D0>]}
19:23:05.249380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5163b304-8590-4064-9eed-dbeb9236f146', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFC24624F0>]}
19:23:05.249380 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
19:23:05.251301 [info ] [MainThread]: 
19:23:05.252928 [debug] [MainThread]: Acquiring new postgres connection "master"
19:23:05.253969 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
19:23:05.262976 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
19:23:05.262976 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
19:23:05.268523 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:23:05.357165 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.09 seconds
19:23:05.364029 [debug] [ThreadPool]: On list_recon-cortex: Close
19:23:05.369161 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
19:23:05.374664 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:23:05.374664 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
19:23:05.388739 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:23:05.468485 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
19:23:05.470244 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:23:05.471461 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
19:23:05.479781 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
19:23:05.482867 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
19:23:05.493403 [debug] [ThreadPool]: On list_recon-cortex_public: Close
19:23:05.536516 [debug] [MainThread]: Using postgres connection "master"
19:23:05.536516 [debug] [MainThread]: On master: BEGIN
19:23:05.548385 [debug] [MainThread]: Opening a new connection, currently in state init
19:23:05.623382 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
19:23:05.625648 [debug] [MainThread]: Using postgres connection "master"
19:23:05.626656 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
19:23:06.585064 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
19:23:06.593302 [debug] [MainThread]: On master: ROLLBACK
19:23:06.601189 [debug] [MainThread]: Using postgres connection "master"
19:23:06.602237 [debug] [MainThread]: On master: BEGIN
19:23:06.613960 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
19:23:06.615699 [debug] [MainThread]: On master: COMMIT
19:23:06.617062 [debug] [MainThread]: Using postgres connection "master"
19:23:06.618212 [debug] [MainThread]: On master: COMMIT
19:23:06.621453 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:23:06.625994 [debug] [MainThread]: On master: Close
19:23:06.628081 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
19:23:06.631502 [info ] [MainThread]: 
19:23:06.654517 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
19:23:06.658547 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
19:23:06.661502 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
19:23:06.662495 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
19:23:06.663832 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
19:23:06.676942 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
19:23:06.680234 [debug] [Thread-1  ]: finished collecting timing info
19:23:06.681236 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
19:23:06.734588 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:23:06.734588 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp005306719367"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.* from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
19:23:06.738195 [debug] [Thread-1  ]: Opening a new connection, currently in state init
19:23:06.813142 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.07 seconds
19:23:06.845298 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:23:06.847679 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
19:23:06.852441 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
19:23:06.853661 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:23:06.854668 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp005306719367'
        
      order by ordinal_position

  
19:23:06.867115 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
19:23:06.868126 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:23:06.868126 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
19:23:07.010218 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.13 seconds
19:23:07.044043 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:23:07.049469 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
19:23:07.060951 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
19:23:07.078680 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
19:23:07.080280 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:23:07.080280 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp005306719367"
    )
  
19:23:07.086687 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
19:23:07.088668 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
19:23:07.088668 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:23:07.097462 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
19:23:07.101744 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
19:23:07.106766 [debug] [Thread-1  ]: finished collecting timing info
19:23:07.108176 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
19:23:07.109289 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5163b304-8590-4064-9eed-dbeb9236f146', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFC14079A0>]}
19:23:07.110551 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.45s]
19:23:07.113080 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
19:23:07.116070 [debug] [MainThread]: Acquiring new postgres connection "master"
19:23:07.116536 [debug] [MainThread]: Using postgres connection "master"
19:23:07.118251 [debug] [MainThread]: On master: BEGIN
19:23:07.119251 [debug] [MainThread]: Opening a new connection, currently in state closed
19:23:07.187000 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
19:23:07.194684 [debug] [MainThread]: On master: COMMIT
19:23:07.195680 [debug] [MainThread]: Using postgres connection "master"
19:23:07.196584 [debug] [MainThread]: On master: COMMIT
19:23:07.201253 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:23:07.202267 [debug] [MainThread]: On master: Close
19:23:07.203253 [info ] [MainThread]: 
19:23:07.205260 [info ] [MainThread]: Finished running 1 incremental model in 1.95s.
19:23:07.206376 [debug] [MainThread]: Connection 'master' was properly closed.
19:23:07.207387 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
19:23:07.208378 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
19:23:07.209419 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
19:23:07.222345 [info ] [MainThread]: 
19:23:07.223350 [info ] [MainThread]: [32mCompleted successfully[0m
19:23:07.227363 [info ] [MainThread]: 
19:23:07.230552 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
19:23:07.231552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFC13FA460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFC13FA7C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CFC13F08E0>]}


============================== 2022-03-29 19:30:14.538120 | bee3406c-5bb6-4f3b-943e-58f3cdc132eb ==============================
19:30:14.538120 [info ] [MainThread]: Running with dbt=1.0.3
19:30:14.549432 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
19:30:14.549432 [debug] [MainThread]: Tracking: tracking
19:30:14.583375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002803616C910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002803616CBB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002803616C9A0>]}
19:30:14.657185 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
19:30:14.665463 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
19:30:14.673632 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
19:30:14.682014 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
19:30:14.706902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bee3406c-5bb6-4f3b-943e-58f3cdc132eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000280372960D0>]}
19:30:14.714038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bee3406c-5bb6-4f3b-943e-58f3cdc132eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000280361C89A0>]}
19:30:14.714038 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
19:30:14.716023 [info ] [MainThread]: 
19:30:14.717241 [debug] [MainThread]: Acquiring new postgres connection "master"
19:30:14.719267 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
19:30:14.728413 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
19:30:14.732811 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
19:30:14.732811 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:30:14.848003 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.12 seconds
19:30:14.854704 [debug] [ThreadPool]: On list_recon-cortex: Close
19:30:14.862939 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
19:30:14.888901 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:30:14.891209 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
19:30:14.892214 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:30:14.960063 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
19:30:14.964878 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:30:14.965890 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
19:30:14.975994 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
19:30:14.978679 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
19:30:14.994083 [debug] [ThreadPool]: On list_recon-cortex_public: Close
19:30:15.052245 [debug] [MainThread]: Using postgres connection "master"
19:30:15.053783 [debug] [MainThread]: On master: BEGIN
19:30:15.053783 [debug] [MainThread]: Opening a new connection, currently in state init
19:30:15.129176 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
19:30:15.130203 [debug] [MainThread]: Using postgres connection "master"
19:30:15.131169 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
19:30:16.082537 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
19:30:16.094323 [debug] [MainThread]: On master: ROLLBACK
19:30:16.098993 [debug] [MainThread]: Using postgres connection "master"
19:30:16.103787 [debug] [MainThread]: On master: BEGIN
19:30:16.116398 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
19:30:16.117400 [debug] [MainThread]: On master: COMMIT
19:30:16.117400 [debug] [MainThread]: Using postgres connection "master"
19:30:16.117400 [debug] [MainThread]: On master: COMMIT
19:30:16.119675 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:30:16.123918 [debug] [MainThread]: On master: Close
19:30:16.125214 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
19:30:16.126857 [info ] [MainThread]: 
19:30:16.142606 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
19:30:16.145827 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
19:30:16.148131 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
19:30:16.149132 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
19:30:16.149132 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
19:30:16.165256 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
19:30:16.168353 [debug] [Thread-1  ]: finished collecting timing info
19:30:16.168353 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
19:30:16.224472 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:30:16.224472 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp010016208375"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        null as agreement_no,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        null as agreement_no,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        null as agreement_no,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        null as agreement_no,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
19:30:16.226632 [debug] [Thread-1  ]: Opening a new connection, currently in state init
19:30:16.339813 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.11 seconds
19:30:16.366329 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:30:16.366329 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
19:30:16.376895 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
19:30:16.379820 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:30:16.379820 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp010016208375'
        
      order by ordinal_position

  
19:30:16.392847 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
19:30:16.394992 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:30:16.394992 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
19:30:16.409751 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.0 seconds
19:30:16.434127 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:30:16.434127 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
19:30:16.445969 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
19:30:16.464747 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
19:30:16.471764 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:30:16.472767 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp010016208375"
    )
  
19:30:16.788513 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.31 seconds
19:30:16.791158 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
19:30:16.791158 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:30:16.799851 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
19:30:16.805902 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
19:30:16.806911 [debug] [Thread-1  ]: finished collecting timing info
19:30:16.808495 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
19:30:16.809536 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bee3406c-5bb6-4f3b-943e-58f3cdc132eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028036159B20>]}
19:30:16.810538 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.66s]
19:30:16.813937 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
19:30:16.817157 [debug] [MainThread]: Acquiring new postgres connection "master"
19:30:16.818648 [debug] [MainThread]: Using postgres connection "master"
19:30:16.818648 [debug] [MainThread]: On master: BEGIN
19:30:16.819995 [debug] [MainThread]: Opening a new connection, currently in state closed
19:30:16.888955 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
19:30:16.892181 [debug] [MainThread]: On master: COMMIT
19:30:16.892181 [debug] [MainThread]: Using postgres connection "master"
19:30:16.894180 [debug] [MainThread]: On master: COMMIT
19:30:16.899445 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:30:16.900452 [debug] [MainThread]: On master: Close
19:30:16.901286 [info ] [MainThread]: 
19:30:16.903804 [info ] [MainThread]: Finished running 1 incremental model in 2.18s.
19:30:16.904817 [debug] [MainThread]: Connection 'master' was properly closed.
19:30:16.906806 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
19:30:16.907903 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
19:30:16.907903 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
19:30:16.919890 [info ] [MainThread]: 
19:30:16.921911 [info ] [MainThread]: [32mCompleted successfully[0m
19:30:16.924888 [info ] [MainThread]: 
19:30:16.927975 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
19:30:16.929973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028035CAD070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028035CEFEE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000280361684F0>]}


============================== 2022-03-29 19:36:36.913719 | b287c271-9003-4a9b-8af9-9a7406e2cf3d ==============================
19:36:36.913719 [info ] [MainThread]: Running with dbt=1.0.3
19:36:36.917412 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
19:36:36.917412 [debug] [MainThread]: Tracking: tracking
19:36:36.946643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BC41FC310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BC41FC880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BC41FC910>]}
19:36:37.009240 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
19:36:37.009240 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
19:36:37.022236 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
19:36:37.028289 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
19:36:37.054023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b287c271-9003-4a9b-8af9-9a7406e2cf3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BC53290D0>]}
19:36:37.062099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b287c271-9003-4a9b-8af9-9a7406e2cf3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BC5294700>]}
19:36:37.062099 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
19:36:37.064767 [info ] [MainThread]: 
19:36:37.065573 [debug] [MainThread]: Acquiring new postgres connection "master"
19:36:37.067585 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
19:36:37.082053 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
19:36:37.083488 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
19:36:37.083488 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:36:37.160767 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.08 seconds
19:36:37.164451 [debug] [ThreadPool]: On list_recon-cortex: Close
19:36:37.168634 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
19:36:37.179304 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:36:37.179304 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
19:36:37.186624 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:36:37.261090 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
19:36:37.262655 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:36:37.263921 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
19:36:37.273884 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
19:36:37.274873 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
19:36:37.284755 [debug] [ThreadPool]: On list_recon-cortex_public: Close
19:36:37.325931 [debug] [MainThread]: Using postgres connection "master"
19:36:37.347998 [debug] [MainThread]: On master: BEGIN
19:36:37.349285 [debug] [MainThread]: Opening a new connection, currently in state init
19:36:37.395208 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
19:36:37.398967 [debug] [MainThread]: Using postgres connection "master"
19:36:37.398967 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
19:36:38.343093 [debug] [MainThread]: SQL status: SELECT 0 in 0.94 seconds
19:36:38.354944 [debug] [MainThread]: On master: ROLLBACK
19:36:38.360560 [debug] [MainThread]: Using postgres connection "master"
19:36:38.377222 [debug] [MainThread]: On master: BEGIN
19:36:38.387825 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
19:36:38.389586 [debug] [MainThread]: On master: COMMIT
19:36:38.390843 [debug] [MainThread]: Using postgres connection "master"
19:36:38.392122 [debug] [MainThread]: On master: COMMIT
19:36:38.395369 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:36:38.399013 [debug] [MainThread]: On master: Close
19:36:38.401430 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
19:36:38.403739 [info ] [MainThread]: 
19:36:38.427981 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
19:36:38.429202 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
19:36:38.432213 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
19:36:38.433203 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
19:36:38.434199 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
19:36:38.448272 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
19:36:38.449276 [debug] [Thread-1  ]: finished collecting timing info
19:36:38.450273 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
19:36:38.511650 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:36:38.511650 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp010638493987"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
19:36:38.516637 [debug] [Thread-1  ]: Opening a new connection, currently in state init
19:36:38.590012 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column "agreement_no" does not exist
LINE 183:     agreement_no as column16,
              ^

19:36:38.590976 [debug] [Thread-1  ]: finished collecting timing info
19:36:38.591981 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
19:36:38.592976 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  column "agreement_no" does not exist
  LINE 183:     agreement_no as column16,
                ^
19:36:38.594147 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b287c271-9003-4a9b-8af9-9a7406e2cf3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BC52D9B20>]}
19:36:38.594147 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.16s]
19:36:38.596148 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
19:36:38.598146 [debug] [MainThread]: Acquiring new postgres connection "master"
19:36:38.598146 [debug] [MainThread]: Using postgres connection "master"
19:36:38.599152 [debug] [MainThread]: On master: BEGIN
19:36:38.599549 [debug] [MainThread]: Opening a new connection, currently in state closed
19:36:38.647567 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
19:36:38.650564 [debug] [MainThread]: On master: COMMIT
19:36:38.650564 [debug] [MainThread]: Using postgres connection "master"
19:36:38.651565 [debug] [MainThread]: On master: COMMIT
19:36:38.655815 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:36:38.656817 [debug] [MainThread]: On master: Close
19:36:38.657815 [info ] [MainThread]: 
19:36:38.660816 [info ] [MainThread]: Finished running 1 incremental model in 1.59s.
19:36:38.662848 [debug] [MainThread]: Connection 'master' was properly closed.
19:36:38.664016 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
19:36:38.665018 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
19:36:38.665018 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
19:36:38.672510 [info ] [MainThread]: 
19:36:38.675519 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
19:36:38.678932 [info ] [MainThread]: 
19:36:38.680931 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
19:36:38.683167 [error] [MainThread]:   column "agreement_no" does not exist
19:36:38.685180 [error] [MainThread]:   LINE 183:     agreement_no as column16,
19:36:38.687165 [error] [MainThread]:                 ^
19:36:38.688165 [info ] [MainThread]: 
19:36:38.690166 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
19:36:38.693230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BC52946D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BC5366310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BC41DAB20>]}


============================== 2022-03-29 19:37:12.622096 | 920c7a54-12d9-4eea-bba9-2d080aff9057 ==============================
19:37:12.622096 [info ] [MainThread]: Running with dbt=1.0.3
19:37:12.628175 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
19:37:12.628175 [debug] [MainThread]: Tracking: tracking
19:37:12.652877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023B424AC6A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023B424ACAC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023B424AC610>]}
19:37:12.711833 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
19:37:12.715925 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
19:37:12.717959 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
19:37:12.730438 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
19:37:12.757097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '920c7a54-12d9-4eea-bba9-2d080aff9057', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023B435D70D0>]}
19:37:12.764064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '920c7a54-12d9-4eea-bba9-2d080aff9057', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023B435434C0>]}
19:37:12.765065 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
19:37:12.767733 [info ] [MainThread]: 
19:37:12.768766 [debug] [MainThread]: Acquiring new postgres connection "master"
19:37:12.770765 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
19:37:12.782921 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
19:37:12.784685 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
19:37:12.784685 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:37:12.861089 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.08 seconds
19:37:12.864068 [debug] [ThreadPool]: On list_recon-cortex: Close
19:37:12.867254 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
19:37:12.877333 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:37:12.878583 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
19:37:12.878583 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:37:12.948898 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
19:37:12.950317 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:37:12.951819 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
19:37:12.962145 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
19:37:12.965195 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
19:37:12.975175 [debug] [ThreadPool]: On list_recon-cortex_public: Close
19:37:13.022630 [debug] [MainThread]: Using postgres connection "master"
19:37:13.026036 [debug] [MainThread]: On master: BEGIN
19:37:13.026190 [debug] [MainThread]: Opening a new connection, currently in state init
19:37:13.103959 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
19:37:13.109334 [debug] [MainThread]: Using postgres connection "master"
19:37:13.110621 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
19:37:14.068646 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
19:37:14.074868 [debug] [MainThread]: On master: ROLLBACK
19:37:14.078998 [debug] [MainThread]: Using postgres connection "master"
19:37:14.083467 [debug] [MainThread]: On master: BEGIN
19:37:14.096596 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
19:37:14.098403 [debug] [MainThread]: On master: COMMIT
19:37:14.099776 [debug] [MainThread]: Using postgres connection "master"
19:37:14.100802 [debug] [MainThread]: On master: COMMIT
19:37:14.104031 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:37:14.108080 [debug] [MainThread]: On master: Close
19:37:14.110073 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
19:37:14.113195 [info ] [MainThread]: 
19:37:14.135990 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
19:37:14.138048 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
19:37:14.139990 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
19:37:14.141112 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
19:37:14.142110 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
19:37:14.151048 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
19:37:14.155997 [debug] [Thread-1  ]: finished collecting timing info
19:37:14.156999 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
19:37:14.220074 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:37:14.221716 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp010714196297"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
19:37:14.221716 [debug] [Thread-1  ]: Opening a new connection, currently in state init
19:37:14.292940 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.07 seconds
19:37:14.302409 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:37:14.303410 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
19:37:14.307865 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
19:37:14.307865 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:37:14.308867 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp010714196297'
        
      order by ordinal_position

  
19:37:14.322177 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
19:37:14.330172 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:37:14.330172 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
19:37:14.338549 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
19:37:14.348324 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:37:14.349324 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
19:37:14.527173 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.18 seconds
19:37:14.559353 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
19:37:14.565034 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:37:14.566035 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp010714196297"
    )
  
19:37:14.573298 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
19:37:14.575347 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
19:37:14.575347 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:37:14.590942 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
19:37:14.593429 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
19:37:14.599808 [debug] [Thread-1  ]: finished collecting timing info
19:37:14.601176 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
19:37:14.602366 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '920c7a54-12d9-4eea-bba9-2d080aff9057', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023B423A2970>]}
19:37:14.603364 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.46s]
19:37:14.606366 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
19:37:14.609763 [debug] [MainThread]: Acquiring new postgres connection "master"
19:37:14.610762 [debug] [MainThread]: Using postgres connection "master"
19:37:14.610762 [debug] [MainThread]: On master: BEGIN
19:37:14.611665 [debug] [MainThread]: Opening a new connection, currently in state closed
19:37:14.677428 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
19:37:14.682467 [debug] [MainThread]: On master: COMMIT
19:37:14.682467 [debug] [MainThread]: Using postgres connection "master"
19:37:14.683792 [debug] [MainThread]: On master: COMMIT
19:37:14.688679 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:37:14.689839 [debug] [MainThread]: On master: Close
19:37:14.690838 [info ] [MainThread]: 
19:37:14.692845 [info ] [MainThread]: Finished running 1 incremental model in 1.92s.
19:37:14.694845 [debug] [MainThread]: Connection 'master' was properly closed.
19:37:14.695845 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
19:37:14.696846 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
19:37:14.698025 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
19:37:14.710522 [info ] [MainThread]: 
19:37:14.711917 [info ] [MainThread]: [32mCompleted successfully[0m
19:37:14.714926 [info ] [MainThread]: 
19:37:14.717289 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
19:37:14.721082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023B4203B520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023B41FF7760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023B424A8820>]}


============================== 2022-03-29 19:58:02.965324 | e8028225-cc51-4f40-b76c-5f5e472e5678 ==============================
19:58:02.965324 [info ] [MainThread]: Running with dbt=1.0.3
19:58:02.977259 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
19:58:02.977259 [debug] [MainThread]: Tracking: tracking
19:58:03.005559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA2F8AC2B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA2F8ACA90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA2F8AC220>]}
19:58:03.063376 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
19:58:03.067365 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
19:58:03.070737 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
19:58:03.082574 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
19:58:03.109821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e8028225-cc51-4f40-b76c-5f5e472e5678', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA2FA090D0>]}
19:58:03.118366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e8028225-cc51-4f40-b76c-5f5e472e5678', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA2F974730>]}
19:58:03.118366 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
19:58:03.120514 [info ] [MainThread]: 
19:58:03.121453 [debug] [MainThread]: Acquiring new postgres connection "master"
19:58:03.123447 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
19:58:03.134311 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
19:58:03.134311 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
19:58:03.138685 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:58:03.205277 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.07 seconds
19:58:03.213163 [debug] [ThreadPool]: On list_recon-cortex: Close
19:58:03.220509 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
19:58:03.231229 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:58:03.239362 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
19:58:03.240241 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:58:03.322081 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
19:58:03.334062 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:58:03.335312 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
19:58:03.345172 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
19:58:03.348022 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
19:58:03.357448 [debug] [ThreadPool]: On list_recon-cortex_public: Close
19:58:03.406069 [debug] [MainThread]: Using postgres connection "master"
19:58:03.406069 [debug] [MainThread]: On master: BEGIN
19:58:03.409560 [debug] [MainThread]: Opening a new connection, currently in state init
19:58:03.479842 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
19:58:03.488132 [debug] [MainThread]: Using postgres connection "master"
19:58:03.489485 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
19:58:04.447466 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
19:58:04.460838 [debug] [MainThread]: On master: ROLLBACK
19:58:04.463816 [debug] [MainThread]: Using postgres connection "master"
19:58:04.468245 [debug] [MainThread]: On master: BEGIN
19:58:04.474494 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
19:58:04.480171 [debug] [MainThread]: On master: COMMIT
19:58:04.480171 [debug] [MainThread]: Using postgres connection "master"
19:58:04.481522 [debug] [MainThread]: On master: COMMIT
19:58:04.484049 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:58:04.488705 [debug] [MainThread]: On master: Close
19:58:04.489901 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
19:58:04.491089 [info ] [MainThread]: 
19:58:04.503805 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
19:58:04.504801 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
19:58:04.506834 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
19:58:04.507800 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
19:58:04.507800 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
19:58:04.518912 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
19:58:04.520217 [debug] [Thread-1  ]: finished collecting timing info
19:58:04.520217 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
19:58:04.572889 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:58:04.574138 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp012804546491"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.agreement_no = sc.agreement_no)
),
filter_credit_matched_data as (
    select sc.*, agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.agreement_no = sc.agreement_no)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
19:58:04.575145 [debug] [Thread-1  ]: Opening a new connection, currently in state init
19:58:04.620561 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near ")"
LINE 70: ),
         ^

19:58:04.621535 [debug] [Thread-1  ]: finished collecting timing info
19:58:04.621535 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
19:58:04.622369 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  syntax error at or near ")"
  LINE 70: ),
           ^
19:58:04.622369 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8028225-cc51-4f40-b76c-5f5e472e5678', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA2F9A5100>]}
19:58:04.623371 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.12s]
19:58:04.624368 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
19:58:04.626377 [debug] [MainThread]: Acquiring new postgres connection "master"
19:58:04.627371 [debug] [MainThread]: Using postgres connection "master"
19:58:04.627371 [debug] [MainThread]: On master: BEGIN
19:58:04.628372 [debug] [MainThread]: Opening a new connection, currently in state closed
19:58:04.679035 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
19:58:04.680041 [debug] [MainThread]: On master: COMMIT
19:58:04.680041 [debug] [MainThread]: Using postgres connection "master"
19:58:04.681033 [debug] [MainThread]: On master: COMMIT
19:58:04.688238 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
19:58:04.688238 [debug] [MainThread]: On master: Close
19:58:04.689245 [info ] [MainThread]: 
19:58:04.690238 [info ] [MainThread]: Finished running 1 incremental model in 1.57s.
19:58:04.693500 [debug] [MainThread]: Connection 'master' was properly closed.
19:58:04.695508 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
19:58:04.695508 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
19:58:04.696508 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
19:58:04.706389 [info ] [MainThread]: 
19:58:04.707387 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
19:58:04.711286 [info ] [MainThread]: 
19:58:04.713290 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
19:58:04.715713 [error] [MainThread]:   syntax error at or near ")"
19:58:04.717980 [error] [MainThread]:   LINE 70: ),
19:58:04.718985 [error] [MainThread]:            ^
19:58:04.722127 [info ] [MainThread]: 
19:58:04.726571 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
19:58:04.728573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA2FA46D60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA2FA467C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA2E892CD0>]}


============================== 2022-03-29 19:59:53.791722 | a44bb3db-aa15-46b2-ae48-bd1849d08328 ==============================
19:59:53.791722 [info ] [MainThread]: Running with dbt=1.0.3
19:59:53.793237 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
19:59:53.794238 [debug] [MainThread]: Tracking: tracking
19:59:53.818251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292D1EBF6A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292D1EBF5B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292D1EBF5E0>]}
19:59:53.872885 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
19:59:53.879619 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
19:59:53.890023 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
19:59:53.895178 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
19:59:53.932434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a44bb3db-aa15-46b2-ae48-bd1849d08328', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292D2FE90D0>]}
19:59:53.941508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a44bb3db-aa15-46b2-ae48-bd1849d08328', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292D1F844C0>]}
19:59:53.942512 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
19:59:53.944788 [info ] [MainThread]: 
19:59:53.945789 [debug] [MainThread]: Acquiring new postgres connection "master"
19:59:53.947787 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
19:59:53.959114 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
19:59:53.959114 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
19:59:53.965338 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:59:54.037879 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.07 seconds
19:59:54.042915 [debug] [ThreadPool]: On list_recon-cortex: Close
19:59:54.046628 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
19:59:54.056850 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:59:54.057830 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
19:59:54.057830 [debug] [ThreadPool]: Opening a new connection, currently in state init
19:59:54.111789 [debug] [ThreadPool]: SQL status: BEGIN in 0.05 seconds
19:59:54.116116 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
19:59:54.116116 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
19:59:54.125896 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
19:59:54.128069 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
19:59:54.135899 [debug] [ThreadPool]: On list_recon-cortex_public: Close
19:59:54.175405 [debug] [MainThread]: Using postgres connection "master"
19:59:54.179648 [debug] [MainThread]: On master: BEGIN
19:59:54.179648 [debug] [MainThread]: Opening a new connection, currently in state init
19:59:54.253589 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
19:59:54.255678 [debug] [MainThread]: Using postgres connection "master"
19:59:54.256842 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
19:59:55.201986 [debug] [MainThread]: SQL status: SELECT 0 in 0.94 seconds
19:59:55.219073 [debug] [MainThread]: On master: ROLLBACK
19:59:55.224228 [debug] [MainThread]: Using postgres connection "master"
19:59:55.230535 [debug] [MainThread]: On master: BEGIN
19:59:55.240046 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
19:59:55.241821 [debug] [MainThread]: On master: COMMIT
19:59:55.242836 [debug] [MainThread]: Using postgres connection "master"
19:59:55.243942 [debug] [MainThread]: On master: COMMIT
19:59:55.246877 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:59:55.252358 [debug] [MainThread]: On master: Close
19:59:55.254360 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
19:59:55.257359 [info ] [MainThread]: 
19:59:55.271666 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
19:59:55.273675 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
19:59:55.275898 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
19:59:55.277137 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
19:59:55.277137 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
19:59:55.287220 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
19:59:55.287802 [debug] [Thread-1  ]: finished collecting timing info
19:59:55.288800 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
19:59:55.339630 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
19:59:55.339630 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp012955320931"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.agreement_no = sc.agreement_no
),
filter_credit_matched_data as (
    select sc.*, agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.agreement_no = sc.agreement_no
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
19:59:55.345085 [debug] [Thread-1  ]: Opening a new connection, currently in state init
19:59:55.422366 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column reference "agreement_no" is ambiguous
LINE 68:     select sd.*, agreement_no as recon_link_id 
                          ^

19:59:55.424415 [debug] [Thread-1  ]: finished collecting timing info
19:59:55.425246 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
19:59:55.426252 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  column reference "agreement_no" is ambiguous
  LINE 68:     select sd.*, agreement_no as recon_link_id 
                            ^
19:59:55.428293 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a44bb3db-aa15-46b2-ae48-bd1849d08328', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292D1FB4160>]}
19:59:55.429250 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.15s]
19:59:55.432459 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
19:59:55.437472 [debug] [MainThread]: Acquiring new postgres connection "master"
19:59:55.438595 [debug] [MainThread]: Using postgres connection "master"
19:59:55.439791 [debug] [MainThread]: On master: BEGIN
19:59:55.440791 [debug] [MainThread]: Opening a new connection, currently in state closed
19:59:55.540165 [debug] [MainThread]: SQL status: BEGIN in 0.1 seconds
19:59:55.541355 [debug] [MainThread]: On master: COMMIT
19:59:55.543254 [debug] [MainThread]: Using postgres connection "master"
19:59:55.544268 [debug] [MainThread]: On master: COMMIT
19:59:55.547537 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
19:59:55.551330 [debug] [MainThread]: On master: Close
19:59:55.554371 [info ] [MainThread]: 
19:59:55.557009 [info ] [MainThread]: Finished running 1 incremental model in 1.61s.
19:59:55.560021 [debug] [MainThread]: Connection 'master' was properly closed.
19:59:55.561236 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
19:59:55.562952 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
19:59:55.564527 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
19:59:55.582638 [info ] [MainThread]: 
19:59:55.585640 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
19:59:55.589502 [info ] [MainThread]: 
19:59:55.591541 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
19:59:55.593575 [error] [MainThread]:   column reference "agreement_no" is ambiguous
19:59:55.594582 [error] [MainThread]:   LINE 68:     select sd.*, agreement_no as recon_link_id 
19:59:55.595584 [error] [MainThread]:                             ^
19:59:55.596578 [info ] [MainThread]: 
19:59:55.597676 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
19:59:55.599677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292D2FC7130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292D19FF070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292D1E72B80>]}


============================== 2022-03-29 20:00:19.060438 | 0dca889f-d610-4587-8773-c080eacb8a6c ==============================
20:00:19.060438 [info ] [MainThread]: Running with dbt=1.0.3
20:00:19.075824 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
20:00:19.075824 [debug] [MainThread]: Tracking: tracking
20:00:19.101380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218FA38C670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218FA38CA60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218FA38C610>]}
20:00:19.151109 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
20:00:19.159489 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
20:00:19.169913 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
20:00:19.190398 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
20:00:19.201986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0dca889f-d610-4587-8773-c080eacb8a6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218FA4E70D0>]}
20:00:19.209833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0dca889f-d610-4587-8773-c080eacb8a6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218FA453520>]}
20:00:19.210299 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
20:00:19.212326 [info ] [MainThread]: 
20:00:19.213317 [debug] [MainThread]: Acquiring new postgres connection "master"
20:00:19.215355 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
20:00:19.225556 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
20:00:19.225556 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
20:00:19.229740 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:00:19.293719 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.06 seconds
20:00:19.297043 [debug] [ThreadPool]: On list_recon-cortex: Close
20:00:19.301995 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
20:00:19.316620 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:00:19.318237 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
20:00:19.318237 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:00:19.392371 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
20:00:19.395070 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:00:19.396642 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
20:00:19.406525 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
20:00:19.408849 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
20:00:19.417683 [debug] [ThreadPool]: On list_recon-cortex_public: Close
20:00:19.468526 [debug] [MainThread]: Using postgres connection "master"
20:00:19.468526 [debug] [MainThread]: On master: BEGIN
20:00:19.476244 [debug] [MainThread]: Opening a new connection, currently in state init
20:00:19.547052 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
20:00:19.548480 [debug] [MainThread]: Using postgres connection "master"
20:00:19.549482 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
20:00:20.501725 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
20:00:20.501725 [debug] [MainThread]: On master: ROLLBACK
20:00:20.519401 [debug] [MainThread]: Using postgres connection "master"
20:00:20.524057 [debug] [MainThread]: On master: BEGIN
20:00:20.534725 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
20:00:20.536729 [debug] [MainThread]: On master: COMMIT
20:00:20.538048 [debug] [MainThread]: Using postgres connection "master"
20:00:20.538048 [debug] [MainThread]: On master: COMMIT
20:00:20.541279 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:00:20.548554 [debug] [MainThread]: On master: Close
20:00:20.551004 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
20:00:20.553571 [info ] [MainThread]: 
20:00:20.578989 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
20:00:20.580985 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
20:00:20.586634 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
20:00:20.587630 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
20:00:20.587630 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
20:00:20.601130 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
20:00:20.603059 [debug] [Thread-1  ]: finished collecting timing info
20:00:20.604129 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
20:00:20.659849 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:00:20.659979 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp013020637437"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.agreement_no = sc.agreement_no
),
filter_credit_matched_data as (
    select sc.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where sd.agreement_no = sc.agreement_no
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
20:00:20.659979 [debug] [Thread-1  ]: Opening a new connection, currently in state init
20:00:20.742715 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.08 seconds
20:00:20.768990 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:00:20.768990 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
20:00:20.781080 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
20:00:20.781080 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:00:20.782076 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp013020637437'
        
      order by ordinal_position

  
20:00:20.794001 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
20:00:20.795997 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:00:20.795997 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
20:00:20.820512 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
20:00:20.837212 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:00:20.839417 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
20:00:20.850423 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
20:00:20.868342 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
20:00:20.876125 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:00:20.877129 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp013020637437"
    )
  
20:00:20.883891 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
20:00:20.894315 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
20:00:20.894315 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:00:20.899265 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
20:00:20.901533 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
20:00:20.907968 [debug] [Thread-1  ]: finished collecting timing info
20:00:20.909539 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
20:00:20.910538 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0dca889f-d610-4587-8773-c080eacb8a6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218FA38CB50>]}
20:00:20.912077 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.32s]
20:00:20.915112 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
20:00:20.918277 [debug] [MainThread]: Acquiring new postgres connection "master"
20:00:20.919687 [debug] [MainThread]: Using postgres connection "master"
20:00:20.919687 [debug] [MainThread]: On master: BEGIN
20:00:20.920698 [debug] [MainThread]: Opening a new connection, currently in state closed
20:00:20.986491 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
20:00:20.987783 [debug] [MainThread]: On master: COMMIT
20:00:20.987783 [debug] [MainThread]: Using postgres connection "master"
20:00:20.989080 [debug] [MainThread]: On master: COMMIT
20:00:20.991320 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:00:20.995414 [debug] [MainThread]: On master: Close
20:00:20.996487 [info ] [MainThread]: 
20:00:20.998566 [info ] [MainThread]: Finished running 1 incremental model in 1.78s.
20:00:21.000492 [debug] [MainThread]: Connection 'master' was properly closed.
20:00:21.001692 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
20:00:21.002731 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
20:00:21.004163 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
20:00:21.018269 [info ] [MainThread]: 
20:00:21.020268 [info ] [MainThread]: [32mCompleted successfully[0m
20:00:21.023266 [info ] [MainThread]: 
20:00:21.025333 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
20:00:21.027401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218F8F3FEE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218F8F074F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218F9264DF0>]}


============================== 2022-03-29 20:05:12.752249 | 93b5ae73-d5c8-4312-a2eb-a953c7c7a449 ==============================
20:05:12.752249 [info ] [MainThread]: Running with dbt=1.0.3
20:05:12.764080 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
20:05:12.764080 [debug] [MainThread]: Tracking: tracking
20:05:12.790573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002113E95C310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002113E95C910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002113E95C850>]}
20:05:12.848563 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
20:05:12.854377 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
20:05:12.856413 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
20:05:12.885152 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
20:05:12.903429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '93b5ae73-d5c8-4312-a2eb-a953c7c7a449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002113EABA0D0>]}
20:05:12.910913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '93b5ae73-d5c8-4312-a2eb-a953c7c7a449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002113EA24730>]}
20:05:12.910913 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
20:05:12.913396 [info ] [MainThread]: 
20:05:12.913914 [debug] [MainThread]: Acquiring new postgres connection "master"
20:05:12.916915 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
20:05:12.927392 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
20:05:12.927392 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
20:05:12.928391 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:05:13.086180 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.16 seconds
20:05:13.093132 [debug] [ThreadPool]: On list_recon-cortex: Close
20:05:13.101083 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
20:05:13.121945 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:05:13.121945 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
20:05:13.129009 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:05:13.197718 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
20:05:13.204809 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:05:13.204809 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
20:05:13.213155 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
20:05:13.216198 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
20:05:13.221769 [debug] [ThreadPool]: On list_recon-cortex_public: Close
20:05:13.275798 [debug] [MainThread]: Using postgres connection "master"
20:05:13.279822 [debug] [MainThread]: On master: BEGIN
20:05:13.279822 [debug] [MainThread]: Opening a new connection, currently in state init
20:05:13.348127 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
20:05:13.349274 [debug] [MainThread]: Using postgres connection "master"
20:05:13.350274 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
20:05:14.315402 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
20:05:14.318045 [debug] [MainThread]: On master: ROLLBACK
20:05:14.322226 [debug] [MainThread]: Using postgres connection "master"
20:05:14.322226 [debug] [MainThread]: On master: BEGIN
20:05:14.337476 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
20:05:14.339218 [debug] [MainThread]: On master: COMMIT
20:05:14.340213 [debug] [MainThread]: Using postgres connection "master"
20:05:14.341456 [debug] [MainThread]: On master: COMMIT
20:05:14.344688 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:05:14.348712 [debug] [MainThread]: On master: Close
20:05:14.350819 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
20:05:14.353924 [info ] [MainThread]: 
20:05:14.377294 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
20:05:14.380737 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
20:05:14.384890 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
20:05:14.385901 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
20:05:14.387054 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
20:05:14.399820 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
20:05:14.402360 [debug] [Thread-1  ]: finished collecting timing info
20:05:14.402360 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
20:05:14.466977 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:05:14.468738 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp013514443565"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
20:05:14.468738 [debug] [Thread-1  ]: Opening a new connection, currently in state init
20:05:14.554595 [debug] [Thread-1  ]: SQL status: SELECT 4 in 0.09 seconds
20:05:14.558632 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:05:14.558632 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
20:05:14.568700 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
20:05:14.568700 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:05:14.569734 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp013514443565'
        
      order by ordinal_position

  
20:05:14.580050 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
20:05:14.587333 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:05:14.588328 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
20:05:14.596412 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
20:05:14.606732 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:05:14.606732 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
20:05:14.621218 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
20:05:14.636835 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
20:05:14.637837 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:05:14.637837 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp013514443565"
    )
  
20:05:14.644281 [debug] [Thread-1  ]: SQL status: INSERT 0 4 in 0.01 seconds
20:05:14.664605 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
20:05:14.665848 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:05:14.666866 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
20:05:14.670839 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
20:05:14.675224 [debug] [Thread-1  ]: finished collecting timing info
20:05:14.676699 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
20:05:14.677738 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '93b5ae73-d5c8-4312-a2eb-a953c7c7a449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002113EA62E20>]}
20:05:14.679737 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 4[0m in 0.29s]
20:05:14.681840 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
20:05:14.686284 [debug] [MainThread]: Acquiring new postgres connection "master"
20:05:14.687285 [debug] [MainThread]: Using postgres connection "master"
20:05:14.688192 [debug] [MainThread]: On master: BEGIN
20:05:14.689187 [debug] [MainThread]: Opening a new connection, currently in state closed
20:05:14.744476 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
20:05:14.746476 [debug] [MainThread]: On master: COMMIT
20:05:14.747469 [debug] [MainThread]: Using postgres connection "master"
20:05:14.748631 [debug] [MainThread]: On master: COMMIT
20:05:14.751783 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:05:14.754441 [debug] [MainThread]: On master: Close
20:05:14.756437 [info ] [MainThread]: 
20:05:14.758752 [info ] [MainThread]: Finished running 1 incremental model in 1.84s.
20:05:14.760827 [debug] [MainThread]: Connection 'master' was properly closed.
20:05:14.761832 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
20:05:14.762828 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
20:05:14.763826 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
20:05:14.778863 [info ] [MainThread]: 
20:05:14.782244 [info ] [MainThread]: [32mCompleted successfully[0m
20:05:14.785299 [info ] [MainThread]: 
20:05:14.787302 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
20:05:14.790411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002113E93C190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002113E93C1C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002113E92D100>]}


============================== 2022-03-29 20:13:04.587814 | bcee6b99-de41-40a1-8e90-beaca1fc2ee3 ==============================
20:13:04.587814 [info ] [MainThread]: Running with dbt=1.0.3
20:13:04.598986 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
20:13:04.598986 [debug] [MainThread]: Tracking: tracking
20:13:04.636951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002502E71C670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002502E71C610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002502E71C5B0>]}
20:13:04.691948 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
20:13:04.691948 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
20:13:04.699354 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
20:13:04.728020 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
20:13:04.748196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bcee6b99-de41-40a1-8e90-beaca1fc2ee3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002502F8490D0>]}
20:13:04.753187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bcee6b99-de41-40a1-8e90-beaca1fc2ee3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002502F7B4520>]}
20:13:04.753187 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
20:13:04.755184 [info ] [MainThread]: 
20:13:04.756187 [debug] [MainThread]: Acquiring new postgres connection "master"
20:13:04.758272 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
20:13:04.769139 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
20:13:04.769139 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
20:13:04.772460 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:13:04.827835 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.06 seconds
20:13:04.833211 [debug] [ThreadPool]: On list_recon-cortex: Close
20:13:04.837656 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
20:13:04.846464 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:13:04.855249 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
20:13:04.855249 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:13:04.948681 [debug] [ThreadPool]: SQL status: BEGIN in 0.09 seconds
20:13:04.954277 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:13:04.955524 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
20:13:04.966774 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
20:13:04.970005 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
20:13:04.978295 [debug] [ThreadPool]: On list_recon-cortex_public: Close
20:13:05.032121 [debug] [MainThread]: Using postgres connection "master"
20:13:05.032121 [debug] [MainThread]: On master: BEGIN
20:13:05.036784 [debug] [MainThread]: Opening a new connection, currently in state init
20:13:05.138139 [debug] [MainThread]: SQL status: BEGIN in 0.1 seconds
20:13:05.143792 [debug] [MainThread]: Using postgres connection "master"
20:13:05.144839 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
20:13:06.107523 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
20:13:06.124357 [debug] [MainThread]: On master: ROLLBACK
20:13:06.129799 [debug] [MainThread]: Using postgres connection "master"
20:13:06.129799 [debug] [MainThread]: On master: BEGIN
20:13:06.143994 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
20:13:06.145870 [debug] [MainThread]: On master: COMMIT
20:13:06.147260 [debug] [MainThread]: Using postgres connection "master"
20:13:06.148412 [debug] [MainThread]: On master: COMMIT
20:13:06.150693 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:13:06.154391 [debug] [MainThread]: On master: Close
20:13:06.155382 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
20:13:06.158383 [info ] [MainThread]: 
20:13:06.175766 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
20:13:06.178306 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
20:13:06.181313 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
20:13:06.182388 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
20:13:06.183430 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
20:13:06.196815 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
20:13:06.197534 [debug] [Thread-1  ]: finished collecting timing info
20:13:06.197534 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
20:13:06.259015 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:13:06.259015 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp014306239757"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when agreement_no is not null then 
            agreement_no
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when agreement_no is not null then 
            agreement_no
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3 or
    sd.agreement_no = sc.ref_agr1 or 
    sd.agreement_no = sc.ref_agr2 or 
    sd.agreement_no = sc.ref_agr3 )
),
filter_credit_matched_data as (
    select sc.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
20:13:06.263311 [debug] [Thread-1  ]: Opening a new connection, currently in state init
20:13:06.314388 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column reference "agreement_no" is ambiguous
LINE 75:     select sd.*, sd.agreement_no as recon_link_id 
                          ^

20:13:06.315708 [debug] [Thread-1  ]: finished collecting timing info
20:13:06.316859 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
20:13:06.317862 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  column reference "agreement_no" is ambiguous
  LINE 75:     select sd.*, sd.agreement_no as recon_link_id 
                            ^
20:13:06.318893 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcee6b99-de41-40a1-8e90-beaca1fc2ee3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002502E612940>]}
20:13:06.318893 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.14s]
20:13:06.320859 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
20:13:06.322858 [debug] [MainThread]: Acquiring new postgres connection "master"
20:13:06.323936 [debug] [MainThread]: Using postgres connection "master"
20:13:06.323936 [debug] [MainThread]: On master: BEGIN
20:13:06.323936 [debug] [MainThread]: Opening a new connection, currently in state closed
20:13:06.389309 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
20:13:06.390269 [debug] [MainThread]: On master: COMMIT
20:13:06.390269 [debug] [MainThread]: Using postgres connection "master"
20:13:06.390982 [debug] [MainThread]: On master: COMMIT
20:13:06.399044 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
20:13:06.400044 [debug] [MainThread]: On master: Close
20:13:06.401041 [info ] [MainThread]: 
20:13:06.402044 [info ] [MainThread]: Finished running 1 incremental model in 1.64s.
20:13:06.404056 [debug] [MainThread]: Connection 'master' was properly closed.
20:13:06.405213 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
20:13:06.406252 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
20:13:06.406252 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
20:13:06.415326 [info ] [MainThread]: 
20:13:06.416401 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
20:13:06.418404 [info ] [MainThread]: 
20:13:06.419403 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
20:13:06.421957 [error] [MainThread]:   column reference "agreement_no" is ambiguous
20:13:06.423027 [error] [MainThread]:   LINE 75:     select sd.*, sd.agreement_no as recon_link_id 
20:13:06.425315 [error] [MainThread]:                             ^
20:13:06.426310 [info ] [MainThread]: 
20:13:06.428307 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
20:13:06.430306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002502F7B45B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002502E2674F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002502F8140A0>]}


============================== 2022-03-29 20:19:18.267370 | 70ef9f3d-0997-4bcd-a263-c32dba72cc75 ==============================
20:19:18.267370 [info ] [MainThread]: Running with dbt=1.0.3
20:19:18.339575 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
20:19:18.341673 [debug] [MainThread]: Tracking: tracking
20:19:18.396516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ABCCA7F6D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ABCCA7F550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ABCCA7F610>]}
20:19:18.504451 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
20:19:18.513801 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
20:19:18.515835 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
20:19:18.527888 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
20:19:18.553021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '70ef9f3d-0997-4bcd-a263-c32dba72cc75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ABCCBDA0D0>]}
20:19:18.560666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '70ef9f3d-0997-4bcd-a263-c32dba72cc75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ABCCB44520>]}
20:19:18.561669 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
20:19:18.563809 [info ] [MainThread]: 
20:19:18.565438 [debug] [MainThread]: Acquiring new postgres connection "master"
20:19:18.566648 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
20:19:18.580056 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
20:19:18.580056 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
20:19:18.582590 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:19:18.660866 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.08 seconds
20:19:18.668513 [debug] [ThreadPool]: On list_recon-cortex: Close
20:19:18.672306 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
20:19:18.677539 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:19:18.689697 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
20:19:18.689697 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:19:18.767405 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
20:19:18.768594 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:19:18.770256 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
20:19:18.781601 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
20:19:18.784030 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
20:19:18.793134 [debug] [ThreadPool]: On list_recon-cortex_public: Close
20:19:18.853393 [debug] [MainThread]: Using postgres connection "master"
20:19:18.854007 [debug] [MainThread]: On master: BEGIN
20:19:18.855012 [debug] [MainThread]: Opening a new connection, currently in state init
20:19:18.937391 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
20:19:18.947961 [debug] [MainThread]: Using postgres connection "master"
20:19:18.948966 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
20:19:19.909729 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
20:19:19.910785 [debug] [MainThread]: On master: ROLLBACK
20:19:19.917898 [debug] [MainThread]: Using postgres connection "master"
20:19:19.920960 [debug] [MainThread]: On master: BEGIN
20:19:19.932867 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
20:19:19.934926 [debug] [MainThread]: On master: COMMIT
20:19:19.935987 [debug] [MainThread]: Using postgres connection "master"
20:19:19.936270 [debug] [MainThread]: On master: COMMIT
20:19:19.940497 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:19:19.944541 [debug] [MainThread]: On master: Close
20:19:19.946748 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
20:19:19.949381 [info ] [MainThread]: 
20:19:19.961290 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
20:19:19.962293 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
20:19:19.964532 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
20:19:19.965533 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
20:19:19.965533 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
20:19:19.973677 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
20:19:19.974711 [debug] [Thread-1  ]: finished collecting timing info
20:19:19.974711 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
20:19:20.023199 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:19:20.031445 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp014920011483"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when s.agreement_no is not null then 
            s.agreement_no
        when length(s.ref_agr1) > 7 and length(s.ref_agr1) <14 then
            s.ref_agr1
        when length(s.ref_agr2) > 7 and length(s.ref_agr2) <14 then
            s.ref_agr2
        when length(s.ref_agr3) > 7 and length(s.ref_agr3) <14 then
            s.ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when s.agreement_no is not null then 
            s.agreement_no
        when length(s.ref_agr1) > 7 and length(s.ref_agr1) <14 then
            s.ref_agr1
        when length(s.ref_agr2) > 7 and length(s.ref_agr2) <14 then
            s.ref_agr2
        when length(s.ref_agr3) > 7 and length(s.ref_agr3) <14 then
            s.ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3 or
    sd.agreement_no = sc.ref_agr1 or 
    sd.agreement_no = sc.ref_agr2 or 
    sd.agreement_no = sc.ref_agr3 )
),
filter_credit_matched_data as (
    select sc.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
20:19:20.031445 [debug] [Thread-1  ]: Opening a new connection, currently in state init
20:19:20.081529 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column reference "agreement_no" is ambiguous
LINE 75:     select sd.*, sd.agreement_no as recon_link_id 
                          ^

20:19:20.082775 [debug] [Thread-1  ]: finished collecting timing info
20:19:20.082775 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
20:19:20.083783 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  column reference "agreement_no" is ambiguous
  LINE 75:     select sd.*, sd.agreement_no as recon_link_id 
                            ^
20:19:20.084781 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '70ef9f3d-0997-4bcd-a263-c32dba72cc75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ABCB9A2940>]}
20:19:20.085777 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.12s]
20:19:20.086777 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
20:19:20.089130 [debug] [MainThread]: Acquiring new postgres connection "master"
20:19:20.090127 [debug] [MainThread]: Using postgres connection "master"
20:19:20.090127 [debug] [MainThread]: On master: BEGIN
20:19:20.090127 [debug] [MainThread]: Opening a new connection, currently in state closed
20:19:20.137517 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
20:19:20.138521 [debug] [MainThread]: On master: COMMIT
20:19:20.139554 [debug] [MainThread]: Using postgres connection "master"
20:19:20.140553 [debug] [MainThread]: On master: COMMIT
20:19:20.145930 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
20:19:20.145930 [debug] [MainThread]: On master: Close
20:19:20.146931 [info ] [MainThread]: 
20:19:20.147812 [info ] [MainThread]: Finished running 1 incremental model in 1.58s.
20:19:20.148819 [debug] [MainThread]: Connection 'master' was properly closed.
20:19:20.149811 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
20:19:20.149811 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
20:19:20.149811 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
20:19:20.158682 [info ] [MainThread]: 
20:19:20.159701 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
20:19:20.161705 [info ] [MainThread]: 
20:19:20.164093 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
20:19:20.166092 [error] [MainThread]:   column reference "agreement_no" is ambiguous
20:19:20.169640 [error] [MainThread]:   LINE 75:     select sd.*, sd.agreement_no as recon_link_id 
20:19:20.171620 [error] [MainThread]:                             ^
20:19:20.174830 [info ] [MainThread]: 
20:19:20.175838 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
20:19:20.176889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ABCB5EF070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ABCCB445B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ABCCA32BB0>]}


============================== 2022-03-29 20:20:24.726121 | 4fc27428-fbef-4da4-a6c9-c4c91d793756 ==============================
20:20:24.726121 [info ] [MainThread]: Running with dbt=1.0.3
20:20:24.732905 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
20:20:24.732905 [debug] [MainThread]: Tracking: tracking
20:20:24.770511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A86A9370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A968CB20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A968C820>]}
20:20:24.832857 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
20:20:24.832857 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
20:20:24.835893 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
20:20:24.849068 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
20:20:24.874848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4fc27428-fbef-4da4-a6c9-c4c91d793756', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A97E80D0>]}
20:20:24.882833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4fc27428-fbef-4da4-a6c9-c4c91d793756', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A9702970>]}
20:20:24.882833 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
20:20:24.885097 [info ] [MainThread]: 
20:20:24.885543 [debug] [MainThread]: Acquiring new postgres connection "master"
20:20:24.887623 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
20:20:24.901183 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
20:20:24.901183 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
20:20:24.903948 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:20:24.981631 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.08 seconds
20:20:24.986255 [debug] [ThreadPool]: On list_recon-cortex: Close
20:20:24.991669 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
20:20:25.000627 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:20:25.000627 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
20:20:25.011630 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:20:25.083748 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
20:20:25.086689 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:20:25.087734 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
20:20:25.097640 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
20:20:25.102819 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
20:20:25.113003 [debug] [ThreadPool]: On list_recon-cortex_public: Close
20:20:25.159952 [debug] [MainThread]: Using postgres connection "master"
20:20:25.159952 [debug] [MainThread]: On master: BEGIN
20:20:25.164647 [debug] [MainThread]: Opening a new connection, currently in state init
20:20:25.271427 [debug] [MainThread]: SQL status: BEGIN in 0.11 seconds
20:20:25.272486 [debug] [MainThread]: Using postgres connection "master"
20:20:25.274735 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
20:20:26.228781 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
20:20:26.239239 [debug] [MainThread]: On master: ROLLBACK
20:20:26.245652 [debug] [MainThread]: Using postgres connection "master"
20:20:26.248831 [debug] [MainThread]: On master: BEGIN
20:20:26.261386 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
20:20:26.263507 [debug] [MainThread]: On master: COMMIT
20:20:26.264553 [debug] [MainThread]: Using postgres connection "master"
20:20:26.266088 [debug] [MainThread]: On master: COMMIT
20:20:26.268311 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:20:26.274190 [debug] [MainThread]: On master: Close
20:20:26.276462 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
20:20:26.278817 [info ] [MainThread]: 
20:20:26.304181 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
20:20:26.305488 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
20:20:26.308341 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
20:20:26.310346 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
20:20:26.311386 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
20:20:26.328495 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
20:20:26.331632 [debug] [Thread-1  ]: finished collecting timing info
20:20:26.332905 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
20:20:26.381688 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:20:26.387984 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp015026368175"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when s.agreement_no is not null then 
            s.agreement_no
        when length(s.ref_agr1) > 7 and length(s.ref_agr1) <14 then
            s.ref_agr1
        when length(s.ref_agr2) > 7 and length(s.ref_agr2) <14 then
            s.ref_agr2
        when length(s.ref_agr3) > 7 and length(s.ref_agr3) <14 then
            s.ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when s.agreement_no is not null then 
            s.agreement_no
        when length(s.ref_agr1) > 7 and length(s.ref_agr1) <14 then
            s.ref_agr1
        when length(s.ref_agr2) > 7 and length(s.ref_agr2) <14 then
            s.ref_agr2
        when length(s.ref_agr3) > 7 and length(s.ref_agr3) <14 then
            s.ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3  )
),
filter_credit_matched_data as (
    select sc.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
20:20:26.387984 [debug] [Thread-1  ]: Opening a new connection, currently in state init
20:20:26.442042 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column reference "agreement_no" is ambiguous
LINE 75:     select sd.*, sd.agreement_no as recon_link_id 
                          ^

20:20:26.443610 [debug] [Thread-1  ]: finished collecting timing info
20:20:26.444940 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
20:20:26.446979 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  column reference "agreement_no" is ambiguous
  LINE 75:     select sd.*, sd.agreement_no as recon_link_id 
                            ^
20:20:26.448001 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4fc27428-fbef-4da4-a6c9-c4c91d793756', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A97AF0D0>]}
20:20:26.449068 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.14s]
20:20:26.453018 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
20:20:26.457462 [debug] [MainThread]: Acquiring new postgres connection "master"
20:20:26.458466 [debug] [MainThread]: Using postgres connection "master"
20:20:26.459477 [debug] [MainThread]: On master: BEGIN
20:20:26.460541 [debug] [MainThread]: Opening a new connection, currently in state closed
20:20:26.517605 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
20:20:26.518515 [debug] [MainThread]: On master: COMMIT
20:20:26.518515 [debug] [MainThread]: Using postgres connection "master"
20:20:26.520025 [debug] [MainThread]: On master: COMMIT
20:20:26.521021 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:20:26.525823 [debug] [MainThread]: On master: Close
20:20:26.526818 [info ] [MainThread]: 
20:20:26.529652 [info ] [MainThread]: Finished running 1 incremental model in 1.64s.
20:20:26.530658 [debug] [MainThread]: Connection 'master' was properly closed.
20:20:26.531653 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
20:20:26.532650 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
20:20:26.533937 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
20:20:26.544654 [info ] [MainThread]: 
20:20:26.545654 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
20:20:26.547703 [info ] [MainThread]: 
20:20:26.548707 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
20:20:26.551710 [error] [MainThread]:   column reference "agreement_no" is ambiguous
20:20:26.553703 [error] [MainThread]:   LINE 75:     select sd.*, sd.agreement_no as recon_link_id 
20:20:26.554706 [error] [MainThread]:                             ^
20:20:26.554706 [info ] [MainThread]: 
20:20:26.555724 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
20:20:26.556703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A81FD070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A97C96D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9A8672280>]}


============================== 2022-03-29 20:21:29.011589 | 7bfa8f13-bcd8-491f-bd38-061528edd4d3 ==============================
20:21:29.011589 [info ] [MainThread]: Running with dbt=1.0.3
20:21:29.021896 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
20:21:29.021896 [debug] [MainThread]: Tracking: tracking
20:21:29.050120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291ADC9C7C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291ADC9C820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291ADC9C670>]}
20:21:29.104683 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
20:21:29.104683 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
20:21:29.123093 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
20:21:29.142906 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
20:21:29.165772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7bfa8f13-bcd8-491f-bd38-061528edd4d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291ADDF70D0>]}
20:21:29.178365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7bfa8f13-bcd8-491f-bd38-061528edd4d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291ACCAF520>]}
20:21:29.179404 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
20:21:29.181928 [info ] [MainThread]: 
20:21:29.183456 [debug] [MainThread]: Acquiring new postgres connection "master"
20:21:29.185458 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
20:21:29.195795 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
20:21:29.195795 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
20:21:29.200820 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:21:29.257458 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.06 seconds
20:21:29.259807 [debug] [ThreadPool]: On list_recon-cortex: Close
20:21:29.265179 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
20:21:29.280695 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:21:29.281986 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
20:21:29.281986 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:21:29.331072 [debug] [ThreadPool]: SQL status: BEGIN in 0.05 seconds
20:21:29.334950 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:21:29.334950 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
20:21:29.343763 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
20:21:29.346757 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
20:21:29.353524 [debug] [ThreadPool]: On list_recon-cortex_public: Close
20:21:29.405097 [debug] [MainThread]: Using postgres connection "master"
20:21:29.405097 [debug] [MainThread]: On master: BEGIN
20:21:29.410007 [debug] [MainThread]: Opening a new connection, currently in state init
20:21:29.480034 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
20:21:29.482117 [debug] [MainThread]: Using postgres connection "master"
20:21:29.483215 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
20:21:30.438745 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
20:21:30.447194 [debug] [MainThread]: On master: ROLLBACK
20:21:30.453776 [debug] [MainThread]: Using postgres connection "master"
20:21:30.457747 [debug] [MainThread]: On master: BEGIN
20:21:30.469785 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
20:21:30.471333 [debug] [MainThread]: On master: COMMIT
20:21:30.472836 [debug] [MainThread]: Using postgres connection "master"
20:21:30.473886 [debug] [MainThread]: On master: COMMIT
20:21:30.477923 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:21:30.482221 [debug] [MainThread]: On master: Close
20:21:30.484504 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
20:21:30.487046 [info ] [MainThread]: 
20:21:30.511456 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
20:21:30.512465 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
20:21:30.515160 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
20:21:30.516166 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
20:21:30.517162 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
20:21:30.523156 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
20:21:30.530173 [debug] [Thread-1  ]: finished collecting timing info
20:21:30.530173 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
20:21:30.596581 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:21:30.596581 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp015130567324"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when agreement_no is not null then 
            agreement_no
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when agreement_no is not null then 
            agreement_no
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
20:21:30.597581 [debug] [Thread-1  ]: Opening a new connection, currently in state init
20:21:30.650769 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column reference "agreement_no" is ambiguous
LINE 75:     select sd.*, sd.agreement_no as recon_link_id 
                          ^

20:21:30.650769 [debug] [Thread-1  ]: finished collecting timing info
20:21:30.651772 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
20:21:30.651772 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  column reference "agreement_no" is ambiguous
  LINE 75:     select sd.*, sd.agreement_no as recon_link_id 
                            ^
20:21:30.652864 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7bfa8f13-bcd8-491f-bd38-061528edd4d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291ADD7F220>]}
20:21:30.652864 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.14s]
20:21:30.654775 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
20:21:30.656771 [debug] [MainThread]: Acquiring new postgres connection "master"
20:21:30.656771 [debug] [MainThread]: Using postgres connection "master"
20:21:30.657771 [debug] [MainThread]: On master: BEGIN
20:21:30.657771 [debug] [MainThread]: Opening a new connection, currently in state closed
20:21:30.704119 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
20:21:30.705119 [debug] [MainThread]: On master: COMMIT
20:21:30.705119 [debug] [MainThread]: Using postgres connection "master"
20:21:30.706117 [debug] [MainThread]: On master: COMMIT
20:21:30.710370 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:21:30.711406 [debug] [MainThread]: On master: Close
20:21:30.712373 [info ] [MainThread]: 
20:21:30.713415 [info ] [MainThread]: Finished running 1 incremental model in 1.53s.
20:21:30.714417 [debug] [MainThread]: Connection 'master' was properly closed.
20:21:30.714417 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
20:21:30.715416 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
20:21:30.715416 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
20:21:30.724452 [info ] [MainThread]: 
20:21:30.725457 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
20:21:30.727471 [info ] [MainThread]: 
20:21:30.729455 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
20:21:30.732483 [error] [MainThread]:   column reference "agreement_no" is ambiguous
20:21:30.734492 [error] [MainThread]:   LINE 75:     select sd.*, sd.agreement_no as recon_link_id 
20:21:30.736454 [error] [MainThread]:                             ^
20:21:30.738454 [info ] [MainThread]: 
20:21:30.739461 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
20:21:30.741452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291AC817F40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291ADE37E20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291ACB9DCD0>]}


============================== 2022-03-29 20:22:52.885325 | 5dc6d88a-4d06-4c88-9494-82567c2d296e ==============================
20:22:52.885325 [info ] [MainThread]: Running with dbt=1.0.3
20:22:52.895916 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
20:22:52.895916 [debug] [MainThread]: Tracking: tracking
20:22:52.921105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8E9D2C850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8E9D2CA90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8E9D2CA60>]}
20:22:52.979235 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
20:22:52.980233 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
20:22:52.985850 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
20:22:53.010147 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
20:22:53.026330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5dc6d88a-4d06-4c88-9494-82567c2d296e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8E9E880D0>]}
20:22:53.032055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5dc6d88a-4d06-4c88-9494-82567c2d296e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8E9DF3730>]}
20:22:53.032055 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
20:22:53.034213 [info ] [MainThread]: 
20:22:53.035054 [debug] [MainThread]: Acquiring new postgres connection "master"
20:22:53.038133 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
20:22:53.051541 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
20:22:53.052729 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
20:22:53.052729 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:22:53.165655 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.11 seconds
20:22:53.167651 [debug] [ThreadPool]: On list_recon-cortex: Close
20:22:53.172153 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
20:22:53.178004 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:22:53.178004 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
20:22:53.190941 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:22:53.261176 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
20:22:53.261176 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:22:53.262178 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
20:22:53.270927 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
20:22:53.276310 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
20:22:53.278900 [debug] [ThreadPool]: On list_recon-cortex_public: Close
20:22:53.324014 [debug] [MainThread]: Using postgres connection "master"
20:22:53.324014 [debug] [MainThread]: On master: BEGIN
20:22:53.327661 [debug] [MainThread]: Opening a new connection, currently in state init
20:22:53.411868 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
20:22:53.413569 [debug] [MainThread]: Using postgres connection "master"
20:22:53.414583 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
20:22:54.377381 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
20:22:54.382120 [debug] [MainThread]: On master: ROLLBACK
20:22:54.385129 [debug] [MainThread]: Using postgres connection "master"
20:22:54.388873 [debug] [MainThread]: On master: BEGIN
20:22:54.395212 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
20:22:54.398146 [debug] [MainThread]: On master: COMMIT
20:22:54.399185 [debug] [MainThread]: Using postgres connection "master"
20:22:54.400152 [debug] [MainThread]: On master: COMMIT
20:22:54.402194 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:22:54.406797 [debug] [MainThread]: On master: Close
20:22:54.407930 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
20:22:54.410194 [info ] [MainThread]: 
20:22:54.421580 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
20:22:54.422889 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
20:22:54.427317 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
20:22:54.427317 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
20:22:54.428318 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
20:22:54.439619 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
20:22:54.440103 [debug] [Thread-1  ]: finished collecting timing info
20:22:54.440103 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
20:22:54.498494 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:22:54.500498 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp015254471912"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3,
    fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3,
    null as agreement_no from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
20:22:54.502772 [debug] [Thread-1  ]: Opening a new connection, currently in state init
20:22:54.551667 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column reference "agreement_no" is ambiguous
LINE 71:     select sd.*, sd.agreement_no as recon_link_id 
                          ^

20:22:54.551667 [debug] [Thread-1  ]: finished collecting timing info
20:22:54.552666 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
20:22:54.552666 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  column reference "agreement_no" is ambiguous
  LINE 71:     select sd.*, sd.agreement_no as recon_link_id 
                            ^
20:22:54.553673 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5dc6d88a-4d06-4c88-9494-82567c2d296e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8E9E883A0>]}
20:22:54.554667 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.13s]
20:22:54.556670 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
20:22:54.559224 [debug] [MainThread]: Acquiring new postgres connection "master"
20:22:54.560262 [debug] [MainThread]: Using postgres connection "master"
20:22:54.561265 [debug] [MainThread]: On master: BEGIN
20:22:54.562392 [debug] [MainThread]: Opening a new connection, currently in state closed
20:22:54.610862 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
20:22:54.610862 [debug] [MainThread]: On master: COMMIT
20:22:54.612077 [debug] [MainThread]: Using postgres connection "master"
20:22:54.612077 [debug] [MainThread]: On master: COMMIT
20:22:54.617078 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
20:22:54.617078 [debug] [MainThread]: On master: Close
20:22:54.619078 [info ] [MainThread]: 
20:22:54.621138 [info ] [MainThread]: Finished running 1 incremental model in 1.58s.
20:22:54.624077 [debug] [MainThread]: Connection 'master' was properly closed.
20:22:54.625078 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
20:22:54.625078 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
20:22:54.626109 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
20:22:54.632545 [info ] [MainThread]: 
20:22:54.634542 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
20:22:54.636543 [info ] [MainThread]: 
20:22:54.637543 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
20:22:54.638553 [error] [MainThread]:   column reference "agreement_no" is ambiguous
20:22:54.640614 [error] [MainThread]:   LINE 71:     select sd.*, sd.agreement_no as recon_link_id 
20:22:54.642909 [error] [MainThread]:                             ^
20:22:54.647041 [info ] [MainThread]: 
20:22:54.648042 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
20:22:54.651186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8E9EC7E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8E9EC7E20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8E9E88640>]}


============================== 2022-03-29 20:23:59.117850 | 102bb9da-42ad-480f-af25-f18194888c36 ==============================
20:23:59.117850 [info ] [MainThread]: Running with dbt=1.0.3
20:23:59.126873 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
20:23:59.126873 [debug] [MainThread]: Tracking: tracking
20:23:59.251023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CC55BC670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CC55BC5B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CC55BC610>]}
20:23:59.574772 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
20:23:59.574772 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
20:23:59.586746 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
20:23:59.610677 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
20:23:59.625535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '102bb9da-42ad-480f-af25-f18194888c36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CC57180D0>]}
20:23:59.632125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '102bb9da-42ad-480f-af25-f18194888c36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CC5683520>]}
20:23:59.633108 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
20:23:59.634801 [info ] [MainThread]: 
20:23:59.635873 [debug] [MainThread]: Acquiring new postgres connection "master"
20:23:59.638015 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
20:23:59.650150 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
20:23:59.650150 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
20:23:59.653824 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:23:59.707505 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.06 seconds
20:23:59.709508 [debug] [ThreadPool]: On list_recon-cortex: Close
20:23:59.716220 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
20:23:59.725700 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:23:59.734393 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
20:23:59.735393 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:23:59.807518 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
20:23:59.809555 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:23:59.810604 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
20:24:00.132962 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.32 seconds
20:24:00.135981 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
20:24:00.141475 [debug] [ThreadPool]: On list_recon-cortex_public: Close
20:24:00.185846 [debug] [MainThread]: Using postgres connection "master"
20:24:00.185846 [debug] [MainThread]: On master: BEGIN
20:24:00.188173 [debug] [MainThread]: Opening a new connection, currently in state init
20:24:00.261405 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
20:24:00.264465 [debug] [MainThread]: Using postgres connection "master"
20:24:00.264465 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
20:24:01.219391 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
20:24:01.231209 [debug] [MainThread]: On master: ROLLBACK
20:24:01.233431 [debug] [MainThread]: Using postgres connection "master"
20:24:01.237513 [debug] [MainThread]: On master: BEGIN
20:24:01.272654 [debug] [MainThread]: SQL status: BEGIN in 0.04 seconds
20:24:01.273684 [debug] [MainThread]: On master: COMMIT
20:24:01.274698 [debug] [MainThread]: Using postgres connection "master"
20:24:01.274698 [debug] [MainThread]: On master: COMMIT
20:24:01.277683 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:24:01.281235 [debug] [MainThread]: On master: Close
20:24:01.282230 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
20:24:01.283496 [info ] [MainThread]: 
20:24:01.299103 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
20:24:01.301103 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
20:24:01.304580 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
20:24:01.306388 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
20:24:01.307382 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
20:24:01.326357 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
20:24:01.328427 [debug] [Thread-1  ]: finished collecting timing info
20:24:01.329523 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
20:24:01.383044 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:24:01.384670 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp015401359251"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
20:24:01.384670 [debug] [Thread-1  ]: Opening a new connection, currently in state init
20:24:01.438192 [debug] [Thread-1  ]: SQL status: SELECT 4 in 0.05 seconds
20:24:01.453856 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:24:01.469935 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
20:24:01.479087 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
20:24:01.479087 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:24:01.480129 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp015401359251'
        
      order by ordinal_position

  
20:24:01.493328 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
20:24:01.512900 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:24:01.513117 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
20:24:01.522959 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
20:24:01.524959 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:24:01.532761 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
20:24:01.540222 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
20:24:01.548427 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
20:24:01.564553 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:24:01.565552 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp015401359251"
    )
  
20:24:01.574349 [debug] [Thread-1  ]: SQL status: INSERT 0 4 in 0.01 seconds
20:24:01.587061 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
20:24:01.587717 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:24:01.587717 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
20:24:01.592717 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
20:24:01.595658 [debug] [Thread-1  ]: finished collecting timing info
20:24:01.595658 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
20:24:01.596656 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '102bb9da-42ad-480f-af25-f18194888c36', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CC55BC4F0>]}
20:24:01.598088 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 4[0m in 0.29s]
20:24:01.599087 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
20:24:01.601091 [debug] [MainThread]: Acquiring new postgres connection "master"
20:24:01.602087 [debug] [MainThread]: Using postgres connection "master"
20:24:01.602087 [debug] [MainThread]: On master: BEGIN
20:24:01.602087 [debug] [MainThread]: Opening a new connection, currently in state closed
20:24:01.675226 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
20:24:01.676228 [debug] [MainThread]: On master: COMMIT
20:24:01.677223 [debug] [MainThread]: Using postgres connection "master"
20:24:01.678110 [debug] [MainThread]: On master: COMMIT
20:24:01.680150 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:24:01.685912 [debug] [MainThread]: On master: Close
20:24:01.687678 [info ] [MainThread]: 
20:24:01.688988 [info ] [MainThread]: Finished running 1 incremental model in 2.05s.
20:24:01.690984 [debug] [MainThread]: Connection 'master' was properly closed.
20:24:01.691984 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
20:24:01.692984 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
20:24:01.692984 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
20:24:01.721573 [info ] [MainThread]: 
20:24:01.722572 [info ] [MainThread]: [32mCompleted successfully[0m
20:24:01.724573 [info ] [MainThread]: 
20:24:01.725571 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
20:24:01.727575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CC45CEA00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CC45CEC10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CC45BDEB0>]}


============================== 2022-03-29 20:26:29.492448 | dd5acf50-c105-49c4-af33-06baf4cbd7c3 ==============================
20:26:29.492448 [info ] [MainThread]: Running with dbt=1.0.3
20:26:29.495036 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
20:26:29.495036 [debug] [MainThread]: Tracking: tracking
20:26:29.528457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027C7663C6D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027C7663CC10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027C7663C5E0>]}
20:26:30.421810 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
20:26:30.421810 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
20:26:30.441427 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
20:26:30.463658 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
20:26:30.477978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dd5acf50-c105-49c4-af33-06baf4cbd7c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027C7776A0D0>]}
20:26:30.487581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dd5acf50-c105-49c4-af33-06baf4cbd7c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027C776D34C0>]}
20:26:30.488585 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
20:26:30.490848 [info ] [MainThread]: 
20:26:30.491844 [debug] [MainThread]: Acquiring new postgres connection "master"
20:26:30.493847 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
20:26:30.495531 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
20:26:30.506936 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
20:26:30.507216 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:26:30.576002 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.07 seconds
20:26:30.578173 [debug] [ThreadPool]: On list_recon-cortex: Close
20:26:30.582700 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
20:26:30.592237 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:26:30.592237 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
20:26:30.600722 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:26:30.682727 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
20:26:30.684591 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:26:30.686055 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
20:26:30.692739 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
20:26:30.698212 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
20:26:30.707658 [debug] [ThreadPool]: On list_recon-cortex_public: Close
20:26:30.759031 [debug] [MainThread]: Using postgres connection "master"
20:26:30.759031 [debug] [MainThread]: On master: BEGIN
20:26:30.767822 [debug] [MainThread]: Opening a new connection, currently in state init
20:26:30.832721 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
20:26:30.832721 [debug] [MainThread]: Using postgres connection "master"
20:26:30.834374 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
20:26:31.796228 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
20:26:31.797906 [debug] [MainThread]: On master: ROLLBACK
20:26:31.804427 [debug] [MainThread]: Using postgres connection "master"
20:26:31.809004 [debug] [MainThread]: On master: BEGIN
20:26:31.815731 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
20:26:31.821673 [debug] [MainThread]: On master: COMMIT
20:26:31.823023 [debug] [MainThread]: Using postgres connection "master"
20:26:31.824036 [debug] [MainThread]: On master: COMMIT
20:26:31.827698 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:26:31.831994 [debug] [MainThread]: On master: Close
20:26:31.834494 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
20:26:31.837859 [info ] [MainThread]: 
20:26:31.864019 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
20:26:31.865046 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
20:26:31.868021 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
20:26:31.868021 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
20:26:31.869055 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
20:26:31.880315 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
20:26:31.881421 [debug] [Thread-1  ]: finished collecting timing info
20:26:31.881421 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
20:26:31.942396 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:26:31.942396 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp015631921216"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
20:26:31.943690 [debug] [Thread-1  ]: Opening a new connection, currently in state init
20:26:32.008529 [debug] [Thread-1  ]: SQL status: SELECT 4 in 0.06 seconds
20:26:32.017112 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:26:32.018257 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
20:26:32.021968 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
20:26:32.022969 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:26:32.022969 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp015631921216'
        
      order by ordinal_position

  
20:26:32.035548 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
20:26:32.041693 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:26:32.041693 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
20:26:32.053048 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
20:26:32.062146 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:26:32.063142 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
20:26:32.072198 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
20:26:32.084626 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
20:26:32.085630 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:26:32.086660 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp015631921216"
    )
  
20:26:32.092019 [debug] [Thread-1  ]: SQL status: INSERT 0 4 in 0.01 seconds
20:26:32.102056 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
20:26:32.103357 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:26:32.103357 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
20:26:32.110359 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
20:26:32.111356 [debug] [Thread-1  ]: finished collecting timing info
20:26:32.111356 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
20:26:32.113358 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd5acf50-c105-49c4-af33-06baf4cbd7c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027C76532A30>]}
20:26:32.113601 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 4[0m in 0.25s]
20:26:32.115356 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
20:26:32.117358 [debug] [MainThread]: Acquiring new postgres connection "master"
20:26:32.117358 [debug] [MainThread]: Using postgres connection "master"
20:26:32.118397 [debug] [MainThread]: On master: BEGIN
20:26:32.118397 [debug] [MainThread]: Opening a new connection, currently in state closed
20:26:32.163920 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
20:26:32.163920 [debug] [MainThread]: On master: COMMIT
20:26:32.163920 [debug] [MainThread]: Using postgres connection "master"
20:26:32.164923 [debug] [MainThread]: On master: COMMIT
20:26:32.166951 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:26:32.169996 [debug] [MainThread]: On master: Close
20:26:32.169996 [info ] [MainThread]: 
20:26:32.170996 [info ] [MainThread]: Finished running 1 incremental model in 1.68s.
20:26:32.173040 [debug] [MainThread]: Connection 'master' was properly closed.
20:26:32.174011 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
20:26:32.174011 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
20:26:32.174011 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
20:26:32.181850 [info ] [MainThread]: 
20:26:32.182851 [info ] [MainThread]: [32mCompleted successfully[0m
20:26:32.183850 [info ] [MainThread]: 
20:26:32.184853 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
20:26:32.185850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027C761CB520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027C76187F40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027C766377C0>]}


============================== 2022-03-29 20:26:46.328089 | a44988cf-fb3c-4dce-aebd-d3bfc24431e1 ==============================
20:26:46.328089 [info ] [MainThread]: Running with dbt=1.0.3
20:26:46.335129 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
20:26:46.335129 [debug] [MainThread]: Tracking: tracking
20:26:46.359984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002575338A370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002575339CB20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002575339C910>]}
20:26:46.411073 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
20:26:46.412498 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
20:26:46.418608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a44988cf-fb3c-4dce-aebd-d3bfc24431e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002575348B0D0>]}
20:26:46.423675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a44988cf-fb3c-4dce-aebd-d3bfc24431e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002575345EBB0>]}
20:26:46.423675 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
20:26:46.425693 [info ] [MainThread]: 
20:26:46.426715 [debug] [MainThread]: Acquiring new postgres connection "master"
20:26:46.427709 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
20:26:46.439086 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
20:26:46.440089 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
20:26:46.441094 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:26:46.519125 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.08 seconds
20:26:46.529543 [debug] [ThreadPool]: On list_recon-cortex: Close
20:26:46.533183 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
20:26:46.538864 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:26:46.538864 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
20:26:46.549116 [debug] [ThreadPool]: Opening a new connection, currently in state init
20:26:46.623698 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
20:26:46.625199 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
20:26:46.626700 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
20:26:46.635952 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
20:26:46.638135 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
20:26:46.647344 [debug] [ThreadPool]: On list_recon-cortex_public: Close
20:26:46.663355 [debug] [MainThread]: Using postgres connection "master"
20:26:46.670624 [debug] [MainThread]: On master: BEGIN
20:26:46.671642 [debug] [MainThread]: Opening a new connection, currently in state init
20:26:46.779452 [debug] [MainThread]: SQL status: BEGIN in 0.1 seconds
20:26:46.780508 [debug] [MainThread]: Using postgres connection "master"
20:26:46.781812 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
20:26:47.732300 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
20:26:47.732300 [debug] [MainThread]: On master: ROLLBACK
20:26:47.752610 [debug] [MainThread]: Using postgres connection "master"
20:26:47.757874 [debug] [MainThread]: On master: BEGIN
20:26:47.766876 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
20:26:47.768843 [debug] [MainThread]: On master: COMMIT
20:26:47.769840 [debug] [MainThread]: Using postgres connection "master"
20:26:47.770192 [debug] [MainThread]: On master: COMMIT
20:26:47.773424 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:26:47.780098 [debug] [MainThread]: On master: Close
20:26:47.782083 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
20:26:47.784936 [info ] [MainThread]: 
20:26:47.807315 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
20:26:47.810362 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
20:26:47.813819 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
20:26:47.815088 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
20:26:47.817088 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
20:26:47.840914 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
20:26:47.841878 [debug] [Thread-1  ]: finished collecting timing info
20:26:47.842877 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
20:26:47.886850 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:26:47.886850 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp015647870601"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd, filter_credit_source_data sc where (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
20:26:47.894426 [debug] [Thread-1  ]: Opening a new connection, currently in state init
20:26:47.958940 [debug] [Thread-1  ]: SQL status: SELECT 4 in 0.06 seconds
20:26:47.977581 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:26:47.978867 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
20:26:47.982870 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
20:26:47.983867 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:26:47.983867 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp015647870601'
        
      order by ordinal_position

  
20:26:47.994729 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
20:26:48.035486 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:26:48.035486 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
20:26:48.045658 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
20:26:48.057429 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:26:48.061163 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
20:26:48.232341 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.17 seconds
20:26:48.261279 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
20:26:48.263525 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:26:48.263525 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp015647870601"
    )
  
20:26:48.270465 [debug] [Thread-1  ]: SQL status: INSERT 0 4 in 0.01 seconds
20:26:48.275122 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
20:26:48.281591 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
20:26:48.282594 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
20:26:48.285188 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
20:26:48.289175 [debug] [Thread-1  ]: finished collecting timing info
20:26:48.290190 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
20:26:48.291171 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a44988cf-fb3c-4dce-aebd-d3bfc24431e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002575452FD30>]}
20:26:48.291984 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 4[0m in 0.48s]
20:26:48.294027 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
20:26:48.295984 [debug] [MainThread]: Acquiring new postgres connection "master"
20:26:48.296984 [debug] [MainThread]: Using postgres connection "master"
20:26:48.296984 [debug] [MainThread]: On master: BEGIN
20:26:48.297984 [debug] [MainThread]: Opening a new connection, currently in state closed
20:26:48.369254 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
20:26:48.370246 [debug] [MainThread]: On master: COMMIT
20:26:48.371185 [debug] [MainThread]: Using postgres connection "master"
20:26:48.371185 [debug] [MainThread]: On master: COMMIT
20:26:48.373742 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
20:26:48.377544 [debug] [MainThread]: On master: Close
20:26:48.378542 [info ] [MainThread]: 
20:26:48.379958 [info ] [MainThread]: Finished running 1 incremental model in 1.95s.
20:26:48.381965 [debug] [MainThread]: Connection 'master' was properly closed.
20:26:48.384039 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
20:26:48.385049 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
20:26:48.385049 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
20:26:48.397245 [info ] [MainThread]: 
20:26:48.399314 [info ] [MainThread]: [32mCompleted successfully[0m
20:26:48.403375 [info ] [MainThread]: 
20:26:48.405381 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
20:26:48.406992 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257544F29A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257544F2B20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257544F2FD0>]}


============================== 2022-03-30 02:55:26.840882 | cc4f15cb-1ec2-4637-bb44-5571a896aff9 ==============================
02:55:26.840882 [info ] [MainThread]: Running with dbt=1.0.3
02:55:26.851279 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
02:55:26.851279 [debug] [MainThread]: Tracking: tracking
02:55:26.888281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BA80CF640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BA80CFBB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BA80CF580>]}
02:55:26.940281 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
02:55:26.941302 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
02:55:26.952706 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
02:55:26.954740 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
02:55:26.971406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cc4f15cb-1ec2-4637-bb44-5571a896aff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BA82280D0>]}
02:55:26.988547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cc4f15cb-1ec2-4637-bb44-5571a896aff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BA81934F0>]}
02:55:26.988547 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
02:55:26.991200 [info ] [MainThread]: 
02:55:26.992547 [debug] [MainThread]: Acquiring new postgres connection "master"
02:55:26.994548 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
02:55:26.999730 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
02:55:26.999730 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
02:55:27.026877 [debug] [ThreadPool]: Opening a new connection, currently in state init
02:55:27.103729 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.08 seconds
02:55:27.106378 [debug] [ThreadPool]: On list_recon-cortex: Close
02:55:27.109383 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
02:55:27.118102 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
02:55:27.118102 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
02:55:27.123011 [debug] [ThreadPool]: Opening a new connection, currently in state init
02:55:27.176041 [debug] [ThreadPool]: SQL status: BEGIN in 0.05 seconds
02:55:27.179833 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
02:55:27.180840 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
02:55:27.192607 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
02:55:27.193577 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
02:55:27.203936 [debug] [ThreadPool]: On list_recon-cortex_public: Close
02:55:27.246772 [debug] [MainThread]: Using postgres connection "master"
02:55:27.248005 [debug] [MainThread]: On master: BEGIN
02:55:27.248005 [debug] [MainThread]: Opening a new connection, currently in state init
02:55:27.308603 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
02:55:27.308603 [debug] [MainThread]: Using postgres connection "master"
02:55:27.309333 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
02:55:28.268542 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
02:55:28.271357 [debug] [MainThread]: On master: ROLLBACK
02:55:28.275048 [debug] [MainThread]: Using postgres connection "master"
02:55:28.277344 [debug] [MainThread]: On master: BEGIN
02:55:28.286635 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
02:55:28.287636 [debug] [MainThread]: On master: COMMIT
02:55:28.287636 [debug] [MainThread]: Using postgres connection "master"
02:55:28.288929 [debug] [MainThread]: On master: COMMIT
02:55:28.289930 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
02:55:28.294550 [debug] [MainThread]: On master: Close
02:55:28.295604 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
02:55:28.297603 [info ] [MainThread]: 
02:55:28.307598 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
02:55:28.307598 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
02:55:28.309605 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
02:55:28.310603 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
02:55:28.310603 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
02:55:28.320597 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
02:55:28.321606 [debug] [Thread-1  ]: finished collecting timing info
02:55:28.321606 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
02:55:28.378632 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
02:55:28.379727 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp082528356596"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd
    where sd.agreement_no in (
        (
            select dbt_grp.agreement_no
            (select sum(amt_txn) as dbt_grp_amt, agreement_no from filter_debit_source_data group by agreement_no) dbt_grp,
            (select sum(amt_txn as cdt_grp_amt agreement_no from filter_credit_source_data group by agreement_no) cdt_grp
            where dbt_grp.agreement_no = cdt_grp.agreement_no
                and dbt_grp.dbt_grp_amt = cdt_grp.cdt_grp_amt)
        )
    )
    
),
filter_credit_matched_data as (
    select sc.*, sc.agreement_no as recon_link_id 
    from filter_credit_source_data sc where 
    where sc.agreement_no in (
        (
            select cdt_grp.agreement_no
            (select sum(amt_txn) as dbt_grp_amt, agreement_no from filter_debit_source_data group by agreement_no) dbt_grp,
            (select sum(amt_txn as cdt_grp_amt agreement_no from filter_credit_source_data group by agreement_no) cdt_grp
            where dbt_grp.agreement_no = cdt_grp.agreement_no
                and dbt_grp.dbt_grp_amt = cdt_grp.cdt_grp_amt)
        )
    )
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr,
        agreement_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr,
        agreement_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
02:55:28.380599 [debug] [Thread-1  ]: Opening a new connection, currently in state init
02:55:28.454804 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "select"
LINE 77:             (select sum(amt_txn) as dbt_grp_amt, agreement_n...
                      ^

02:55:28.456393 [debug] [Thread-1  ]: finished collecting timing info
02:55:28.458251 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
02:55:28.460744 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  syntax error at or near "select"
  LINE 77:             (select sum(amt_txn) as dbt_grp_amt, agreement_n...
                        ^
02:55:28.462561 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc4f15cb-1ec2-4637-bb44-5571a896aff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BA81AAA00>]}
02:55:28.464563 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.15s]
02:55:28.467765 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
02:55:28.471759 [debug] [MainThread]: Acquiring new postgres connection "master"
02:55:28.472347 [debug] [MainThread]: Using postgres connection "master"
02:55:28.472759 [debug] [MainThread]: On master: BEGIN
02:55:28.473804 [debug] [MainThread]: Opening a new connection, currently in state closed
02:55:28.520686 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
02:55:28.521751 [debug] [MainThread]: On master: COMMIT
02:55:28.521751 [debug] [MainThread]: Using postgres connection "master"
02:55:28.521751 [debug] [MainThread]: On master: COMMIT
02:55:28.526367 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
02:55:28.526701 [debug] [MainThread]: On master: Close
02:55:28.527700 [info ] [MainThread]: 
02:55:28.528704 [info ] [MainThread]: Finished running 1 incremental model in 1.54s.
02:55:28.531702 [debug] [MainThread]: Connection 'master' was properly closed.
02:55:28.532727 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
02:55:28.532727 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
02:55:28.532727 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
02:55:28.537701 [info ] [MainThread]: 
02:55:28.538841 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
02:55:28.539700 [info ] [MainThread]: 
02:55:28.540700 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
02:55:28.543716 [error] [MainThread]:   syntax error at or near "select"
02:55:28.544699 [error] [MainThread]:   LINE 77:             (select sum(amt_txn) as dbt_grp_amt, agreement_n...
02:55:28.545702 [error] [MainThread]:                         ^
02:55:28.546700 [info ] [MainThread]: 
02:55:28.547739 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
02:55:28.548705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BA8193490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BA82591F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017BA80C83D0>]}


============================== 2022-03-30 02:56:07.714367 | eaec7b14-c8c7-46f5-8ad8-232e7dd1cedb ==============================
02:56:07.714367 [info ] [MainThread]: Running with dbt=1.0.3
02:56:07.728722 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
02:56:07.728722 [debug] [MainThread]: Tracking: tracking
02:56:07.760720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002937890C670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002937890CA90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002937890C610>]}
02:56:07.848526 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
02:56:07.849531 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
02:56:07.860528 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
02:56:07.869528 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
02:56:07.894607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eaec7b14-c8c7-46f5-8ad8-232e7dd1cedb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029378A670D0>]}
02:56:07.901208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eaec7b14-c8c7-46f5-8ad8-232e7dd1cedb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293789D3520>]}
02:56:07.902179 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
02:56:07.904795 [info ] [MainThread]: 
02:56:07.906180 [debug] [MainThread]: Acquiring new postgres connection "master"
02:56:07.908587 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
02:56:07.922568 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
02:56:07.923649 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
02:56:07.924873 [debug] [ThreadPool]: Opening a new connection, currently in state init
02:56:08.000688 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.08 seconds
02:56:08.002721 [debug] [ThreadPool]: On list_recon-cortex: Close
02:56:08.004777 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
02:56:08.014720 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
02:56:08.015717 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
02:56:08.016176 [debug] [ThreadPool]: Opening a new connection, currently in state init
02:56:08.079006 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
02:56:08.082410 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
02:56:08.082410 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
02:56:08.087221 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.0 seconds
02:56:08.093538 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
02:56:08.097951 [debug] [ThreadPool]: On list_recon-cortex_public: Close
02:56:08.136462 [debug] [MainThread]: Using postgres connection "master"
02:56:08.136462 [debug] [MainThread]: On master: BEGIN
02:56:08.139689 [debug] [MainThread]: Opening a new connection, currently in state init
02:56:08.211590 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
02:56:08.212926 [debug] [MainThread]: Using postgres connection "master"
02:56:08.212926 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
02:56:09.179517 [debug] [MainThread]: SQL status: SELECT 0 in 0.97 seconds
02:56:09.181964 [debug] [MainThread]: On master: ROLLBACK
02:56:09.186852 [debug] [MainThread]: Using postgres connection "master"
02:56:09.186852 [debug] [MainThread]: On master: BEGIN
02:56:09.197081 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
02:56:09.200580 [debug] [MainThread]: On master: COMMIT
02:56:09.201623 [debug] [MainThread]: Using postgres connection "master"
02:56:09.201623 [debug] [MainThread]: On master: COMMIT
02:56:09.203660 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
02:56:09.208330 [debug] [MainThread]: On master: Close
02:56:09.210460 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
02:56:09.213153 [info ] [MainThread]: 
02:56:09.226596 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
02:56:09.227716 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
02:56:09.230595 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
02:56:09.231594 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
02:56:09.231951 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
02:56:09.242632 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
02:56:09.327483 [debug] [Thread-1  ]: finished collecting timing info
02:56:09.328258 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
02:56:09.386536 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
02:56:09.387517 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp082609368455"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd
    where sd.agreement_no in (
        (
            select dbt_grp.agreement_no from
            (select sum(amt_txn) as dbt_grp_amt, agreement_no from filter_debit_source_data group by agreement_no) dbt_grp,
            (select sum(amt_txn as cdt_grp_amt agreement_no from filter_credit_source_data group by agreement_no) cdt_grp
            where dbt_grp.agreement_no = cdt_grp.agreement_no
                and dbt_grp.dbt_grp_amt = cdt_grp.cdt_grp_amt)
        )
    )
    
),
filter_credit_matched_data as (
    select sc.*, sc.agreement_no as recon_link_id 
    from filter_credit_source_data sc where 
    where sc.agreement_no in (
        (
            select cdt_grp.agreement_no from 
            (select sum(amt_txn) as dbt_grp_amt, agreement_no from filter_debit_source_data group by agreement_no) dbt_grp,
            (select sum(amt_txn as cdt_grp_amt agreement_no from filter_credit_source_data group by agreement_no) cdt_grp
            where dbt_grp.agreement_no = cdt_grp.agreement_no
                and dbt_grp.dbt_grp_amt = cdt_grp.cdt_grp_amt)
        )
    )
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr,
        agreement_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr,
        agreement_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
02:56:09.387777 [debug] [Thread-1  ]: Opening a new connection, currently in state init
02:56:09.460033 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "as"
LINE 78:             (select sum(amt_txn as cdt_grp_amt agreement_no ...
                                         ^

02:56:09.460935 [debug] [Thread-1  ]: finished collecting timing info
02:56:09.461291 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
02:56:09.462290 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  syntax error at or near "as"
  LINE 78:             (select sum(amt_txn as cdt_grp_amt agreement_no ...
                                           ^
02:56:09.462290 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eaec7b14-c8c7-46f5-8ad8-232e7dd1cedb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293789F16A0>]}
02:56:09.463326 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.23s]
02:56:09.465289 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
02:56:09.467287 [debug] [MainThread]: Acquiring new postgres connection "master"
02:56:09.467287 [debug] [MainThread]: Using postgres connection "master"
02:56:09.468285 [debug] [MainThread]: On master: BEGIN
02:56:09.468285 [debug] [MainThread]: Opening a new connection, currently in state closed
02:56:09.550080 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
02:56:09.551078 [debug] [MainThread]: On master: COMMIT
02:56:09.552576 [debug] [MainThread]: Using postgres connection "master"
02:56:09.553120 [debug] [MainThread]: On master: COMMIT
02:56:09.558193 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
02:56:09.559498 [debug] [MainThread]: On master: Close
02:56:09.561122 [info ] [MainThread]: 
02:56:09.562414 [info ] [MainThread]: Finished running 1 incremental model in 1.65s.
02:56:09.564068 [debug] [MainThread]: Connection 'master' was properly closed.
02:56:09.565069 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
02:56:09.566072 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
02:56:09.566072 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
02:56:09.576567 [info ] [MainThread]: 
02:56:09.577078 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
02:56:09.579114 [info ] [MainThread]: 
02:56:09.580066 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
02:56:09.582181 [error] [MainThread]:   syntax error at or near "as"
02:56:09.583068 [error] [MainThread]:   LINE 78:             (select sum(amt_txn as cdt_grp_amt agreement_no ...
02:56:09.587070 [error] [MainThread]:                                            ^
02:56:09.588100 [info ] [MainThread]: 
02:56:09.589068 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
02:56:09.590069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293789D35B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029378AA7B80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029378908AC0>]}


============================== 2022-03-30 02:57:30.246256 | b74c677a-093c-469b-a0bc-5d1b3dfb57bd ==============================
02:57:30.246256 [info ] [MainThread]: Running with dbt=1.0.3
02:57:30.250764 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
02:57:30.250764 [debug] [MainThread]: Tracking: tracking
02:57:30.279764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002367365C880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002367365CA90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002367365CA60>]}
02:57:30.334837 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
02:57:30.334837 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
02:57:30.341686 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
02:57:30.355159 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
02:57:30.381930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b74c677a-093c-469b-a0bc-5d1b3dfb57bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000236737B90D0>]}
02:57:30.388623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b74c677a-093c-469b-a0bc-5d1b3dfb57bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023673723730>]}
02:57:30.389605 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
02:57:30.390602 [info ] [MainThread]: 
02:57:30.392600 [debug] [MainThread]: Acquiring new postgres connection "master"
02:57:30.394848 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
02:57:30.408924 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
02:57:30.409608 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
02:57:30.409608 [debug] [ThreadPool]: Opening a new connection, currently in state init
02:57:30.497412 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.09 seconds
02:57:30.499407 [debug] [ThreadPool]: On list_recon-cortex: Close
02:57:30.501373 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
02:57:30.507219 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
02:57:30.507219 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
02:57:30.510760 [debug] [ThreadPool]: Opening a new connection, currently in state init
02:57:30.608816 [debug] [ThreadPool]: SQL status: BEGIN in 0.1 seconds
02:57:30.611008 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
02:57:30.612004 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
02:57:30.622621 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
02:57:30.625338 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
02:57:30.634244 [debug] [ThreadPool]: On list_recon-cortex_public: Close
02:57:30.682509 [debug] [MainThread]: Using postgres connection "master"
02:57:30.682509 [debug] [MainThread]: On master: BEGIN
02:57:30.682509 [debug] [MainThread]: Opening a new connection, currently in state init
02:57:30.759453 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
02:57:30.764436 [debug] [MainThread]: Using postgres connection "master"
02:57:30.765440 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
02:57:31.726598 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
02:57:31.731933 [debug] [MainThread]: On master: ROLLBACK
02:57:31.736583 [debug] [MainThread]: Using postgres connection "master"
02:57:31.741327 [debug] [MainThread]: On master: BEGIN
02:57:31.748484 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
02:57:31.761578 [debug] [MainThread]: On master: COMMIT
02:57:31.762577 [debug] [MainThread]: Using postgres connection "master"
02:57:31.763579 [debug] [MainThread]: On master: COMMIT
02:57:31.770351 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
02:57:31.772110 [debug] [MainThread]: On master: Close
02:57:31.774487 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
02:57:31.777321 [info ] [MainThread]: 
02:57:31.792977 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
02:57:31.794225 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
02:57:31.796272 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
02:57:31.797200 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
02:57:31.797731 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
02:57:31.800261 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
02:57:31.808288 [debug] [Thread-1  ]: finished collecting timing info
02:57:31.809295 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
02:57:31.872342 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
02:57:31.873312 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp082731848308"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd
    where sd.agreement_no in (
        (
            select dbt_grp.agreement_no from
            (select sum(amt_txn) as dbt_grp_amt, agreement_no from filter_debit_source_data group by agreement_no) dbt_grp,
            (select sum(amt_txn) as cdt_grp_amt agreement_no from filter_credit_source_data group by agreement_no) cdt_grp
            where dbt_grp.agreement_no = cdt_grp.agreement_no
                and dbt_grp.dbt_grp_amt = cdt_grp.cdt_grp_amt
        )
    )
    
),
filter_credit_matched_data as (
    select sc.*, sc.agreement_no as recon_link_id 
    from filter_credit_source_data sc where 
    where sc.agreement_no in (
        (
            select cdt_grp.agreement_no from 
            (select sum(amt_txn) as dbt_grp_amt, agreement_no from filter_debit_source_data group by agreement_no) dbt_grp,
            (select sum(amt_txn) as cdt_grp_amt agreement_no from filter_credit_source_data group by agreement_no) cdt_grp
            where dbt_grp.agreement_no = cdt_grp.agreement_no
                and dbt_grp.dbt_grp_amt = cdt_grp.cdt_grp_amt
        )
    )
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr,
        agreement_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr,
        agreement_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
02:57:31.873312 [debug] [Thread-1  ]: Opening a new connection, currently in state init
02:57:31.939347 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "agreement_no"
LINE 78:             (select sum(amt_txn) as cdt_grp_amt agreement_no...
                                                         ^

02:57:31.940776 [debug] [Thread-1  ]: finished collecting timing info
02:57:31.941387 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
02:57:31.942529 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  syntax error at or near "agreement_no"
  LINE 78:             (select sum(amt_txn) as cdt_grp_amt agreement_no...
                                                           ^
02:57:31.943388 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b74c677a-093c-469b-a0bc-5d1b3dfb57bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002367255DF40>]}
02:57:31.944489 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.15s]
02:57:31.947027 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
02:57:31.949626 [debug] [MainThread]: Acquiring new postgres connection "master"
02:57:31.950117 [debug] [MainThread]: Using postgres connection "master"
02:57:31.951026 [debug] [MainThread]: On master: BEGIN
02:57:31.951026 [debug] [MainThread]: Opening a new connection, currently in state closed
02:57:32.017454 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
02:57:32.019468 [debug] [MainThread]: On master: COMMIT
02:57:32.020452 [debug] [MainThread]: Using postgres connection "master"
02:57:32.020452 [debug] [MainThread]: On master: COMMIT
02:57:32.025128 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
02:57:32.025128 [debug] [MainThread]: On master: Close
02:57:32.025996 [info ] [MainThread]: 
02:57:32.027028 [info ] [MainThread]: Finished running 1 incremental model in 1.63s.
02:57:32.027989 [debug] [MainThread]: Connection 'master' was properly closed.
02:57:32.028991 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
02:57:32.028991 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
02:57:32.028991 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
02:57:32.041990 [info ] [MainThread]: 
02:57:32.042991 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
02:57:32.045023 [info ] [MainThread]: 
02:57:32.045990 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
02:57:32.046987 [error] [MainThread]:   syntax error at or near "agreement_no"
02:57:32.047997 [error] [MainThread]:   LINE 78:             (select sum(amt_txn) as cdt_grp_amt agreement_no...
02:57:32.048989 [error] [MainThread]:                                                            ^
02:57:32.050994 [info ] [MainThread]: 
02:57:32.053027 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
02:57:32.053988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000236737F6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000236737F6790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002367374CDF0>]}


============================== 2022-03-30 02:58:16.593888 | 26b7c035-623d-4375-8b04-f9242ed2e627 ==============================
02:58:16.593888 [info ] [MainThread]: Running with dbt=1.0.3
02:58:16.595326 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
02:58:16.596434 [debug] [MainThread]: Tracking: tracking
02:58:16.625435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D750EC280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D750EC970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D750EC1F0>]}
02:58:16.684432 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
02:58:16.684879 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
02:58:16.696526 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
02:58:16.711723 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
02:58:16.728776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '26b7c035-623d-4375-8b04-f9242ed2e627', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D762190D0>]}
02:58:16.776799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '26b7c035-623d-4375-8b04-f9242ed2e627', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D751B36D0>]}
02:58:16.777829 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
02:58:16.781810 [info ] [MainThread]: 
02:58:16.783558 [debug] [MainThread]: Acquiring new postgres connection "master"
02:58:16.786837 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
02:58:16.805941 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
02:58:16.805941 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
02:58:16.806795 [debug] [ThreadPool]: Opening a new connection, currently in state init
02:58:16.917561 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.11 seconds
02:58:16.919324 [debug] [ThreadPool]: On list_recon-cortex: Close
02:58:16.921654 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
02:58:16.929134 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
02:58:16.932103 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
02:58:16.932103 [debug] [ThreadPool]: Opening a new connection, currently in state init
02:58:16.992310 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
02:58:16.993361 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
02:58:16.993361 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
02:58:17.001503 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
02:58:17.003548 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
02:58:17.011250 [debug] [ThreadPool]: On list_recon-cortex_public: Close
02:58:17.046843 [debug] [MainThread]: Using postgres connection "master"
02:58:17.050328 [debug] [MainThread]: On master: BEGIN
02:58:17.050328 [debug] [MainThread]: Opening a new connection, currently in state init
02:58:17.150539 [debug] [MainThread]: SQL status: BEGIN in 0.1 seconds
02:58:17.152411 [debug] [MainThread]: Using postgres connection "master"
02:58:17.153791 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
02:58:18.116174 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
02:58:18.122242 [debug] [MainThread]: On master: ROLLBACK
02:58:18.127941 [debug] [MainThread]: Using postgres connection "master"
02:58:18.128800 [debug] [MainThread]: On master: BEGIN
02:58:18.134707 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
02:58:18.137914 [debug] [MainThread]: On master: COMMIT
02:58:18.137914 [debug] [MainThread]: Using postgres connection "master"
02:58:18.138914 [debug] [MainThread]: On master: COMMIT
02:58:18.143124 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
02:58:18.143124 [debug] [MainThread]: On master: Close
02:58:18.144165 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
02:58:18.146123 [info ] [MainThread]: 
02:58:18.152803 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
02:58:18.153907 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
02:58:18.155031 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
02:58:18.155563 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
02:58:18.156033 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
02:58:18.162024 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
02:58:18.163772 [debug] [Thread-1  ]: finished collecting timing info
02:58:18.163772 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
02:58:18.222778 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
02:58:18.223650 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp082818199654"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd
    where sd.agreement_no in (
        (
            select dbt_grp.agreement_no from
            (select sum(amt_txn) as dbt_grp_amt, agreement_no from filter_debit_source_data group by agreement_no) dbt_grp,
            (select sum(amt_txn) as cdt_grp_amt, agreement_no from filter_credit_source_data group by agreement_no) cdt_grp
            where dbt_grp.agreement_no = cdt_grp.agreement_no
                and dbt_grp.dbt_grp_amt = cdt_grp.cdt_grp_amt
        )
    )
    
),
filter_credit_matched_data as (
    select sc.*, sc.agreement_no as recon_link_id 
    from filter_credit_source_data sc where 
    where sc.agreement_no in (
        (
            select cdt_grp.agreement_no from 
            (select sum(amt_txn) as dbt_grp_amt, agreement_no from filter_debit_source_data group by agreement_no) dbt_grp,
            (select sum(amt_txn) as cdt_grp_amt, agreement_no from filter_credit_source_data group by agreement_no) cdt_grp
            where dbt_grp.agreement_no = cdt_grp.agreement_no
                and dbt_grp.dbt_grp_amt = cdt_grp.cdt_grp_amt
        )
    )
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr,
        agreement_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr,
        agreement_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
02:58:18.223650 [debug] [Thread-1  ]: Opening a new connection, currently in state init
02:58:18.281835 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "where"
LINE 88:     where sc.agreement_no in (
             ^

02:58:18.282817 [debug] [Thread-1  ]: finished collecting timing info
02:58:18.282817 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
02:58:18.283817 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  syntax error at or near "where"
  LINE 88:     where sc.agreement_no in (
               ^
02:58:18.283817 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26b7c035-623d-4375-8b04-f9242ed2e627', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D75218250>]}
02:58:18.284817 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.13s]
02:58:18.285826 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
02:58:18.288820 [debug] [MainThread]: Acquiring new postgres connection "master"
02:58:18.289630 [debug] [MainThread]: Using postgres connection "master"
02:58:18.289821 [debug] [MainThread]: On master: BEGIN
02:58:18.290945 [debug] [MainThread]: Opening a new connection, currently in state closed
02:58:18.361818 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
02:58:18.361818 [debug] [MainThread]: On master: COMMIT
02:58:18.362818 [debug] [MainThread]: Using postgres connection "master"
02:58:18.362818 [debug] [MainThread]: On master: COMMIT
02:58:18.370832 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
02:58:18.370832 [debug] [MainThread]: On master: Close
02:58:18.371853 [info ] [MainThread]: 
02:58:18.372816 [info ] [MainThread]: Finished running 1 incremental model in 1.59s.
02:58:18.373832 [debug] [MainThread]: Connection 'master' was properly closed.
02:58:18.373832 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
02:58:18.374817 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
02:58:18.374817 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
02:58:18.382821 [info ] [MainThread]: 
02:58:18.384822 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
02:58:18.389821 [info ] [MainThread]: 
02:58:18.390820 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
02:58:18.392818 [error] [MainThread]:   syntax error at or near "where"
02:58:18.393821 [error] [MainThread]:   LINE 88:     where sc.agreement_no in (
02:58:18.394819 [error] [MainThread]:                ^
02:58:18.396819 [info ] [MainThread]: 
02:58:18.397819 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
02:58:18.401828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D751B3700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D76258970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D750CA7C0>]}


============================== 2022-03-30 02:58:42.289450 | 89877caa-7480-42f3-b05b-b126c3ba88cc ==============================
02:58:42.289450 [info ] [MainThread]: Running with dbt=1.0.3
02:58:42.293676 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
02:58:42.293676 [debug] [MainThread]: Tracking: tracking
02:58:42.318386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BD9319C6A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BD9319CB20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BD9319C5E0>]}
02:58:42.382174 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
02:58:42.383176 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
02:58:42.395168 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
02:58:42.415265 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
02:58:42.428051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '89877caa-7480-42f3-b05b-b126c3ba88cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BD942C70D0>]}
02:58:42.436785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '89877caa-7480-42f3-b05b-b126c3ba88cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BD942334C0>]}
02:58:42.436785 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
02:58:42.439487 [info ] [MainThread]: 
02:58:42.440442 [debug] [MainThread]: Acquiring new postgres connection "master"
02:58:42.443449 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
02:58:42.463441 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
02:58:42.464443 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
02:58:42.465448 [debug] [ThreadPool]: Opening a new connection, currently in state init
02:58:42.533469 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.07 seconds
02:58:42.535450 [debug] [ThreadPool]: On list_recon-cortex: Close
02:58:42.537920 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
02:58:42.545449 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
02:58:42.546047 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
02:58:42.546438 [debug] [ThreadPool]: Opening a new connection, currently in state init
02:58:42.587750 [debug] [ThreadPool]: SQL status: BEGIN in 0.04 seconds
02:58:42.587750 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
02:58:42.587750 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
02:58:42.594991 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
02:58:42.597052 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
02:58:42.627600 [debug] [ThreadPool]: On list_recon-cortex_public: Close
02:58:42.658121 [debug] [MainThread]: Using postgres connection "master"
02:58:42.658121 [debug] [MainThread]: On master: BEGIN
02:58:42.661158 [debug] [MainThread]: Opening a new connection, currently in state init
02:58:42.734555 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
02:58:42.735557 [debug] [MainThread]: Using postgres connection "master"
02:58:42.735557 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
02:58:43.705841 [debug] [MainThread]: SQL status: SELECT 0 in 0.97 seconds
02:58:43.710555 [debug] [MainThread]: On master: ROLLBACK
02:58:43.716962 [debug] [MainThread]: Using postgres connection "master"
02:58:43.718784 [debug] [MainThread]: On master: BEGIN
02:58:43.729339 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
02:58:43.731149 [debug] [MainThread]: On master: COMMIT
02:58:43.732594 [debug] [MainThread]: Using postgres connection "master"
02:58:43.733678 [debug] [MainThread]: On master: COMMIT
02:58:43.738798 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
02:58:43.740629 [debug] [MainThread]: On master: Close
02:58:43.742629 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
02:58:43.745863 [info ] [MainThread]: 
02:58:43.755591 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
02:58:43.757596 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
02:58:43.760588 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
02:58:43.760588 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
02:58:43.761592 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
02:58:43.771693 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
02:58:43.773012 [debug] [Thread-1  ]: finished collecting timing info
02:58:43.773012 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
02:58:43.828624 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
02:58:43.829588 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp082843808588"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd
    where sd.agreement_no in (
        (
            select dbt_grp.agreement_no from
            (select sum(amt_txn) as dbt_grp_amt, agreement_no from filter_debit_source_data group by agreement_no) dbt_grp,
            (select sum(amt_txn) as cdt_grp_amt, agreement_no from filter_credit_source_data group by agreement_no) cdt_grp
            where dbt_grp.agreement_no = cdt_grp.agreement_no
                and dbt_grp.dbt_grp_amt = cdt_grp.cdt_grp_amt
        )
    )
    
),
filter_credit_matched_data as (
    select sc.*, sc.agreement_no as recon_link_id 
    from filter_credit_source_data sc  
    where sc.agreement_no in (
        (
            select cdt_grp.agreement_no from 
            (select sum(amt_txn) as dbt_grp_amt, agreement_no from filter_debit_source_data group by agreement_no) dbt_grp,
            (select sum(amt_txn) as cdt_grp_amt, agreement_no from filter_credit_source_data group by agreement_no) cdt_grp
            where dbt_grp.agreement_no = cdt_grp.agreement_no
                and dbt_grp.dbt_grp_amt = cdt_grp.cdt_grp_amt
        )
    )
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr,
        agreement_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr,
        agreement_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
02:58:43.829588 [debug] [Thread-1  ]: Opening a new connection, currently in state init
02:58:43.907820 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.08 seconds
02:58:43.919227 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
02:58:43.919227 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
02:58:43.922163 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
02:58:43.925234 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
02:58:43.926288 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp082843808588'
        
      order by ordinal_position

  
02:58:43.938267 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
02:58:43.945871 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
02:58:43.946911 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
02:58:43.962152 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.02 seconds
02:58:43.973991 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
02:58:43.975313 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
02:58:43.983112 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
02:58:43.994693 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
02:58:43.996305 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
02:58:43.996305 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp082843808588"
    )
  
02:58:44.002756 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
02:58:44.009607 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
02:58:44.011368 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
02:58:44.011368 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
02:58:44.018293 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
02:58:44.018293 [debug] [Thread-1  ]: finished collecting timing info
02:58:44.019327 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
02:58:44.019327 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89877caa-7480-42f3-b05b-b126c3ba88cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BD93092970>]}
02:58:44.020324 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.26s]
02:58:44.021364 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
02:58:44.023396 [debug] [MainThread]: Acquiring new postgres connection "master"
02:58:44.024744 [debug] [MainThread]: Using postgres connection "master"
02:58:44.024822 [debug] [MainThread]: On master: BEGIN
02:58:44.025366 [debug] [MainThread]: Opening a new connection, currently in state closed
02:58:44.077650 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
02:58:44.078363 [debug] [MainThread]: On master: COMMIT
02:58:44.079366 [debug] [MainThread]: Using postgres connection "master"
02:58:44.080368 [debug] [MainThread]: On master: COMMIT
02:58:44.084365 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
02:58:44.085366 [debug] [MainThread]: On master: Close
02:58:44.086369 [info ] [MainThread]: 
02:58:44.087396 [info ] [MainThread]: Finished running 1 incremental model in 1.65s.
02:58:44.088367 [debug] [MainThread]: Connection 'master' was properly closed.
02:58:44.089366 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
02:58:44.090372 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
02:58:44.090372 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
02:58:44.106464 [info ] [MainThread]: 
02:58:44.108446 [info ] [MainThread]: [32mCompleted successfully[0m
02:58:44.109369 [info ] [MainThread]: 
02:58:44.111369 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
02:58:44.113428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BD92CE7CA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BD92CE7760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BD93198550>]}


============================== 2022-03-30 03:16:57.023889 | d86594d1-3465-4f41-bcd4-2290db5dec26 ==============================
03:16:57.023889 [info ] [MainThread]: Running with dbt=1.0.3
03:16:57.033542 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
03:16:57.034544 [debug] [MainThread]: Tracking: tracking
03:16:57.058974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B58B41C280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B58B41C910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B58B41C1F0>]}
03:16:57.279471 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
03:16:57.280471 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
03:16:57.287473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd86594d1-3465-4f41-bcd4-2290db5dec26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B58B50C0D0>]}
03:16:57.292797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd86594d1-3465-4f41-bcd4-2290db5dec26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B58A349400>]}
03:16:57.293339 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
03:16:57.295368 [info ] [MainThread]: 
03:16:57.296341 [debug] [MainThread]: Acquiring new postgres connection "master"
03:16:57.298343 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
03:16:57.312015 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
03:16:57.313006 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
03:16:57.313006 [debug] [ThreadPool]: Opening a new connection, currently in state init
03:16:57.365248 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.05 seconds
03:16:57.368256 [debug] [ThreadPool]: On list_recon-cortex: Close
03:16:57.372254 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
03:16:57.384408 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
03:16:57.384408 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
03:16:57.388432 [debug] [ThreadPool]: Opening a new connection, currently in state init
03:16:57.479531 [debug] [ThreadPool]: SQL status: BEGIN in 0.09 seconds
03:16:57.480527 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
03:16:57.481604 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
03:16:57.497146 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.01 seconds
03:16:57.498144 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
03:16:57.508610 [debug] [ThreadPool]: On list_recon-cortex_public: Close
03:16:57.516763 [debug] [MainThread]: Using postgres connection "master"
03:16:57.518489 [debug] [MainThread]: On master: BEGIN
03:16:57.518489 [debug] [MainThread]: Opening a new connection, currently in state init
03:16:57.581276 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
03:16:57.582288 [debug] [MainThread]: Using postgres connection "master"
03:16:57.583637 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
03:16:58.538324 [debug] [MainThread]: SQL status: SELECT 0 in 0.95 seconds
03:16:58.551678 [debug] [MainThread]: On master: ROLLBACK
03:16:58.554960 [debug] [MainThread]: Using postgres connection "master"
03:16:58.560877 [debug] [MainThread]: On master: BEGIN
03:16:58.567549 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
03:16:58.572404 [debug] [MainThread]: On master: COMMIT
03:16:58.573405 [debug] [MainThread]: Using postgres connection "master"
03:16:58.574411 [debug] [MainThread]: On master: COMMIT
03:16:58.580125 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
03:16:58.580125 [debug] [MainThread]: On master: Close
03:16:58.581139 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
03:16:58.583630 [info ] [MainThread]: 
03:16:58.599187 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
03:16:58.602297 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
03:16:58.604292 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
03:16:58.604292 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
03:16:58.605290 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
03:16:58.625410 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
03:16:58.627444 [debug] [Thread-1  ]: finished collecting timing info
03:16:58.628412 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
03:16:58.691902 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
03:16:58.693908 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp084658665985"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd
    where sd.agreement_no in (
        (
            select dbt_grp.agreement_no from
            (select sum(amt_txn) as dbt_grp_amt, agreement_no from filter_debit_source_data group by agreement_no) dbt_grp,
            (select sum(amt_txn) as cdt_grp_amt, agreement_no from filter_credit_source_data group by agreement_no) cdt_grp
            where dbt_grp.agreement_no = cdt_grp.agreement_no
                and dbt_grp.dbt_grp_amt = cdt_grp.cdt_grp_amt
        )
    )
    
),
filter_credit_matched_data as (
    select sc.*, sc.agreement_no as recon_link_id 
    from filter_credit_source_data sc  
    where sc.agreement_no in (
        (
            select cdt_grp.agreement_no from 
            (select sum(amt_txn) as dbt_grp_amt, agreement_no from filter_debit_source_data group by agreement_no) dbt_grp,
            (select sum(amt_txn) as cdt_grp_amt, agreement_no from filter_credit_source_data group by agreement_no) cdt_grp
            where dbt_grp.agreement_no = cdt_grp.agreement_no
                and dbt_grp.dbt_grp_amt = cdt_grp.cdt_grp_amt
        )
    )
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr,
        agreement_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr,
        agreement_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
03:16:58.694904 [debug] [Thread-1  ]: Opening a new connection, currently in state init
03:16:58.759592 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.06 seconds
03:16:58.777401 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
03:16:58.785015 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
03:16:58.792966 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
03:16:58.793959 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
03:16:58.793959 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp084658665985'
        
      order by ordinal_position

  
03:16:58.810821 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.02 seconds
03:16:58.854608 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
03:16:58.856483 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
03:16:58.866497 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
03:16:58.875912 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
03:16:58.875912 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
03:16:58.884269 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
03:16:58.886298 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
03:16:58.895614 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
03:16:58.895614 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp084658665985"
    )
  
03:16:58.901927 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
03:16:58.902964 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
03:16:58.902964 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
03:16:58.909728 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
03:16:58.922740 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
03:16:58.923753 [debug] [Thread-1  ]: finished collecting timing info
03:16:58.926734 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
03:16:58.930199 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd86594d1-3465-4f41-bcd4-2290db5dec26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B58B5D8190>]}
03:16:58.931485 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.33s]
03:16:58.935888 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
03:16:58.942093 [debug] [MainThread]: Acquiring new postgres connection "master"
03:16:58.943687 [debug] [MainThread]: Using postgres connection "master"
03:16:58.944685 [debug] [MainThread]: On master: BEGIN
03:16:58.945687 [debug] [MainThread]: Opening a new connection, currently in state closed
03:16:58.995461 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
03:16:58.995461 [debug] [MainThread]: On master: COMMIT
03:16:58.995461 [debug] [MainThread]: Using postgres connection "master"
03:16:58.996461 [debug] [MainThread]: On master: COMMIT
03:16:58.999948 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
03:16:59.001276 [debug] [MainThread]: On master: Close
03:16:59.002287 [info ] [MainThread]: 
03:16:59.002976 [info ] [MainThread]: Finished running 1 incremental model in 1.71s.
03:16:59.007157 [debug] [MainThread]: Connection 'master' was properly closed.
03:16:59.008150 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
03:16:59.008150 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
03:16:59.009217 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
03:16:59.017023 [info ] [MainThread]: 
03:16:59.018039 [info ] [MainThread]: [32mCompleted successfully[0m
03:16:59.021321 [info ] [MainThread]: 
03:16:59.022320 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
03:16:59.023626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B58B526F40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B58A342E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B58B5A2A90>]}


============================== 2022-03-30 03:37:34.613196 | a6e2dc5d-bbce-4e07-994d-f49de74fb918 ==============================
03:37:34.613196 [info ] [MainThread]: Running with dbt=1.0.3
03:37:34.626995 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
03:37:34.627997 [debug] [MainThread]: Tracking: tracking
03:37:34.656580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCFEAEC7C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCFEAECB50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCFEAEC5B0>]}
03:37:34.712185 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
03:37:34.712939 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
03:37:34.725462 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
03:37:34.744266 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
03:37:34.756962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a6e2dc5d-bbce-4e07-994d-f49de74fb918', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCFFC1A0D0>]}
03:37:34.765244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a6e2dc5d-bbce-4e07-994d-f49de74fb918', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCFFB31520>]}
03:37:34.765244 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
03:37:34.767817 [info ] [MainThread]: 
03:37:34.769051 [debug] [MainThread]: Acquiring new postgres connection "master"
03:37:34.771047 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
03:37:34.787081 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
03:37:34.788775 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
03:37:34.788775 [debug] [ThreadPool]: Opening a new connection, currently in state init
03:37:34.884266 [debug] [ThreadPool]: SQL status: SELECT 40 in 0.1 seconds
03:37:34.893128 [debug] [ThreadPool]: On list_recon-cortex: Close
03:37:34.900707 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
03:37:34.919849 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
03:37:34.919849 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
03:37:34.927365 [debug] [ThreadPool]: Opening a new connection, currently in state init
03:37:35.008141 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
03:37:35.009968 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
03:37:35.011611 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
03:37:35.047381 [debug] [ThreadPool]: SQL status: SELECT 57 in 0.03 seconds
03:37:35.051394 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
03:37:35.058594 [debug] [ThreadPool]: On list_recon-cortex_public: Close
03:37:35.111915 [debug] [MainThread]: Using postgres connection "master"
03:37:35.125707 [debug] [MainThread]: On master: BEGIN
03:37:35.125707 [debug] [MainThread]: Opening a new connection, currently in state init
03:37:35.213563 [debug] [MainThread]: SQL status: BEGIN in 0.09 seconds
03:37:35.217473 [debug] [MainThread]: Using postgres connection "master"
03:37:35.219160 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
03:37:36.207269 [debug] [MainThread]: SQL status: SELECT 0 in 0.99 seconds
03:37:36.209877 [debug] [MainThread]: On master: ROLLBACK
03:37:36.214774 [debug] [MainThread]: Using postgres connection "master"
03:37:36.218786 [debug] [MainThread]: On master: BEGIN
03:37:36.227547 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
03:37:36.229157 [debug] [MainThread]: On master: COMMIT
03:37:36.229157 [debug] [MainThread]: Using postgres connection "master"
03:37:36.230157 [debug] [MainThread]: On master: COMMIT
03:37:36.233431 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
03:37:36.237490 [debug] [MainThread]: On master: Close
03:37:36.239812 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
03:37:36.243207 [info ] [MainThread]: 
03:37:36.265096 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
03:37:36.266129 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
03:37:36.268328 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
03:37:36.269329 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
03:37:36.270327 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
03:37:36.284157 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
03:37:36.287378 [debug] [Thread-1  ]: finished collecting timing info
03:37:36.287378 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
03:37:36.348337 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
03:37:36.348337 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp090736334186"
  as (
    


with filter_data_source_1 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'D'
),
filter_data_source_2 as (
    select s.* from set2_hdfc_auto s where 
    s.cod_drcr = 'C'
),
filter_ref_file as (
    select s.* from set2_los_rtgs_report s
),
filter_debit_source_enrich1 as (
    select fds1.*, 
    fds2.app_id_c as ref_agr1,
    fds2.app_id_c as ref_agr2,
    fds2.app_id_c as ref_agr3 from filter_data_source_1 fds1, filter_ref_file fds2 
      where fds1.txt_txn_desc like 'RTGS%'
      and fds1.amt_txn = fds2.disb_amount_n
     and trim(right(fds1.txt_txn_desc,22)) = trim(fds2.utr)
    UNION all
   select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3
     from filter_data_source_1 fds2
    where fds2.txt_txn_desc not like 'RTGS%'
),
filter_credit_source_enrich1 as (
    select fds2.*,  trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 1),'[[:alpha:]]','','g'))  as ref_agr1,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-',2),'[[:alpha:]]','','g'))  as ref_agr2,
    trim(regexp_replace(split_part(fds2."txt_txn_desc" , '-', 3),'[[:alpha:]]','','g')) as ref_agr3 from filter_data_source_2 fds2
),
filter_debit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no from filter_debit_source_enrich1 s
),
filter_credit_source_data as (
    select s.*,  
    case 
        when ref_agr1 = ref_agr2 and ref_agr2 = ref_agr3 then
            ref_agr1
        when length(ref_agr1) > 7 and length(ref_agr1) <14 then
            ref_agr1
        when length(ref_agr2) > 7 and length(ref_agr2) <14 then
            ref_agr2
        when length(ref_agr3) > 7 and length(ref_agr3) <14 then
            ref_agr3
        ELSE
            null    
    end as agreement_no  from filter_credit_source_enrich1 s
),
filter_debit_matched_data as (
    select sd.*, sd.agreement_no as recon_link_id 
    from filter_debit_source_data sd
    where sd.agreement_no in (
        (
            select dbt_grp.agreement_no from
            (select sum(amt_txn) as dbt_grp_amt, agreement_no from filter_debit_source_data group by agreement_no) dbt_grp,
            (select sum(amt_txn) as cdt_grp_amt, agreement_no from filter_credit_source_data group by agreement_no) cdt_grp
            where dbt_grp.agreement_no = cdt_grp.agreement_no
                and dbt_grp.dbt_grp_amt = cdt_grp.cdt_grp_amt
        )
    )
    
),
filter_credit_matched_data as (
    select sc.*, sc.agreement_no as recon_link_id 
    from filter_credit_source_data sc  
    where sc.agreement_no in (
        (
            select cdt_grp.agreement_no from 
            (select sum(amt_txn) as dbt_grp_amt, agreement_no from filter_debit_source_data group by agreement_no) dbt_grp,
            (select sum(amt_txn) as cdt_grp_amt, agreement_no from filter_credit_source_data group by agreement_no) cdt_grp
            where dbt_grp.agreement_no = cdt_grp.agreement_no
                and dbt_grp.dbt_grp_amt = cdt_grp.cdt_grp_amt
        )
    )
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3,
        cod_drcr,
        agreement_no from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3,
        cod_drcr,
        agreement_no from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3,
        cod_drcr,
        agreement_no from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3,
        cod_drcr,
        agreement_no from filter_debit_matched_data fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    agreement_no as column16,
    cod_drcr as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
03:37:36.354514 [debug] [Thread-1  ]: Opening a new connection, currently in state init
03:37:36.412352 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.06 seconds
03:37:36.423065 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
03:37:36.424078 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
03:37:36.427624 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
03:37:36.428837 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
03:37:36.428837 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp090736334186'
        
      order by ordinal_position

  
03:37:36.439186 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
03:37:36.447182 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
03:37:36.447182 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
03:37:36.457235 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
03:37:36.471870 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
03:37:36.471870 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
03:37:36.481849 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
03:37:36.500594 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
03:37:36.501595 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
03:37:36.502596 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp090736334186"
    )
  
03:37:36.508605 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
03:37:36.518728 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
03:37:36.519724 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
03:37:36.519724 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
03:37:36.526800 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
03:37:36.527801 [debug] [Thread-1  ]: finished collecting timing info
03:37:36.528800 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
03:37:36.529801 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6e2dc5d-bbce-4e07-994d-f49de74fb918', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCFEAEC400>]}
03:37:36.529801 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.26s]
03:37:36.531801 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
03:37:36.532800 [debug] [MainThread]: Acquiring new postgres connection "master"
03:37:36.534379 [debug] [MainThread]: Using postgres connection "master"
03:37:36.534802 [debug] [MainThread]: On master: BEGIN
03:37:36.535576 [debug] [MainThread]: Opening a new connection, currently in state closed
03:37:36.584227 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
03:37:36.586489 [debug] [MainThread]: On master: COMMIT
03:37:36.587480 [debug] [MainThread]: Using postgres connection "master"
03:37:36.589238 [debug] [MainThread]: On master: COMMIT
03:37:36.596143 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
03:37:36.597142 [debug] [MainThread]: On master: Close
03:37:36.600962 [info ] [MainThread]: 
03:37:36.603396 [info ] [MainThread]: Finished running 1 incremental model in 1.83s.
03:37:36.607636 [debug] [MainThread]: Connection 'master' was properly closed.
03:37:36.608637 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
03:37:36.610632 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
03:37:36.611634 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
03:37:36.634643 [info ] [MainThread]: 
03:37:36.637751 [info ] [MainThread]: [32mCompleted successfully[0m
03:37:36.643422 [info ] [MainThread]: 
03:37:36.647933 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
03:37:36.652776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCFEAD0A00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCFEAD0C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FCFE9E2640>]}
