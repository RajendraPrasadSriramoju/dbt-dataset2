

============================== 2022-03-21 18:08:36.288224 | 0633fd83-c442-4121-903f-83293091a0f8 ==============================
18:08:36.288224 [info ] [MainThread]: Running with dbt=1.0.3
18:08:36.289274 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
18:08:36.290730 [debug] [MainThread]: Tracking: tracking
18:08:36.325731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984D0B8FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984D0B8FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984D0B8C70>]}
18:08:36.365486 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
18:08:36.370285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0633fd83-c442-4121-903f-83293091a0f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984D0B5940>]}
18:08:37.218667 [debug] [MainThread]: Parsing macros\adapters.sql
18:08:37.323849 [debug] [MainThread]: Parsing macros\catalog.sql
18:08:37.323849 [debug] [MainThread]: Parsing macros\relations.sql
18:08:37.340255 [debug] [MainThread]: Parsing macros\materializations\snapshot_merge.sql
18:08:37.342300 [debug] [MainThread]: Parsing macros\adapters\columns.sql
18:08:37.344473 [debug] [MainThread]: Parsing macros\adapters\freshness.sql
18:08:37.344473 [debug] [MainThread]: Parsing macros\adapters\indexes.sql
18:08:37.344473 [debug] [MainThread]: Parsing macros\adapters\metadata.sql
18:08:37.362102 [debug] [MainThread]: Parsing macros\adapters\persist_docs.sql
18:08:37.362102 [debug] [MainThread]: Parsing macros\adapters\relation.sql
18:08:37.379264 [debug] [MainThread]: Parsing macros\adapters\schema.sql
18:08:37.381117 [debug] [MainThread]: Parsing macros\etc\datetime.sql
18:08:37.383461 [debug] [MainThread]: Parsing macros\etc\statement.sql
18:08:37.383461 [debug] [MainThread]: Parsing macros\generic_test_sql\accepted_values.sql
18:08:37.383461 [debug] [MainThread]: Parsing macros\generic_test_sql\not_null.sql
18:08:37.395926 [debug] [MainThread]: Parsing macros\generic_test_sql\relationships.sql
18:08:37.396910 [debug] [MainThread]: Parsing macros\generic_test_sql\unique.sql
18:08:37.398177 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_alias.sql
18:08:37.399159 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_database.sql
18:08:37.401618 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_schema.sql
18:08:37.403294 [debug] [MainThread]: Parsing macros\materializations\configs.sql
18:08:37.405747 [debug] [MainThread]: Parsing macros\materializations\hooks.sql
18:08:37.408243 [debug] [MainThread]: Parsing macros\materializations\models\incremental\column_helpers.sql
18:08:37.408243 [debug] [MainThread]: Parsing macros\materializations\models\incremental\incremental.sql
18:08:37.408243 [debug] [MainThread]: Parsing macros\materializations\models\incremental\is_incremental.sql
18:08:37.425522 [debug] [MainThread]: Parsing macros\materializations\models\incremental\merge.sql
18:08:37.427552 [debug] [MainThread]: Parsing macros\materializations\models\incremental\on_schema_change.sql
18:08:37.443318 [debug] [MainThread]: Parsing macros\materializations\models\table\create_table_as.sql
18:08:37.443318 [debug] [MainThread]: Parsing macros\materializations\models\table\table.sql
18:08:37.458943 [debug] [MainThread]: Parsing macros\materializations\models\view\create_or_replace_view.sql
18:08:37.458943 [debug] [MainThread]: Parsing macros\materializations\models\view\create_view_as.sql
18:08:37.458943 [debug] [MainThread]: Parsing macros\materializations\models\view\helpers.sql
18:08:37.458943 [debug] [MainThread]: Parsing macros\materializations\models\view\view.sql
18:08:37.467164 [debug] [MainThread]: Parsing macros\materializations\seeds\helpers.sql
18:08:37.482878 [debug] [MainThread]: Parsing macros\materializations\seeds\seed.sql
18:08:37.482878 [debug] [MainThread]: Parsing macros\materializations\snapshots\helpers.sql
18:08:37.498500 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot.sql
18:08:37.498500 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot_merge.sql
18:08:37.514882 [debug] [MainThread]: Parsing macros\materializations\snapshots\strategies.sql
18:08:37.531154 [debug] [MainThread]: Parsing macros\materializations\tests\helpers.sql
18:08:37.535788 [debug] [MainThread]: Parsing macros\materializations\tests\test.sql
18:08:37.542330 [debug] [MainThread]: Parsing macros\materializations\tests\where_subquery.sql
18:08:37.544332 [debug] [MainThread]: Parsing tests\generic\builtin.sql
18:08:37.769255 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
18:08:37.795988 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
18:08:37.825439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0633fd83-c442-4121-903f-83293091a0f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984CC71040>]}
18:08:37.906491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0633fd83-c442-4121-903f-83293091a0f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984CC71820>]}
18:08:37.908970 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
18:08:37.916176 [info ] [MainThread]: 
18:08:37.921044 [debug] [MainThread]: Acquiring new postgres connection "master"
18:08:37.927564 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
18:08:37.954808 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
18:08:37.955883 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
18:08:37.955883 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:08:38.022442 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.07 seconds
18:08:38.023439 [debug] [ThreadPool]: On list_recon-cortex: Close
18:08:38.029227 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
18:08:38.038510 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:08:38.046556 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
18:08:38.047813 [debug] [ThreadPool]: Opening a new connection, currently in state init
18:08:38.110798 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
18:08:38.110798 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
18:08:38.111798 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
18:08:38.124847 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
18:08:38.127265 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
18:08:38.137533 [debug] [ThreadPool]: On list_recon-cortex_public: Close
18:08:38.154494 [debug] [MainThread]: Using postgres connection "master"
18:08:38.157597 [debug] [MainThread]: On master: BEGIN
18:08:38.158674 [debug] [MainThread]: Opening a new connection, currently in state init
18:08:38.206076 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
18:08:38.206076 [debug] [MainThread]: Using postgres connection "master"
18:08:38.207073 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
18:08:39.276507 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
18:08:39.286888 [debug] [MainThread]: On master: ROLLBACK
18:08:39.294235 [debug] [MainThread]: Using postgres connection "master"
18:08:39.295874 [debug] [MainThread]: On master: BEGIN
18:08:39.307917 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
18:08:39.309652 [debug] [MainThread]: On master: COMMIT
18:08:39.310896 [debug] [MainThread]: Using postgres connection "master"
18:08:39.312324 [debug] [MainThread]: On master: COMMIT
18:08:39.318802 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
18:08:39.320798 [debug] [MainThread]: On master: Close
18:08:39.324488 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
18:08:39.328447 [info ] [MainThread]: 
18:08:39.454598 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
18:08:39.455596 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
18:08:39.456600 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.457598 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
18:08:39.458596 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
18:08:39.472289 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
18:08:39.474345 [debug] [Thread-1  ]: finished collecting timing info
18:08:39.475346 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
18:08:39.579816 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.581025 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp233839552785"
  as (
    


with source_data as (

    select s.* from set2_hdfc_auto s 

),

filter_debit_source_data as (
    select s.*,  split_part(s."txt_txn_desc" , '-', 1)  as ref_agr1,
    split_part(s."txt_txn_desc" , '-',2)  as ref_agr2,
    split_part(s."txt_txn_desc" , '-', 3) as ref_agr3 from source_data s where s.cod_drcr = 'D'
),

filter_credit_source_data as (
    select s.*,  split_part(s."txt_txn_desc" , '-', 1)  as ref_agr1,
    split_part(s."txt_txn_desc" , '-',2)  as ref_agr2,
    split_part(s."txt_txn_desc" , '-', 3) as ref_agr3 from source_data s where s.cod_drcr = 'C'
),
filter_debit_matched_data as (
    select sd.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and 
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_matched_data as (
    select sc.*, concat(sd.amt_txn, sd.ref_agr1, sd.ref_agr2, sd.ref_agr3) as recon_link_id from filter_debit_source_data sd, filter_credit_source_data sc where sd.amt_txn = sc.amt_txn and
    (sd.ref_agr1 = sc.ref_agr1 or 
    sd.ref_agr1 = sc.ref_agr2 or 
    sd.ref_agr1 = sc.ref_agr3 or 
    sd.ref_agr2 = sc.ref_agr1 or 
    sd.ref_agr2 = sc.ref_agr2 or 
    sd.ref_agr2 = sc.ref_agr3 or 
    sd.ref_agr3 = sc.ref_agr1 or 
    sd.ref_agr3 = sc.ref_agr2 or 
    sd.ref_agr3 = sc.ref_agr3)
),
filter_credit_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.ref_agr1,
        fcs.ref_agr2,
        fcs.ref_agr3 from filter_credit_source_data fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.ref_agr1,
        fcm.ref_agr2,
        fcm.ref_agr3 from filter_credit_matched_data fcm
),
filter_debit_unmatched_data as (
    select fds.amt_txn,
        fds.dat_txn,
        fds.dat_value,
        fds.ref_chq_no,
        fds.cod_acct_no,
        fds.cod_auth_id,
        fds.amt_od_limit,
        fds.txt_txn_desc,
        fds.bal_available,
        fds.cod_cc_brn_txn,
        fds.cod_txn_literal,
        fds.cod_txn_mnemonic,
        fds.ref_agr1,
        fds.ref_agr2,
        fds.ref_agr3 from filter_debit_source_data fds 
    except select 
        fdm.amt_txn,
        fdm.dat_txn,
        fdm.dat_value,
        fdm.ref_chq_no,
        fdm.cod_acct_no,
        fdm.cod_auth_id,
        fdm.amt_od_limit,
        fdm.txt_txn_desc,
        fdm.bal_available,
        fdm.cod_cc_brn_txn,
        fdm.cod_txn_literal,
        fdm.cod_txn_mnemonic,
        fdm.ref_agr1,
        fdm.ref_agr2,
        fdm.ref_agr3 from filter_debit_matched_data fdm
)


select
    221 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_unmatched_data
union all
select
    221 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_unmatched_data
union all
select
    221 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_debit_matched_data
union all
select
    221 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    ref_agr1 as column13,
    ref_agr2 as column14,
    ref_agr3 as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    recon_link_id as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_credit_matched_data



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
18:08:39.582033 [debug] [Thread-1  ]: Opening a new connection, currently in state init
18:08:39.639922 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.06 seconds
18:08:39.649921 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.650917 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
18:08:39.659118 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
18:08:39.659118 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.660123 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp233839552785'
        
      order by ordinal_position

  
18:08:39.714050 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.05 seconds
18:08:39.738914 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.743785 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
18:08:39.767354 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.02 seconds
18:08:39.806598 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.808165 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
18:08:39.819640 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
18:08:39.859398 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
18:08:39.871735 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.873738 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp233839552785"
    )
  
18:08:39.882487 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
18:08:39.915171 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
18:08:39.918761 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
18:08:39.919763 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
18:08:39.926268 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
18:08:39.927269 [debug] [Thread-1  ]: finished collecting timing info
18:08:39.927875 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
18:08:39.928892 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0633fd83-c442-4121-903f-83293091a0f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984CFBAD90>]}
18:08:39.930399 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.47s]
18:08:39.932398 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
18:08:39.934398 [debug] [MainThread]: Acquiring new postgres connection "master"
18:08:39.935399 [debug] [MainThread]: Using postgres connection "master"
18:08:39.935399 [debug] [MainThread]: On master: BEGIN
18:08:39.936399 [debug] [MainThread]: Opening a new connection, currently in state closed
18:08:40.018085 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
18:08:40.020094 [debug] [MainThread]: On master: COMMIT
18:08:40.021091 [debug] [MainThread]: Using postgres connection "master"
18:08:40.023154 [debug] [MainThread]: On master: COMMIT
18:08:40.030884 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
18:08:40.032129 [debug] [MainThread]: On master: Close
18:08:40.037231 [info ] [MainThread]: 
18:08:40.040838 [info ] [MainThread]: Finished running 1 incremental model in 2.12s.
18:08:40.042767 [debug] [MainThread]: Connection 'master' was properly closed.
18:08:40.044768 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
18:08:40.046078 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
18:08:40.046078 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
18:08:40.062182 [info ] [MainThread]: 
18:08:40.064182 [info ] [MainThread]: [32mCompleted successfully[0m
18:08:40.069522 [info ] [MainThread]: 
18:08:40.075039 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
18:08:40.078040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984E1D89D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984CFBA400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002984E1F09A0>]}


============================== 2022-03-22 05:35:25.934080 | 678e94be-02c0-4dae-a098-9077f08e0daa ==============================
05:35:25.934080 [info ] [MainThread]: Running with dbt=1.0.3
05:35:25.944203 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
05:35:25.944203 [debug] [MainThread]: Tracking: tracking
05:35:26.029877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F2BC7C70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F2BC7FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F2BC70D0>]}
05:35:26.123066 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
05:35:26.123066 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
05:35:26.127496 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
05:35:26.138277 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
05:35:26.163897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '678e94be-02c0-4dae-a098-9077f08e0daa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F3CEB0D0>]}
05:35:26.170490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '678e94be-02c0-4dae-a098-9077f08e0daa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F3C23A30>]}
05:35:26.171490 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
05:35:26.173921 [info ] [MainThread]: 
05:35:26.174601 [debug] [MainThread]: Acquiring new postgres connection "master"
05:35:26.176605 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
05:35:26.183304 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
05:35:26.183304 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
05:35:26.188058 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:35:26.266760 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.08 seconds
05:35:26.268794 [debug] [ThreadPool]: On list_recon-cortex: Close
05:35:26.270794 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
05:35:26.278837 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:35:26.279154 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
05:35:26.279154 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:35:26.352791 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
05:35:26.352791 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:35:26.353836 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
05:35:26.363877 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
05:35:26.369269 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
05:35:26.374141 [debug] [ThreadPool]: On list_recon-cortex_public: Close
05:35:26.387172 [debug] [MainThread]: Using postgres connection "master"
05:35:26.388981 [debug] [MainThread]: On master: BEGIN
05:35:26.389171 [debug] [MainThread]: Opening a new connection, currently in state init
05:35:26.463503 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
05:35:26.468510 [debug] [MainThread]: Using postgres connection "master"
05:35:26.469632 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
05:35:27.525285 [debug] [MainThread]: SQL status: SELECT 0 in 1.06 seconds
05:35:27.539210 [debug] [MainThread]: On master: ROLLBACK
05:35:27.544173 [debug] [MainThread]: Using postgres connection "master"
05:35:27.544173 [debug] [MainThread]: On master: BEGIN
05:35:27.550645 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
05:35:27.552574 [debug] [MainThread]: On master: COMMIT
05:35:27.552574 [debug] [MainThread]: Using postgres connection "master"
05:35:27.553573 [debug] [MainThread]: On master: COMMIT
05:35:27.560271 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
05:35:27.561225 [debug] [MainThread]: On master: Close
05:35:27.562421 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
05:35:27.563426 [info ] [MainThread]: 
05:35:27.574611 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
05:35:27.575608 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
05:35:27.579961 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
05:35:27.581213 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
05:35:27.583607 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
05:35:27.597643 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
05:35:27.599605 [debug] [Thread-1  ]: finished collecting timing info
05:35:27.600613 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
05:35:27.718134 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:35:27.718134 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp110527693933"
  as (
    


with source_data as (

    select s.* from set2_hdfc_auto s 

),

filter_data_source_1 as (
    select s.*, right(s."txt_txn_desc", 22) as rtgs_utr_no from source_data s where s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),

filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_data_source_2 filter_data_source_2
     where fds1.amt_txn = fds2.disb_amt_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1, filter_data_source_2 filter_data_source_2
     where fds1.amt_txn = fds2.disb_amt_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_datasrc1_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.rtgs_utr_no from filter_data_source_1 fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.rtgs_utr_no from filter_matched_data_source_1 fcm
),
filter_datasrc2_unmatched_data as (
    select fds.utr,
        fds.app_id_c,
        fds.las_edit_d,
        fds.disb_amt_n,
        fds.disb_msg_gen_date from filter_data_source_2 fds 
    except select 
        fdm.utr,
        fdm.app_id_c,
        fdm.las_edit_d,
        fdm.disb_amt_n,
        fdm.disb_msg_gen_date from filter_matched_data_source_2 fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc1_unmatched_data
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amt_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc2_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amt_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
05:35:27.719136 [debug] [Thread-1  ]: Opening a new connection, currently in state init
05:35:27.824193 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "rtgs_utr_no"
LINE 186:     rtgs_utr_no as column13,
              ^

05:35:27.826728 [debug] [Thread-1  ]: finished collecting timing info
05:35:27.826728 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
05:35:27.828661 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  syntax error at or near "rtgs_utr_no"
  LINE 186:     rtgs_utr_no as column13,
                ^
05:35:27.828661 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '678e94be-02c0-4dae-a098-9077f08e0daa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F3C1A8B0>]}
05:35:27.829664 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.25s]
05:35:27.830257 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
05:35:27.832256 [debug] [MainThread]: Acquiring new postgres connection "master"
05:35:27.833259 [debug] [MainThread]: Using postgres connection "master"
05:35:27.834258 [debug] [MainThread]: On master: BEGIN
05:35:27.835261 [debug] [MainThread]: Opening a new connection, currently in state closed
05:35:27.911624 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
05:35:27.912371 [debug] [MainThread]: On master: COMMIT
05:35:27.912371 [debug] [MainThread]: Using postgres connection "master"
05:35:27.913256 [debug] [MainThread]: On master: COMMIT
05:35:27.917269 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
05:35:27.918011 [debug] [MainThread]: On master: Close
05:35:27.919259 [info ] [MainThread]: 
05:35:27.920414 [info ] [MainThread]: Finished running 1 incremental model in 1.74s.
05:35:27.921258 [debug] [MainThread]: Connection 'master' was properly closed.
05:35:27.922262 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
05:35:27.922262 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
05:35:27.923256 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
05:35:27.929257 [info ] [MainThread]: 
05:35:27.930263 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
05:35:27.934266 [info ] [MainThread]: 
05:35:27.937280 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
05:35:27.939258 [error] [MainThread]:   syntax error at or near "rtgs_utr_no"
05:35:27.940257 [error] [MainThread]:   LINE 186:     rtgs_utr_no as column13,
05:35:27.941259 [error] [MainThread]:                 ^
05:35:27.943313 [info ] [MainThread]: 
05:35:27.945259 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
05:35:27.946256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F3D51A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F3D49AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1F3BA2C70>]}


============================== 2022-03-22 05:35:57.177189 | fe95a23f-0db9-4988-974b-224e4549c2f8 ==============================
05:35:57.177189 [info ] [MainThread]: Running with dbt=1.0.3
05:35:57.193162 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
05:35:57.194163 [debug] [MainThread]: Tracking: tracking
05:35:57.284010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB676884F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB67688FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB67688C70>]}
05:35:57.331298 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
05:35:57.338746 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
05:35:57.339748 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
05:35:57.350392 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
05:35:57.376413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fe95a23f-0db9-4988-974b-224e4549c2f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB687AB0D0>]}
05:35:57.383589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fe95a23f-0db9-4988-974b-224e4549c2f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB686E39A0>]}
05:35:57.383589 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
05:35:57.386407 [info ] [MainThread]: 
05:35:57.387606 [debug] [MainThread]: Acquiring new postgres connection "master"
05:35:57.389589 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
05:35:57.406588 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
05:35:57.407785 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
05:35:57.407785 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:35:57.478182 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.07 seconds
05:35:57.479895 [debug] [ThreadPool]: On list_recon-cortex: Close
05:35:57.481898 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
05:35:57.489002 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:35:57.490214 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
05:35:57.490214 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:35:57.548017 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
05:35:57.548656 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:35:57.549020 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
05:35:57.552272 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.0 seconds
05:35:57.563396 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
05:35:57.569154 [debug] [ThreadPool]: On list_recon-cortex_public: Close
05:35:57.584726 [debug] [MainThread]: Using postgres connection "master"
05:35:57.585726 [debug] [MainThread]: On master: BEGIN
05:35:57.586765 [debug] [MainThread]: Opening a new connection, currently in state init
05:35:57.703026 [debug] [MainThread]: SQL status: BEGIN in 0.12 seconds
05:35:57.704914 [debug] [MainThread]: Using postgres connection "master"
05:35:57.706288 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
05:35:58.767496 [debug] [MainThread]: SQL status: SELECT 0 in 1.06 seconds
05:35:58.775574 [debug] [MainThread]: On master: ROLLBACK
05:35:58.781156 [debug] [MainThread]: Using postgres connection "master"
05:35:58.787360 [debug] [MainThread]: On master: BEGIN
05:35:58.800138 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
05:35:58.801658 [debug] [MainThread]: On master: COMMIT
05:35:58.802656 [debug] [MainThread]: Using postgres connection "master"
05:35:58.804059 [debug] [MainThread]: On master: COMMIT
05:35:58.811303 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
05:35:58.811820 [debug] [MainThread]: On master: Close
05:35:58.813818 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
05:35:58.815423 [info ] [MainThread]: 
05:35:58.828253 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
05:35:58.829253 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
05:35:58.833425 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
05:35:58.835251 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
05:35:58.835251 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
05:35:58.847251 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
05:35:58.850491 [debug] [Thread-1  ]: finished collecting timing info
05:35:58.851259 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
05:35:58.963039 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:35:58.964199 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp110558942259"
  as (
    


with source_data as (

    select s.* from set2_hdfc_auto s 

),

filter_data_source_1 as (
    select s.*, right(s."txt_txn_desc", 22) as rtgs_utr_no from source_data s where s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),

filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_data_source_2 filter_data_source_2
     where fds1.amt_txn = fds2.disb_amt_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1, filter_data_source_2 filter_data_source_2
     where fds1.amt_txn = fds2.disb_amt_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_datasrc1_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.rtgs_utr_no from filter_data_source_1 fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.rtgs_utr_no from filter_matched_data_source_1 fcm
),
filter_datasrc2_unmatched_data as (
    select fds.utr,
        fds.app_id_c,
        fds.las_edit_d,
        fds.disb_amt_n,
        fds.disb_msg_gen_date from filter_data_source_2 fds 
    except select 
        fdm.utr,
        fdm.app_id_c,
        fdm.las_edit_d,
        fdm.disb_amt_n,
        fdm.disb_msg_gen_date from filter_matched_data_source_2 fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc1_unmatched_data
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amt_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc2_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amt_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
05:35:58.964199 [debug] [Thread-1  ]: Opening a new connection, currently in state init
05:35:59.034447 [debug] [Thread-1  ]: Postgres adapter: Postgres error: missing FROM-clause entry for table "fds2"
LINE 24:     select fds1.*, fds2.app_id_c as agreement_no from filter...
                            ^

05:35:59.034447 [debug] [Thread-1  ]: finished collecting timing info
05:35:59.035472 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
05:35:59.036623 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  missing FROM-clause entry for table "fds2"
  LINE 24:     select fds1.*, fds2.app_id_c as agreement_no from filter...
                              ^
05:35:59.037442 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fe95a23f-0db9-4988-974b-224e4549c2f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB67572100>]}
05:35:59.038444 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.21s]
05:35:59.040467 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
05:35:59.043448 [debug] [MainThread]: Acquiring new postgres connection "master"
05:35:59.044445 [debug] [MainThread]: Using postgres connection "master"
05:35:59.044445 [debug] [MainThread]: On master: BEGIN
05:35:59.045471 [debug] [MainThread]: Opening a new connection, currently in state closed
05:35:59.147450 [debug] [MainThread]: SQL status: BEGIN in 0.1 seconds
05:35:59.149452 [debug] [MainThread]: On master: COMMIT
05:35:59.150537 [debug] [MainThread]: Using postgres connection "master"
05:35:59.151503 [debug] [MainThread]: On master: COMMIT
05:35:59.159471 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
05:35:59.161466 [debug] [MainThread]: On master: Close
05:35:59.164468 [info ] [MainThread]: 
05:35:59.169574 [info ] [MainThread]: Finished running 1 incremental model in 1.78s.
05:35:59.173472 [debug] [MainThread]: Connection 'master' was properly closed.
05:35:59.174620 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
05:35:59.176463 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
05:35:59.177554 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
05:35:59.192449 [info ] [MainThread]: 
05:35:59.195454 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
05:35:59.199455 [info ] [MainThread]: 
05:35:59.201807 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
05:35:59.204457 [error] [MainThread]:   missing FROM-clause entry for table "fds2"
05:35:59.207264 [error] [MainThread]:   LINE 24:     select fds1.*, fds2.app_id_c as agreement_no from filter...
05:35:59.208447 [error] [MainThread]:                               ^
05:35:59.210446 [info ] [MainThread]: 
05:35:59.212444 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
05:35:59.215085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB68810A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB68808AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB68806400>]}


============================== 2022-03-22 05:37:38.679382 | 63386267-4680-465e-baf3-3b109d94481d ==============================
05:37:38.679382 [info ] [MainThread]: Running with dbt=1.0.3
05:37:38.690402 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
05:37:38.690402 [debug] [MainThread]: Tracking: tracking
05:37:38.719473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210C99E7520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210C99E7FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210C99E70D0>]}
05:37:38.854019 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
05:37:38.861125 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
05:37:38.863144 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
05:37:38.873695 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
05:37:38.898666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '63386267-4680-465e-baf3-3b109d94481d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210CAB0B0D0>]}
05:37:38.906628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '63386267-4680-465e-baf3-3b109d94481d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210CAA479A0>]}
05:37:38.906628 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
05:37:38.909110 [info ] [MainThread]: 
05:37:38.910451 [debug] [MainThread]: Acquiring new postgres connection "master"
05:37:38.912115 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
05:37:38.927109 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
05:37:38.928598 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
05:37:38.929139 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:37:38.998354 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.07 seconds
05:37:39.000101 [debug] [ThreadPool]: On list_recon-cortex: Close
05:37:39.002068 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
05:37:39.009098 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:37:39.010065 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
05:37:39.010065 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:37:39.091799 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
05:37:39.095977 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:37:39.096980 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
05:37:39.107284 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
05:37:39.110078 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
05:37:39.150751 [debug] [ThreadPool]: On list_recon-cortex_public: Close
05:37:39.165008 [debug] [MainThread]: Using postgres connection "master"
05:37:39.173012 [debug] [MainThread]: On master: BEGIN
05:37:39.174025 [debug] [MainThread]: Opening a new connection, currently in state init
05:37:39.257608 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
05:37:39.258642 [debug] [MainThread]: Using postgres connection "master"
05:37:39.258642 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
05:37:40.330199 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
05:37:40.333111 [debug] [MainThread]: On master: ROLLBACK
05:37:40.337734 [debug] [MainThread]: Using postgres connection "master"
05:37:40.341865 [debug] [MainThread]: On master: BEGIN
05:37:40.350884 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
05:37:40.351960 [debug] [MainThread]: On master: COMMIT
05:37:40.352879 [debug] [MainThread]: Using postgres connection "master"
05:37:40.352879 [debug] [MainThread]: On master: COMMIT
05:37:40.357860 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
05:37:40.359588 [debug] [MainThread]: On master: Close
05:37:40.362593 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
05:37:40.363579 [info ] [MainThread]: 
05:37:40.374584 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
05:37:40.376582 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
05:37:40.383582 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
05:37:40.385582 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
05:37:40.386585 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
05:37:40.397578 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
05:37:40.398714 [debug] [Thread-1  ]: finished collecting timing info
05:37:40.399582 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
05:37:40.516916 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:37:40.516916 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp110740493854"
  as (
    


with source_data as (

    select s.* from set2_hdfc_auto s 

),

filter_data_source_1 as (
    select s.*, right(s."txt_txn_desc", 22) as rtgs_utr_no from source_data s where s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),

filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_data_source_2 fds2
     where fds1.amt_txn = fds2.disb_amt_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1, filter_data_source_2 fds2
     where fds1.amt_txn = fds2.disb_amt_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_datasrc1_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.rtgs_utr_no from filter_data_source_1 fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.rtgs_utr_no from filter_matched_data_source_1 fcm
),
filter_datasrc2_unmatched_data as (
    select fds.utr,
        fds.app_id_c,
        fds.las_edit_d,
        fds.disb_amt_n,
        fds.disb_msg_gen_date from filter_data_source_2 fds 
    except select 
        fdm.utr,
        fdm.app_id_c,
        fdm.las_edit_d,
        fdm.disb_amt_n,
        fdm.disb_msg_gen_date from filter_matched_data_source_2 fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc1_unmatched_data
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amt_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc2_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amt_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
05:37:40.517912 [debug] [Thread-1  ]: Opening a new connection, currently in state init
05:37:40.578521 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column fds2.disb_amt_n does not exist
LINE 25:      where fds1.amt_txn = fds2.disb_amt_n
                                   ^
HINT:  Perhaps you meant to reference the column "fds2.disb_amount_n".

05:37:40.579517 [debug] [Thread-1  ]: finished collecting timing info
05:37:40.580519 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
05:37:40.582515 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  column fds2.disb_amt_n does not exist
  LINE 25:      where fds1.amt_txn = fds2.disb_amt_n
                                     ^
  HINT:  Perhaps you meant to reference the column "fds2.disb_amount_n".
05:37:40.583516 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '63386267-4680-465e-baf3-3b109d94481d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210CAA247F0>]}
05:37:40.584517 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.20s]
05:37:40.586514 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
05:37:40.589521 [debug] [MainThread]: Acquiring new postgres connection "master"
05:37:40.589521 [debug] [MainThread]: Using postgres connection "master"
05:37:40.590818 [debug] [MainThread]: On master: BEGIN
05:37:40.591519 [debug] [MainThread]: Opening a new connection, currently in state closed
05:37:40.636792 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
05:37:40.638522 [debug] [MainThread]: On master: COMMIT
05:37:40.638522 [debug] [MainThread]: Using postgres connection "master"
05:37:40.639528 [debug] [MainThread]: On master: COMMIT
05:37:40.644513 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
05:37:40.644513 [debug] [MainThread]: On master: Close
05:37:40.646515 [info ] [MainThread]: 
05:37:40.647514 [info ] [MainThread]: Finished running 1 incremental model in 1.74s.
05:37:40.648515 [debug] [MainThread]: Connection 'master' was properly closed.
05:37:40.648515 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
05:37:40.649515 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
05:37:40.649515 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
05:37:40.660516 [info ] [MainThread]: 
05:37:40.661518 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
05:37:40.664517 [info ] [MainThread]: 
05:37:40.666526 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
05:37:40.670517 [error] [MainThread]:   column fds2.disb_amt_n does not exist
05:37:40.673882 [error] [MainThread]:   LINE 25:      where fds1.amt_txn = fds2.disb_amt_n
05:37:40.675518 [error] [MainThread]:                                      ^
05:37:40.676515 [error] [MainThread]:   HINT:  Perhaps you meant to reference the column "fds2.disb_amount_n".
05:37:40.677515 [info ] [MainThread]: 
05:37:40.678516 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
05:37:40.679514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210CAB71A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210CAB69AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210CAB66E50>]}


============================== 2022-03-22 05:39:42.565931 | eb5b70c7-f911-4f63-b2a8-735997b047ae ==============================
05:39:42.565931 [info ] [MainThread]: Running with dbt=1.0.3
05:39:42.576413 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
05:39:42.576413 [debug] [MainThread]: Tracking: tracking
05:39:42.657776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF301F9A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF312B7C40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF312B7700>]}
05:39:42.706816 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
05:39:42.714530 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
05:39:42.716532 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
05:39:42.726991 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
05:39:42.750438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eb5b70c7-f911-4f63-b2a8-735997b047ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF3140B0D0>]}
05:39:42.759755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eb5b70c7-f911-4f63-b2a8-735997b047ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF31343A30>]}
05:39:42.761082 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
05:39:42.762737 [info ] [MainThread]: 
05:39:42.764749 [debug] [MainThread]: Acquiring new postgres connection "master"
05:39:42.766732 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
05:39:42.783734 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
05:39:42.783734 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
05:39:42.784737 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:39:42.847878 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.06 seconds
05:39:42.849765 [debug] [ThreadPool]: On list_recon-cortex: Close
05:39:42.852731 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
05:39:42.861727 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:39:42.861727 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
05:39:42.862730 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:39:42.924664 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
05:39:42.925828 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:39:42.925828 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
05:39:43.166684 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.24 seconds
05:39:43.169693 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
05:39:43.177155 [debug] [ThreadPool]: On list_recon-cortex_public: Close
05:39:43.185703 [debug] [MainThread]: Using postgres connection "master"
05:39:43.196051 [debug] [MainThread]: On master: BEGIN
05:39:43.197052 [debug] [MainThread]: Opening a new connection, currently in state init
05:39:43.287078 [debug] [MainThread]: SQL status: BEGIN in 0.09 seconds
05:39:43.289074 [debug] [MainThread]: Using postgres connection "master"
05:39:43.290213 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
05:39:44.356390 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
05:39:44.364810 [debug] [MainThread]: On master: ROLLBACK
05:39:44.389597 [debug] [MainThread]: Using postgres connection "master"
05:39:44.393738 [debug] [MainThread]: On master: BEGIN
05:39:44.400178 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
05:39:44.402652 [debug] [MainThread]: On master: COMMIT
05:39:44.402652 [debug] [MainThread]: Using postgres connection "master"
05:39:44.402652 [debug] [MainThread]: On master: COMMIT
05:39:44.407195 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
05:39:44.407195 [debug] [MainThread]: On master: Close
05:39:44.408195 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
05:39:44.409215 [info ] [MainThread]: 
05:39:44.420194 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
05:39:44.420194 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
05:39:44.423762 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
05:39:44.424991 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
05:39:44.426236 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
05:39:44.447251 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
05:39:44.449205 [debug] [Thread-1  ]: finished collecting timing info
05:39:44.449746 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
05:39:44.583061 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:39:44.583061 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp110944551478"
  as (
    


with source_data as (

    select s.* from set2_hdfc_auto s 

),

filter_data_source_1 as (
    select s.*, right(s."txt_txn_desc", 22) as rtgs_utr_no from source_data s where s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),

filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_data_source_2 fds2
     where fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1, filter_data_source_2 fds2
     where fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_datasrc1_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.rtgs_utr_no from filter_data_source_1 fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.rtgs_utr_no from filter_matched_data_source_1 fcm
),
filter_datasrc2_unmatched_data as (
    select fds.utr,
        fds.app_id_c,
        fds.las_edit_d,
        fds.disb_amount_n,
        fds.disb_msg_gen_date from filter_data_source_2 fds 
    except select 
        fdm.utr,
        fdm.app_id_c,
        fdm.las_edit_d,
        fdm.disb_amount_n,
        fdm.disb_msg_gen_date from filter_matched_data_source_2 fdm
)


select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc1_unmatched_data
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc2_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
05:39:44.584106 [debug] [Thread-1  ]: Opening a new connection, currently in state init
05:39:44.632749 [debug] [Thread-1  ]: Postgres adapter: Postgres error: UNION types double precision and character varying cannot be matched
LINE 127:     utr as column1,
              ^

05:39:44.632749 [debug] [Thread-1  ]: finished collecting timing info
05:39:44.633747 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
05:39:44.634745 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  UNION types double precision and character varying cannot be matched
  LINE 127:     utr as column1,
                ^
05:39:44.634745 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eb5b70c7-f911-4f63-b2a8-735997b047ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF3133A760>]}
05:39:44.635746 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.21s]
05:39:44.637511 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
05:39:44.639513 [debug] [MainThread]: Acquiring new postgres connection "master"
05:39:44.641127 [debug] [MainThread]: Using postgres connection "master"
05:39:44.641514 [debug] [MainThread]: On master: BEGIN
05:39:44.642512 [debug] [MainThread]: Opening a new connection, currently in state closed
05:39:44.699593 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
05:39:44.701699 [debug] [MainThread]: On master: COMMIT
05:39:44.702964 [debug] [MainThread]: Using postgres connection "master"
05:39:44.704590 [debug] [MainThread]: On master: COMMIT
05:39:44.711700 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
05:39:44.713591 [debug] [MainThread]: On master: Close
05:39:44.715586 [info ] [MainThread]: 
05:39:44.716765 [info ] [MainThread]: Finished running 1 incremental model in 1.95s.
05:39:44.718589 [debug] [MainThread]: Connection 'master' was properly closed.
05:39:44.719585 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
05:39:44.720590 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
05:39:44.721587 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
05:39:44.736609 [info ] [MainThread]: 
05:39:44.737586 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
05:39:44.740586 [info ] [MainThread]: 
05:39:44.741587 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
05:39:44.747597 [error] [MainThread]:   UNION types double precision and character varying cannot be matched
05:39:44.749743 [error] [MainThread]:   LINE 127:     utr as column1,
05:39:44.751591 [error] [MainThread]:                 ^
05:39:44.753587 [info ] [MainThread]: 
05:39:44.755587 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
05:39:44.756586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF3138CE80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF31343520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF31466B20>]}


============================== 2022-03-22 05:44:14.971699 | ad1d0260-74ad-4802-a4c0-96d6ffe63b18 ==============================
05:44:14.971699 [info ] [MainThread]: Running with dbt=1.0.3
05:44:14.980308 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
05:44:14.980308 [debug] [MainThread]: Tracking: tracking
05:44:15.018309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46AA59A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46AB48C40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46AB48700>]}
05:44:15.073384 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
05:44:15.077533 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
05:44:15.078537 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
05:44:15.090668 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
05:44:15.119162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ad1d0260-74ad-4802-a4c0-96d6ffe63b18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46BC6B0D0>]}
05:44:15.126681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ad1d0260-74ad-4802-a4c0-96d6ffe63b18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46BBA3A30>]}
05:44:15.126681 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
05:44:15.129376 [info ] [MainThread]: 
05:44:15.130422 [debug] [MainThread]: Acquiring new postgres connection "master"
05:44:15.132734 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
05:44:15.147769 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
05:44:15.148858 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
05:44:15.148858 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:44:15.240441 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.09 seconds
05:44:15.246251 [debug] [ThreadPool]: On list_recon-cortex: Close
05:44:15.249651 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
05:44:15.259845 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:44:15.261747 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
05:44:15.261747 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:44:15.353921 [debug] [ThreadPool]: SQL status: BEGIN in 0.09 seconds
05:44:15.361140 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
05:44:15.363148 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
05:44:15.372136 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
05:44:15.378139 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
05:44:15.383361 [debug] [ThreadPool]: On list_recon-cortex_public: Close
05:44:15.390393 [debug] [MainThread]: Using postgres connection "master"
05:44:15.394317 [debug] [MainThread]: On master: BEGIN
05:44:15.394317 [debug] [MainThread]: Opening a new connection, currently in state init
05:44:15.468779 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
05:44:15.470374 [debug] [MainThread]: Using postgres connection "master"
05:44:15.471370 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
05:44:16.525784 [debug] [MainThread]: SQL status: SELECT 0 in 1.05 seconds
05:44:16.544080 [debug] [MainThread]: On master: ROLLBACK
05:44:16.549628 [debug] [MainThread]: Using postgres connection "master"
05:44:16.549628 [debug] [MainThread]: On master: BEGIN
05:44:16.563170 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
05:44:16.563170 [debug] [MainThread]: On master: COMMIT
05:44:16.563170 [debug] [MainThread]: Using postgres connection "master"
05:44:16.564170 [debug] [MainThread]: On master: COMMIT
05:44:16.569069 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
05:44:16.570069 [debug] [MainThread]: On master: Close
05:44:16.571069 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
05:44:16.571069 [info ] [MainThread]: 
05:44:16.580658 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
05:44:16.581647 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
05:44:16.584659 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.586756 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
05:44:16.588719 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
05:44:16.598679 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
05:44:16.599688 [debug] [Thread-1  ]: finished collecting timing info
05:44:16.600648 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
05:44:16.726917 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.726917 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp111416705815"
  as (
    


with source_data as (

    select s.* from set2_hdfc_auto s 

),

filter_data_source_1 as (
    select s.*, right(s."txt_txn_desc", 22) as rtgs_utr_no from source_data s where s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),

filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1, filter_data_source_2 fds2
     where fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1, filter_data_source_2 fds2
     where fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_datasrc1_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.rtgs_utr_no from filter_data_source_1 fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.rtgs_utr_no from filter_matched_data_source_1 fcm
),
filter_datasrc2_unmatched_data as (
    select fds.utr,
        fds.app_id_c,
        fds.las_edit_d,
        fds.disb_amount_n,
        fds.disb_msg_gen_date from filter_data_source_2 fds 
    except select 
        fdm.utr,
        fdm.app_id_c,
        fdm.las_edit_d,
        fdm.disb_amount_n,
        fdm.disb_msg_gen_date from filter_matched_data_source_2 fdm
)


select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc1_unmatched_data
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc2_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
05:44:16.727894 [debug] [Thread-1  ]: Opening a new connection, currently in state init
05:44:16.826381 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.1 seconds
05:44:16.830993 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.840454 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
05:44:16.842650 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
05:44:16.849137 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.849137 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp111416705815'
        
      order by ordinal_position

  
05:44:16.870567 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.02 seconds
05:44:16.879567 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.880661 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
05:44:16.891362 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
05:44:16.903921 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.905103 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
05:44:16.914100 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
05:44:16.929775 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
05:44:16.931544 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.931544 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp111416705815"
    )
  
05:44:16.938256 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
05:44:16.940260 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
05:44:16.940260 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
05:44:16.948507 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
05:44:16.949774 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
05:44:16.956109 [debug] [Thread-1  ]: finished collecting timing info
05:44:16.956556 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
05:44:16.957575 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad1d0260-74ad-4802-a4c0-96d6ffe63b18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46BCC6A90>]}
05:44:16.958119 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.37s]
05:44:16.959554 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
05:44:16.961557 [debug] [MainThread]: Acquiring new postgres connection "master"
05:44:16.962570 [debug] [MainThread]: Using postgres connection "master"
05:44:16.962570 [debug] [MainThread]: On master: BEGIN
05:44:16.963556 [debug] [MainThread]: Opening a new connection, currently in state closed
05:44:17.024899 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
05:44:17.027133 [debug] [MainThread]: On master: COMMIT
05:44:17.027881 [debug] [MainThread]: Using postgres connection "master"
05:44:17.027987 [debug] [MainThread]: On master: COMMIT
05:44:17.032199 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
05:44:17.033156 [debug] [MainThread]: On master: Close
05:44:17.033215 [info ] [MainThread]: 
05:44:17.035211 [info ] [MainThread]: Finished running 1 incremental model in 1.90s.
05:44:17.036213 [debug] [MainThread]: Connection 'master' was properly closed.
05:44:17.037212 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
05:44:17.038459 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
05:44:17.039213 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
05:44:17.047403 [info ] [MainThread]: 
05:44:17.049221 [info ] [MainThread]: [32mCompleted successfully[0m
05:44:17.053219 [info ] [MainThread]: 
05:44:17.054214 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
05:44:17.056213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46BBA3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46BBEDA00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B46A433AF0>]}


============================== 2022-03-22 08:30:43.747813 | 8e4cc3d8-313e-4997-8736-989a4a5eded8 ==============================
08:30:43.747813 [info ] [MainThread]: Running with dbt=1.0.3
08:30:43.790868 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:30:43.790868 [debug] [MainThread]: Tracking: tracking
08:30:43.904562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002566EF68FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002566EF68FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002566EF688E0>]}
08:30:43.954116 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:30:43.954116 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
08:30:43.967268 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
08:30:43.980926 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
08:30:44.000402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8e4cc3d8-313e-4997-8736-989a4a5eded8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002567008C0D0>]}
08:30:44.008107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8e4cc3d8-313e-4997-8736-989a4a5eded8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002566FFC3A30>]}
08:30:44.008107 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
08:30:44.011111 [info ] [MainThread]: 
08:30:44.013144 [debug] [MainThread]: Acquiring new postgres connection "master"
08:30:44.015141 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
08:30:44.028141 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
08:30:44.029145 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
08:30:44.029145 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:30:44.127844 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.1 seconds
08:30:44.132393 [debug] [ThreadPool]: On list_recon-cortex: Close
08:30:44.140171 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
08:30:44.146382 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
08:30:44.146382 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
08:30:44.158631 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:30:44.237073 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
08:30:44.238124 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
08:30:44.239078 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
08:30:44.253290 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
08:30:44.261977 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
08:30:44.265266 [debug] [ThreadPool]: On list_recon-cortex_public: Close
08:30:44.278481 [debug] [MainThread]: Using postgres connection "master"
08:30:44.279480 [debug] [MainThread]: On master: BEGIN
08:30:44.280479 [debug] [MainThread]: Opening a new connection, currently in state init
08:30:44.412419 [debug] [MainThread]: SQL status: BEGIN in 0.13 seconds
08:30:44.414203 [debug] [MainThread]: Using postgres connection "master"
08:30:44.415230 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
08:30:45.478349 [debug] [MainThread]: SQL status: SELECT 0 in 1.06 seconds
08:30:45.487480 [debug] [MainThread]: On master: ROLLBACK
08:30:45.493821 [debug] [MainThread]: Using postgres connection "master"
08:30:45.495365 [debug] [MainThread]: On master: BEGIN
08:30:45.504953 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
08:30:45.508843 [debug] [MainThread]: On master: COMMIT
08:30:45.510034 [debug] [MainThread]: Using postgres connection "master"
08:30:45.511035 [debug] [MainThread]: On master: COMMIT
08:30:45.516708 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
08:30:45.520981 [debug] [MainThread]: On master: Close
08:30:45.523044 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
08:30:45.525090 [info ] [MainThread]: 
08:30:45.653152 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
08:30:45.654153 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
08:30:45.655176 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.656375 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
08:30:45.656375 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
08:30:45.667156 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
08:30:45.669939 [debug] [Thread-1  ]: finished collecting timing info
08:30:45.670163 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
08:30:45.792134 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.793135 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp140045773024"
  as (
    


with source_data as (

    select s.* from set2_hdfc_auto s 

),

filter_data_source_1 as (
    select s.*, right(s."txt_txn_desc", 22) as rtgs_utr_no from source_data s where s.cod_drcr = 'D' and s.txt_txn_desc like 'RTGS%'
),

filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
),
filter_datasrc1_unmatched_data as (
    select fcs.amt_txn,
        fcs.dat_txn,
        fcs.dat_value,
        fcs.ref_chq_no,
        fcs.cod_acct_no,
        fcs.cod_auth_id,
        fcs.amt_od_limit,
        fcs.txt_txn_desc,
        fcs.bal_available,
        fcs.cod_cc_brn_txn,
        fcs.cod_txn_literal,
        fcs.cod_txn_mnemonic,
        fcs.rtgs_utr_no from filter_data_source_1 fcs 
    except 
    select 
        fcm.amt_txn,
        fcm.dat_txn,
        fcm.dat_value,
        fcm.ref_chq_no,
        fcm.cod_acct_no,
        fcm.cod_auth_id,
        fcm.amt_od_limit,
        fcm.txt_txn_desc,
        fcm.bal_available,
        fcm.cod_cc_brn_txn,
        fcm.cod_txn_literal,
        fcm.cod_txn_mnemonic,
        fcm.rtgs_utr_no from filter_matched_data_source_1 fcm
),
filter_datasrc2_unmatched_data as (
    select fds.utr,
        fds.app_id_c,
        fds.las_edit_d,
        fds.disb_amount_n,
        fds.disb_msg_gen_date from filter_data_source_2 fds 
    except select 
        fdm.utr,
        fdm.app_id_c,
        fdm.las_edit_d,
        fdm.disb_amount_n,
        fdm.disb_msg_gen_date from filter_matched_data_source_2 fdm
)


select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc1_unmatched_data
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    null as recon_link_id,
    0 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_datasrc2_unmatched_data
union all
select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
08:30:45.793135 [debug] [Thread-1  ]: Opening a new connection, currently in state init
08:30:45.851342 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.06 seconds
08:30:45.860377 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.861348 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
08:30:45.865341 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
08:30:45.866338 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.866338 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp140045773024'
        
      order by ordinal_position

  
08:30:45.879652 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
08:30:45.888116 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.888116 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
08:30:45.898441 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
08:30:45.909588 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.910063 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
08:30:45.919910 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
08:30:45.927955 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
08:30:45.935968 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.935968 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp140045773024"
    )
  
08:30:45.943953 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.01 seconds
08:30:45.945887 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
08:30:45.945887 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
08:30:45.954008 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
08:30:45.960992 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
08:30:45.962607 [debug] [Thread-1  ]: finished collecting timing info
08:30:45.963608 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
08:30:45.963704 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e4cc3d8-313e-4997-8736-989a4a5eded8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256700E8EE0>]}
08:30:45.964742 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.31s]
08:30:45.965749 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
08:30:45.973271 [debug] [MainThread]: Acquiring new postgres connection "master"
08:30:45.976272 [debug] [MainThread]: Using postgres connection "master"
08:30:45.977281 [debug] [MainThread]: On master: BEGIN
08:30:45.978270 [debug] [MainThread]: Opening a new connection, currently in state closed
08:30:46.057261 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
08:30:46.058119 [debug] [MainThread]: On master: COMMIT
08:30:46.058119 [debug] [MainThread]: Using postgres connection "master"
08:30:46.058887 [debug] [MainThread]: On master: COMMIT
08:30:46.061147 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
08:30:46.064495 [debug] [MainThread]: On master: Close
08:30:46.065494 [info ] [MainThread]: 
08:30:46.066667 [info ] [MainThread]: Finished running 1 incremental model in 2.05s.
08:30:46.068043 [debug] [MainThread]: Connection 'master' was properly closed.
08:30:46.068669 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
08:30:46.069301 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
08:30:46.069702 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
08:30:46.077316 [info ] [MainThread]: 
08:30:46.078938 [info ] [MainThread]: [32mCompleted successfully[0m
08:30:46.081071 [info ] [MainThread]: 
08:30:46.081928 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
08:30:46.083935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002566FFC3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002567000DB50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256700D62B0>]}


============================== 2022-03-22 09:04:38.639483 | cd7b97c1-1fe7-4c94-b3cf-e7edec631cea ==============================
09:04:38.639483 [info ] [MainThread]: Running with dbt=1.0.3
09:04:38.640553 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:04:38.640553 [debug] [MainThread]: Tracking: tracking
09:04:38.697453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017536418B20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017536418FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000175364180D0>]}
09:04:38.748835 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:04:38.748835 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
09:04:38.761934 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
09:04:38.779599 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
09:04:38.797275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cd7b97c1-1fe7-4c94-b3cf-e7edec631cea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001753656B0D0>]}
09:04:38.804376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cd7b97c1-1fe7-4c94-b3cf-e7edec631cea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000175364A39A0>]}
09:04:38.804376 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:04:38.807158 [info ] [MainThread]: 
09:04:38.808072 [debug] [MainThread]: Acquiring new postgres connection "master"
09:04:38.810940 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:04:38.827944 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:04:38.828944 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:04:38.830963 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:04:38.917633 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.09 seconds
09:04:38.919682 [debug] [ThreadPool]: On list_recon-cortex: Close
09:04:38.921646 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:04:38.928821 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:04:38.929990 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:04:38.929990 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:04:38.982117 [debug] [ThreadPool]: SQL status: BEGIN in 0.05 seconds
09:04:38.984983 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:04:38.986002 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:04:38.996154 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:04:38.998201 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:04:39.012094 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:04:39.027485 [debug] [MainThread]: Using postgres connection "master"
09:04:39.028808 [debug] [MainThread]: On master: BEGIN
09:04:39.028808 [debug] [MainThread]: Opening a new connection, currently in state init
09:04:39.093590 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
09:04:39.094592 [debug] [MainThread]: Using postgres connection "master"
09:04:39.095582 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:04:40.162306 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
09:04:40.166628 [debug] [MainThread]: On master: ROLLBACK
09:04:40.171582 [debug] [MainThread]: Using postgres connection "master"
09:04:40.176994 [debug] [MainThread]: On master: BEGIN
09:04:40.186539 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:04:40.188314 [debug] [MainThread]: On master: COMMIT
09:04:40.189402 [debug] [MainThread]: Using postgres connection "master"
09:04:40.190406 [debug] [MainThread]: On master: COMMIT
09:04:40.197298 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:04:40.198336 [debug] [MainThread]: On master: Close
09:04:40.199818 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:04:40.201820 [info ] [MainThread]: 
09:04:40.215154 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:04:40.216155 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:04:40.218333 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:04:40.220153 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:04:40.220153 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:04:40.236157 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:04:40.237258 [debug] [Thread-1  ]: finished collecting timing info
09:04:40.238156 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:04:40.354255 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:04:40.355258 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp143440333396"
  as (
    


with filter_data_source_1 as (

    select s.* from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    where fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:04:40.355258 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:04:40.421339 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column fds1.rtgs_utr_no does not exist
LINE 21:      and fds1.rtgs_utr_no = fds2.utr
                  ^

09:04:40.422131 [debug] [Thread-1  ]: finished collecting timing info
09:04:40.422131 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:04:40.423139 [debug] [Thread-1  ]: Database Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)
  column fds1.rtgs_utr_no does not exist
  LINE 21:      and fds1.rtgs_utr_no = fds2.utr
                    ^
09:04:40.424158 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cd7b97c1-1fe7-4c94-b3cf-e7edec631cea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001753650A1F0>]}
09:04:40.425160 [error] [Thread-1  ]: 1 of 1 ERROR creating incremental model public.tb_txn_recon_data................ [[31mERROR[0m in 0.21s]
09:04:40.426208 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:04:40.428363 [debug] [MainThread]: Acquiring new postgres connection "master"
09:04:40.429342 [debug] [MainThread]: Using postgres connection "master"
09:04:40.430114 [debug] [MainThread]: On master: BEGIN
09:04:40.430114 [debug] [MainThread]: Opening a new connection, currently in state closed
09:04:40.493160 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
09:04:40.494081 [debug] [MainThread]: On master: COMMIT
09:04:40.495078 [debug] [MainThread]: Using postgres connection "master"
09:04:40.497098 [debug] [MainThread]: On master: COMMIT
09:04:40.504713 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
09:04:40.505107 [debug] [MainThread]: On master: Close
09:04:40.506078 [info ] [MainThread]: 
09:04:40.508077 [info ] [MainThread]: Finished running 1 incremental model in 1.70s.
09:04:40.511093 [debug] [MainThread]: Connection 'master' was properly closed.
09:04:40.513142 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:04:40.514077 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:04:40.515075 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:04:40.523080 [info ] [MainThread]: 
09:04:40.524077 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
09:04:40.528088 [info ] [MainThread]: 
09:04:40.531078 [error] [MainThread]: [33mDatabase Error in model tb_txn_recon_data (models\dataset2\tb_txn_recon_data.sql)[0m
09:04:40.535117 [error] [MainThread]:   column fds1.rtgs_utr_no does not exist
09:04:40.536079 [error] [MainThread]:   LINE 21:      and fds1.rtgs_utr_no = fds2.utr
09:04:40.538075 [error] [MainThread]:                     ^
09:04:40.539077 [info ] [MainThread]: 
09:04:40.539077 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
09:04:40.540075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000175365D1A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000175365C9AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017536414430>]}


============================== 2022-03-22 09:05:56.040193 | d5d11194-173b-4b8b-a5e8-aabc3709e66b ==============================
09:05:56.040193 [info ] [MainThread]: Running with dbt=1.0.3
09:05:56.051792 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:05:56.051792 [debug] [MainThread]: Tracking: tracking
09:05:56.082824 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D0D84C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D0D8FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D0D80D0>]}
09:05:56.197627 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:05:56.212460 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
09:05:56.214451 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
09:05:56.226471 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
09:05:56.250972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd5d11194-173b-4b8b-a5e8-aabc3709e66b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D22C0D0>]}
09:05:56.260531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd5d11194-173b-4b8b-a5e8-aabc3709e66b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D167A30>]}
09:05:56.260531 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:05:56.263145 [info ] [MainThread]: 
09:05:56.263624 [debug] [MainThread]: Acquiring new postgres connection "master"
09:05:56.265620 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:05:56.281620 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:05:56.282324 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:05:56.282620 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:05:56.342896 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.06 seconds
09:05:56.344616 [debug] [ThreadPool]: On list_recon-cortex: Close
09:05:56.346620 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:05:56.354619 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:05:56.355622 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:05:56.355622 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:05:56.407591 [debug] [ThreadPool]: SQL status: BEGIN in 0.05 seconds
09:05:56.412404 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:05:56.412404 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:05:56.415098 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.0 seconds
09:05:56.424875 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:05:56.451264 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:05:56.459069 [debug] [MainThread]: Using postgres connection "master"
09:05:56.461095 [debug] [MainThread]: On master: BEGIN
09:05:56.461095 [debug] [MainThread]: Opening a new connection, currently in state init
09:05:56.554830 [debug] [MainThread]: SQL status: BEGIN in 0.09 seconds
09:05:56.556020 [debug] [MainThread]: Using postgres connection "master"
09:05:56.557022 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:05:57.635168 [debug] [MainThread]: SQL status: SELECT 0 in 1.08 seconds
09:05:57.637276 [debug] [MainThread]: On master: ROLLBACK
09:05:57.641770 [debug] [MainThread]: Using postgres connection "master"
09:05:57.641770 [debug] [MainThread]: On master: BEGIN
09:05:57.650988 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:05:57.651993 [debug] [MainThread]: On master: COMMIT
09:05:57.651993 [debug] [MainThread]: Using postgres connection "master"
09:05:57.652991 [debug] [MainThread]: On master: COMMIT
09:05:57.656735 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:05:57.658548 [debug] [MainThread]: On master: Close
09:05:57.658548 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:05:57.659694 [info ] [MainThread]: 
09:05:57.669709 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:05:57.670698 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:05:57.674701 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:05:57.675698 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:05:57.676699 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:05:57.692694 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:05:57.693696 [debug] [Thread-1  ]: finished collecting timing info
09:05:57.694695 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:05:57.816687 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:05:57.817195 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp143557793911"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    where fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:05:57.817195 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:05:57.866016 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.05 seconds
09:05:57.875645 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:05:57.875645 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:05:57.883083 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
09:05:57.884083 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:05:57.884083 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp143557793911'
        
      order by ordinal_position

  
09:05:57.897014 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:05:57.907473 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:05:57.908315 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:05:57.916463 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:05:57.922056 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:05:57.922056 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:05:57.934344 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:05:57.950368 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:05:57.951362 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:05:57.951362 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp143557793911"
    )
  
09:05:57.982916 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.03 seconds
09:05:57.999036 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:05:57.999036 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:05:58.006109 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:05:58.010431 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
09:05:58.013918 [debug] [Thread-1  ]: finished collecting timing info
09:05:58.014956 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:05:58.016922 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5d11194-173b-4b8b-a5e8-aabc3709e66b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D289EE0>]}
09:05:58.017922 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.34s]
09:05:58.019916 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:05:58.021917 [debug] [MainThread]: Acquiring new postgres connection "master"
09:05:58.021917 [debug] [MainThread]: Using postgres connection "master"
09:05:58.022952 [debug] [MainThread]: On master: BEGIN
09:05:58.022952 [debug] [MainThread]: Opening a new connection, currently in state closed
09:05:58.088895 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
09:05:58.089790 [debug] [MainThread]: On master: COMMIT
09:05:58.090369 [debug] [MainThread]: Using postgres connection "master"
09:05:58.090786 [debug] [MainThread]: On master: COMMIT
09:05:58.096942 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
09:05:58.097896 [debug] [MainThread]: On master: Close
09:05:58.099853 [info ] [MainThread]: 
09:05:58.100786 [info ] [MainThread]: Finished running 1 incremental model in 1.84s.
09:05:58.101786 [debug] [MainThread]: Connection 'master' was properly closed.
09:05:58.101786 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:05:58.102790 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:05:58.102790 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:05:58.107785 [info ] [MainThread]: 
09:05:58.108822 [info ] [MainThread]: [32mCompleted successfully[0m
09:05:58.109785 [info ] [MainThread]: 
09:05:58.110792 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:05:58.111790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D167520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D1ACB50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49D2771F0>]}


============================== 2022-03-22 09:06:47.221220 | 7e55d40c-ae85-490f-8293-99f6aa633d80 ==============================
09:06:47.221220 [info ] [MainThread]: Running with dbt=1.0.3
09:06:47.222912 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:06:47.222912 [debug] [MainThread]: Tracking: tracking
09:06:47.254912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A130548730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A130548FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A130548340>]}
09:06:47.312945 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:06:47.315106 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:06:47.318387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7e55d40c-ae85-490f-8293-99f6aa633d80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A13064B0D0>]}
09:06:47.325453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7e55d40c-ae85-490f-8293-99f6aa633d80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A1305D3B50>]}
09:06:47.326416 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:06:47.328567 [info ] [MainThread]: 
09:06:47.329515 [debug] [MainThread]: Acquiring new postgres connection "master"
09:06:47.331430 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:06:47.346426 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:06:47.347420 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:06:47.347420 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:06:47.437770 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.09 seconds
09:06:47.439563 [debug] [ThreadPool]: On list_recon-cortex: Close
09:06:47.442527 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:06:47.449718 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:06:47.450919 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:06:47.450919 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:06:47.533865 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
09:06:47.537294 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:06:47.538290 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:06:47.549058 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:06:47.554127 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:06:47.556959 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:06:47.568786 [debug] [MainThread]: Using postgres connection "master"
09:06:47.573303 [debug] [MainThread]: On master: BEGIN
09:06:47.573303 [debug] [MainThread]: Opening a new connection, currently in state init
09:06:47.639700 [debug] [MainThread]: SQL status: BEGIN in 0.07 seconds
09:06:47.641789 [debug] [MainThread]: Using postgres connection "master"
09:06:47.643356 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:06:48.708455 [debug] [MainThread]: SQL status: SELECT 0 in 1.06 seconds
09:06:48.711654 [debug] [MainThread]: On master: ROLLBACK
09:06:48.717670 [debug] [MainThread]: Using postgres connection "master"
09:06:48.717670 [debug] [MainThread]: On master: BEGIN
09:06:48.731155 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:06:48.735486 [debug] [MainThread]: On master: COMMIT
09:06:48.736137 [debug] [MainThread]: Using postgres connection "master"
09:06:48.738147 [debug] [MainThread]: On master: COMMIT
09:06:48.742432 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:06:48.743702 [debug] [MainThread]: On master: Close
09:06:48.744703 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:06:48.745700 [info ] [MainThread]: 
09:06:48.754701 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:06:48.756701 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:06:48.760717 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:06:48.762771 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:06:48.763874 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:06:48.781700 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:06:48.782701 [debug] [Thread-1  ]: finished collecting timing info
09:06:48.782701 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:06:48.854700 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:06:48.855735 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp143648832700"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    where fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:06:48.855735 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:06:48.908251 [debug] [Thread-1  ]: SQL status: SELECT 3 in 0.05 seconds
09:06:48.918976 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:06:48.918976 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:06:48.923362 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
09:06:48.924359 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:06:48.925359 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp143648832700'
        
      order by ordinal_position

  
09:06:48.936994 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:06:48.947624 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:06:48.948627 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:06:48.982466 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.03 seconds
09:06:48.988614 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:06:48.992997 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:06:49.002515 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:06:49.015102 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:06:49.016143 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:06:49.017143 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp143648832700"
    )
  
09:06:49.021617 [debug] [Thread-1  ]: SQL status: INSERT 0 3 in 0.0 seconds
09:06:49.028079 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:06:49.028079 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:06:49.030842 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:06:49.035418 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
09:06:49.037085 [debug] [Thread-1  ]: finished collecting timing info
09:06:49.037085 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:06:49.038090 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e55d40c-ae85-490f-8293-99f6aa633d80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A1306F1820>]}
09:06:49.038090 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 3[0m in 0.28s]
09:06:49.040083 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:06:49.042113 [debug] [MainThread]: Acquiring new postgres connection "master"
09:06:49.043224 [debug] [MainThread]: Using postgres connection "master"
09:06:49.043224 [debug] [MainThread]: On master: BEGIN
09:06:49.043224 [debug] [MainThread]: Opening a new connection, currently in state closed
09:06:49.119149 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
09:06:49.119993 [debug] [MainThread]: On master: COMMIT
09:06:49.120147 [debug] [MainThread]: Using postgres connection "master"
09:06:49.120147 [debug] [MainThread]: On master: COMMIT
09:06:49.124981 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:06:49.125146 [debug] [MainThread]: On master: Close
09:06:49.127159 [info ] [MainThread]: 
09:06:49.128224 [info ] [MainThread]: Finished running 1 incremental model in 1.80s.
09:06:49.129145 [debug] [MainThread]: Connection 'master' was properly closed.
09:06:49.129145 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:06:49.130144 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:06:49.130144 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:06:49.135148 [info ] [MainThread]: 
09:06:49.136170 [info ] [MainThread]: [32mCompleted successfully[0m
09:06:49.139157 [info ] [MainThread]: 
09:06:49.143183 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:06:49.145691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A1305D35E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A130667580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A1306BF220>]}


============================== 2022-03-22 09:08:14.179111 | 42d947a9-d1d2-4767-b1cb-f1bba54b5d9c ==============================
09:08:14.179111 [info ] [MainThread]: Running with dbt=1.0.3
09:08:14.180460 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:08:14.180460 [debug] [MainThread]: Tracking: tracking
09:08:14.214678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E474698A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E475758C40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E475758700>]}
09:08:14.405241 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:08:14.405241 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
09:08:14.412195 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
09:08:14.433121 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
09:08:14.446242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '42d947a9-d1d2-4767-b1cb-f1bba54b5d9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E4758AC0D0>]}
09:08:14.454024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '42d947a9-d1d2-4767-b1cb-f1bba54b5d9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E4757E3A30>]}
09:08:14.455020 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:08:14.456700 [info ] [MainThread]: 
09:08:14.458700 [debug] [MainThread]: Acquiring new postgres connection "master"
09:08:14.460879 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:08:14.470730 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:08:14.471707 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:08:14.471707 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:08:14.544421 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.07 seconds
09:08:14.546360 [debug] [ThreadPool]: On list_recon-cortex: Close
09:08:14.548321 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:08:14.554355 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:08:14.554355 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:08:14.556925 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:08:14.628353 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
09:08:14.629689 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:08:14.630734 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:08:14.640244 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:08:14.648477 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:08:14.655866 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:08:14.667705 [debug] [MainThread]: Using postgres connection "master"
09:08:14.671046 [debug] [MainThread]: On master: BEGIN
09:08:14.672095 [debug] [MainThread]: Opening a new connection, currently in state init
09:08:14.771030 [debug] [MainThread]: SQL status: BEGIN in 0.1 seconds
09:08:14.772334 [debug] [MainThread]: Using postgres connection "master"
09:08:14.773340 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:08:15.840590 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
09:08:15.845758 [debug] [MainThread]: On master: ROLLBACK
09:08:15.852426 [debug] [MainThread]: Using postgres connection "master"
09:08:15.853425 [debug] [MainThread]: On master: BEGIN
09:08:15.861210 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:08:15.861210 [debug] [MainThread]: On master: COMMIT
09:08:15.862215 [debug] [MainThread]: Using postgres connection "master"
09:08:15.863207 [debug] [MainThread]: On master: COMMIT
09:08:15.867563 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:08:15.867798 [debug] [MainThread]: On master: Close
09:08:15.868897 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:08:15.869898 [info ] [MainThread]: 
09:08:15.879895 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:08:15.881907 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:08:15.887175 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:08:15.888902 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:08:15.889900 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:08:15.902910 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:08:15.904901 [debug] [Thread-1  ]: finished collecting timing info
09:08:15.906514 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:08:16.023619 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:16.024846 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp143816004158"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:08:16.024846 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:08:16.070255 [debug] [Thread-1  ]: SQL status: SELECT 5 in 0.05 seconds
09:08:16.082349 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:16.083571 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:08:16.087895 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
09:08:16.088897 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:16.088897 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp143816004158'
        
      order by ordinal_position

  
09:08:16.101566 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:08:16.109328 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:16.109328 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:08:16.118322 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:08:16.128209 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:16.129209 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:08:16.137483 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:08:16.148188 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:08:16.149187 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:16.149187 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp143816004158"
    )
  
09:08:16.156077 [debug] [Thread-1  ]: SQL status: INSERT 0 5 in 0.01 seconds
09:08:16.177316 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:08:16.178313 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:16.179318 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:08:16.185310 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
09:08:16.187311 [debug] [Thread-1  ]: finished collecting timing info
09:08:16.188327 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:08:16.189312 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42d947a9-d1d2-4767-b1cb-f1bba54b5d9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E475907A90>]}
09:08:16.190310 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 5[0m in 0.31s]
09:08:16.192310 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:08:16.194312 [debug] [MainThread]: Acquiring new postgres connection "master"
09:08:16.194312 [debug] [MainThread]: Using postgres connection "master"
09:08:16.195313 [debug] [MainThread]: On master: BEGIN
09:08:16.195313 [debug] [MainThread]: Opening a new connection, currently in state closed
09:08:16.271372 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
09:08:16.272377 [debug] [MainThread]: On master: COMMIT
09:08:16.272377 [debug] [MainThread]: Using postgres connection "master"
09:08:16.273096 [debug] [MainThread]: On master: COMMIT
09:08:16.277201 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:08:16.278194 [debug] [MainThread]: On master: Close
09:08:16.279093 [info ] [MainThread]: 
09:08:16.280096 [info ] [MainThread]: Finished running 1 incremental model in 1.82s.
09:08:16.282094 [debug] [MainThread]: Connection 'master' was properly closed.
09:08:16.282094 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:08:16.283095 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:08:16.284101 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:08:16.293105 [info ] [MainThread]: 
09:08:16.297106 [info ] [MainThread]: [32mCompleted successfully[0m
09:08:16.301097 [info ] [MainThread]: 
09:08:16.303561 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:08:16.307111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E4757E3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E47582CA00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E474073AF0>]}


============================== 2022-03-22 09:08:56.843215 | 09a7df9c-edca-4270-8aec-f29bc83224c4 ==============================
09:08:56.843215 [info ] [MainThread]: Running with dbt=1.0.3
09:08:56.858641 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:08:56.859669 [debug] [MainThread]: Tracking: tracking
09:08:56.888249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FED27C70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FED27FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FED278E0>]}
09:08:56.943284 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:08:56.943284 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:08:56.949283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '09a7df9c-edca-4270-8aec-f29bc83224c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FEE2C0D0>]}
09:08:56.955250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '09a7df9c-edca-4270-8aec-f29bc83224c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FEDAAB20>]}
09:08:56.955250 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:08:56.957883 [info ] [MainThread]: 
09:08:56.959249 [debug] [MainThread]: Acquiring new postgres connection "master"
09:08:56.961249 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:08:56.976800 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:08:56.977830 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:08:56.978798 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:08:57.050077 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.07 seconds
09:08:57.052640 [debug] [ThreadPool]: On list_recon-cortex: Close
09:08:57.055641 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:08:57.063795 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:08:57.063795 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:08:57.067941 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:08:57.134829 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
09:08:57.135827 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:08:57.136863 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:08:57.147908 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:08:57.150946 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:08:57.165423 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:08:57.174812 [debug] [MainThread]: Using postgres connection "master"
09:08:57.174812 [debug] [MainThread]: On master: BEGIN
09:08:57.181025 [debug] [MainThread]: Opening a new connection, currently in state init
09:08:57.262304 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
09:08:57.263300 [debug] [MainThread]: Using postgres connection "master"
09:08:57.264287 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:08:58.325095 [debug] [MainThread]: SQL status: SELECT 0 in 1.06 seconds
09:08:58.341434 [debug] [MainThread]: On master: ROLLBACK
09:08:58.348964 [debug] [MainThread]: Using postgres connection "master"
09:08:58.350703 [debug] [MainThread]: On master: BEGIN
09:08:58.362075 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:08:58.363111 [debug] [MainThread]: On master: COMMIT
09:08:58.364069 [debug] [MainThread]: Using postgres connection "master"
09:08:58.364069 [debug] [MainThread]: On master: COMMIT
09:08:58.371072 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
09:08:58.371072 [debug] [MainThread]: On master: Close
09:08:58.373069 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:08:58.374068 [info ] [MainThread]: 
09:08:58.385071 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:08:58.386070 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:08:58.390108 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.392161 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:08:58.393077 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:08:58.404113 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:08:58.405069 [debug] [Thread-1  ]: finished collecting timing info
09:08:58.405069 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:08:58.477068 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.478069 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp143858451071"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:08:58.479071 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:08:58.535570 [debug] [Thread-1  ]: SQL status: SELECT 5 in 0.06 seconds
09:08:58.542693 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.542693 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:08:58.549124 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
09:08:58.551122 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.551845 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp143858451071'
        
      order by ordinal_position

  
09:08:58.566900 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:08:58.585614 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.586612 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:08:58.596235 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:08:58.608397 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.608397 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:08:58.641096 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.03 seconds
09:08:58.656841 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:08:58.657848 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.658842 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp143858451071"
    )
  
09:08:58.666843 [debug] [Thread-1  ]: SQL status: INSERT 0 5 in 0.01 seconds
09:08:58.681890 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:08:58.681890 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:08:58.682844 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:08:58.688842 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
09:08:58.689846 [debug] [Thread-1  ]: finished collecting timing info
09:08:58.690851 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:08:58.693079 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09a7df9c-edca-4270-8aec-f29bc83224c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FEED85E0>]}
09:08:58.693842 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 5[0m in 0.31s]
09:08:58.694860 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:08:58.697860 [debug] [MainThread]: Acquiring new postgres connection "master"
09:08:58.697860 [debug] [MainThread]: Using postgres connection "master"
09:08:58.698842 [debug] [MainThread]: On master: BEGIN
09:08:58.698842 [debug] [MainThread]: Opening a new connection, currently in state closed
09:08:58.743303 [debug] [MainThread]: SQL status: BEGIN in 0.04 seconds
09:08:58.743725 [debug] [MainThread]: On master: COMMIT
09:08:58.743725 [debug] [MainThread]: Using postgres connection "master"
09:08:58.744729 [debug] [MainThread]: On master: COMMIT
09:08:58.748763 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:08:58.749995 [debug] [MainThread]: On master: Close
09:08:58.750724 [info ] [MainThread]: 
09:08:58.751419 [info ] [MainThread]: Finished running 1 incremental model in 1.79s.
09:08:58.751724 [debug] [MainThread]: Connection 'master' was properly closed.
09:08:58.752726 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:08:58.752726 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:08:58.752726 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:08:58.759477 [info ] [MainThread]: 
09:08:58.759727 [info ] [MainThread]: [32mCompleted successfully[0m
09:08:58.760726 [info ] [MainThread]: 
09:08:58.761819 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:08:58.763730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FEDAA5B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FEE47580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283FEEA0310>]}


============================== 2022-03-22 09:12:54.061796 | 71452c59-bee6-4edf-b1a1-9848ac67228c ==============================
09:12:54.061796 [info ] [MainThread]: Running with dbt=1.0.3
09:12:54.066296 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:12:54.067363 [debug] [MainThread]: Tracking: tracking
09:12:54.109510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D6E8520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D6E8FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D6E80D0>]}
09:12:54.205786 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:12:54.205786 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
09:12:54.236147 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
09:12:54.279271 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
09:12:54.305469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '71452c59-bee6-4edf-b1a1-9848ac67228c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D83C0D0>]}
09:12:54.325947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '71452c59-bee6-4edf-b1a1-9848ac67228c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D7779A0>]}
09:12:54.326950 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:12:54.330409 [info ] [MainThread]: 
09:12:54.333195 [debug] [MainThread]: Acquiring new postgres connection "master"
09:12:54.337195 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:12:54.371587 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:12:54.374198 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:12:54.376207 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:12:54.446198 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.07 seconds
09:12:54.449198 [debug] [ThreadPool]: On list_recon-cortex: Close
09:12:54.453194 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:12:54.457622 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:12:54.457622 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:12:54.468424 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:12:54.530265 [debug] [ThreadPool]: SQL status: BEGIN in 0.06 seconds
09:12:54.533671 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:12:54.534680 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:12:54.853279 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.32 seconds
09:12:54.854327 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:12:54.866971 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:12:54.876145 [debug] [MainThread]: Using postgres connection "master"
09:12:54.876145 [debug] [MainThread]: On master: BEGIN
09:12:54.892005 [debug] [MainThread]: Opening a new connection, currently in state init
09:12:54.967920 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
09:12:54.969635 [debug] [MainThread]: Using postgres connection "master"
09:12:54.970682 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:12:56.029961 [debug] [MainThread]: SQL status: SELECT 0 in 1.06 seconds
09:12:56.046956 [debug] [MainThread]: On master: ROLLBACK
09:12:56.050106 [debug] [MainThread]: Using postgres connection "master"
09:12:56.054228 [debug] [MainThread]: On master: BEGIN
09:12:56.065301 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:12:56.069043 [debug] [MainThread]: On master: COMMIT
09:12:56.070093 [debug] [MainThread]: Using postgres connection "master"
09:12:56.071049 [debug] [MainThread]: On master: COMMIT
09:12:56.073271 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:12:56.077942 [debug] [MainThread]: On master: Close
09:12:56.080158 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:12:56.083445 [info ] [MainThread]: 
09:12:56.096522 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:12:56.097527 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:12:56.102519 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.102519 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:12:56.103516 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:12:56.111518 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:12:56.112932 [debug] [Thread-1  ]: finished collecting timing info
09:12:56.113519 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:12:56.210462 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.210462 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp144256198520"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    CASE WHEN agreement_no is not null then 1
    ELSE
     1
    end as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:12:56.216546 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:12:56.273347 [debug] [Thread-1  ]: SQL status: SELECT 5 in 0.06 seconds
09:12:56.282206 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.282206 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:12:56.288206 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
09:12:56.289212 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.289212 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp144256198520'
        
      order by ordinal_position

  
09:12:56.304208 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:12:56.313209 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.314208 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:12:56.324253 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:12:56.331326 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.331326 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:12:56.349033 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:12:56.367800 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:12:56.369799 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.369799 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp144256198520"
    )
  
09:12:56.390753 [debug] [Thread-1  ]: SQL status: INSERT 0 5 in 0.02 seconds
09:12:56.399330 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:12:56.399330 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:12:56.400328 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:12:56.406768 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
09:12:56.408767 [debug] [Thread-1  ]: finished collecting timing info
09:12:56.409420 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:12:56.410416 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '71452c59-bee6-4edf-b1a1-9848ac67228c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D6E1280>]}
09:12:56.412445 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 5[0m in 0.31s]
09:12:56.414469 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:12:56.419470 [debug] [MainThread]: Acquiring new postgres connection "master"
09:12:56.420578 [debug] [MainThread]: Using postgres connection "master"
09:12:56.421447 [debug] [MainThread]: On master: BEGIN
09:12:56.422451 [debug] [MainThread]: Opening a new connection, currently in state closed
09:12:56.483461 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
09:12:56.485458 [debug] [MainThread]: On master: COMMIT
09:12:56.487449 [debug] [MainThread]: Using postgres connection "master"
09:12:56.487449 [debug] [MainThread]: On master: COMMIT
09:12:56.492446 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:12:56.493447 [debug] [MainThread]: On master: Close
09:12:56.495448 [info ] [MainThread]: 
09:12:56.497449 [info ] [MainThread]: Finished running 1 incremental model in 2.16s.
09:12:56.499451 [debug] [MainThread]: Connection 'master' was properly closed.
09:12:56.500478 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:12:56.502518 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:12:56.504476 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:12:56.515446 [info ] [MainThread]: 
09:12:56.518488 [info ] [MainThread]: [32mCompleted successfully[0m
09:12:56.522450 [info ] [MainThread]: 
09:12:56.524449 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:12:56.526451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D8A2A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D7BCEE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001712D6E9D90>]}


============================== 2022-03-22 09:13:32.217543 | e46e367e-6e09-4dae-b52b-0b7e6ba9e79b ==============================
09:13:32.217543 [info ] [MainThread]: Running with dbt=1.0.3
09:13:32.218956 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:13:32.218956 [debug] [MainThread]: Tracking: tracking
09:13:32.248752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4497784C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C449778FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4497780D0>]}
09:13:32.415969 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:13:32.415969 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
09:13:32.426220 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
09:13:32.440935 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
09:13:32.457856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e46e367e-6e09-4dae-b52b-0b7e6ba9e79b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4498CA0D0>]}
09:13:32.464569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e46e367e-6e09-4dae-b52b-0b7e6ba9e79b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C449803A30>]}
09:13:32.465568 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:13:32.467545 [info ] [MainThread]: 
09:13:32.468813 [debug] [MainThread]: Acquiring new postgres connection "master"
09:13:32.470806 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:13:32.485833 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:13:32.486881 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:13:32.486881 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:13:32.551727 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.06 seconds
09:13:32.552694 [debug] [ThreadPool]: On list_recon-cortex: Close
09:13:32.554693 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:13:32.560696 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:13:32.561696 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:13:32.562322 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:13:32.653446 [debug] [ThreadPool]: SQL status: BEGIN in 0.09 seconds
09:13:32.653446 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:13:32.654447 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:13:32.667405 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:13:32.669701 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:13:32.675694 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:13:32.685380 [debug] [MainThread]: Using postgres connection "master"
09:13:32.687611 [debug] [MainThread]: On master: BEGIN
09:13:32.688610 [debug] [MainThread]: Opening a new connection, currently in state init
09:13:32.773308 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
09:13:32.774904 [debug] [MainThread]: Using postgres connection "master"
09:13:32.776664 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:13:33.847588 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
09:13:33.851920 [debug] [MainThread]: On master: ROLLBACK
09:13:33.856451 [debug] [MainThread]: Using postgres connection "master"
09:13:33.857448 [debug] [MainThread]: On master: BEGIN
09:13:33.866683 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:13:33.867200 [debug] [MainThread]: On master: COMMIT
09:13:33.867200 [debug] [MainThread]: Using postgres connection "master"
09:13:33.867200 [debug] [MainThread]: On master: COMMIT
09:13:33.875351 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
09:13:33.876348 [debug] [MainThread]: On master: Close
09:13:33.877857 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:13:33.878388 [info ] [MainThread]: 
09:13:33.889403 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:13:33.890402 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:13:33.894844 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:13:33.895461 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:13:33.896626 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:13:33.912425 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:13:33.913390 [debug] [Thread-1  ]: finished collecting timing info
09:13:33.914391 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:13:34.034359 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:13:34.035704 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp144334013718"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.* from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    CASE WHEN agreement_no is not null then 1
    ELSE
     0
    end as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    1 as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:13:34.035704 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:13:34.091566 [debug] [Thread-1  ]: SQL status: SELECT 5 in 0.06 seconds
09:13:34.103320 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:13:34.104321 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:13:34.108687 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
09:13:34.109687 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:13:34.109687 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp144334013718'
        
      order by ordinal_position

  
09:13:34.122739 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:13:34.130848 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:13:34.131816 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:13:34.140775 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:13:34.149951 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:13:34.149951 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:13:34.158807 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:13:34.170807 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:13:34.171352 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:13:34.171817 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp144334013718"
    )
  
09:13:34.180788 [debug] [Thread-1  ]: SQL status: INSERT 0 5 in 0.01 seconds
09:13:34.187816 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:13:34.187816 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:13:34.188625 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:13:34.195481 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
09:13:34.196492 [debug] [Thread-1  ]: finished collecting timing info
09:13:34.197306 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:13:34.198250 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e46e367e-6e09-4dae-b52b-0b7e6ba9e79b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C449928EE0>]}
09:13:34.198250 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 5[0m in 0.30s]
09:13:34.200776 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:13:34.202250 [debug] [MainThread]: Acquiring new postgres connection "master"
09:13:34.202250 [debug] [MainThread]: Using postgres connection "master"
09:13:34.203435 [debug] [MainThread]: On master: BEGIN
09:13:34.203435 [debug] [MainThread]: Opening a new connection, currently in state closed
09:13:34.267072 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
09:13:34.268075 [debug] [MainThread]: On master: COMMIT
09:13:34.268075 [debug] [MainThread]: Using postgres connection "master"
09:13:34.268075 [debug] [MainThread]: On master: COMMIT
09:13:34.274967 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
09:13:34.274967 [debug] [MainThread]: On master: Close
09:13:34.275920 [info ] [MainThread]: 
09:13:34.277201 [info ] [MainThread]: Finished running 1 incremental model in 1.81s.
09:13:34.277877 [debug] [MainThread]: Connection 'master' was properly closed.
09:13:34.277877 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:13:34.277877 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:13:34.278876 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:13:34.284877 [info ] [MainThread]: 
09:13:34.285880 [info ] [MainThread]: [32mCompleted successfully[0m
09:13:34.287879 [info ] [MainThread]: 
09:13:34.289900 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:13:34.294882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C449932A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C44992AAC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4486B81F0>]}


============================== 2022-03-22 09:18:01.497095 | 207d5547-71f4-4d22-b2c4-d4eacbd7c573 ==============================
09:18:01.497095 [info ] [MainThread]: Running with dbt=1.0.3
09:18:01.507772 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:18:01.507772 [debug] [MainThread]: Tracking: tracking
09:18:01.541777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C305F384C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C305F38FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C305F380D0>]}
09:18:01.599926 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:18:01.601813 [debug] [MainThread]: Partial parsing: updated file: dataset2://models\dataset2\tb_txn_recon_data.sql
09:18:01.603847 [debug] [MainThread]: 1603: static parser failed on dataset2\tb_txn_recon_data.sql
09:18:01.630810 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dataset2\tb_txn_recon_data.sql
09:18:01.645498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '207d5547-71f4-4d22-b2c4-d4eacbd7c573', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C30608A0D0>]}
09:18:01.651886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '207d5547-71f4-4d22-b2c4-d4eacbd7c573', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C305FC3A30>]}
09:18:01.651886 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:18:01.654582 [info ] [MainThread]: 
09:18:01.655245 [debug] [MainThread]: Acquiring new postgres connection "master"
09:18:01.657236 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:18:01.673281 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:18:01.673281 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:18:01.674229 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:18:01.761265 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.09 seconds
09:18:01.764286 [debug] [ThreadPool]: On list_recon-cortex: Close
09:18:01.766286 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:18:01.774442 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:18:01.774442 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:18:01.778321 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:18:01.852094 [debug] [ThreadPool]: SQL status: BEGIN in 0.07 seconds
09:18:01.854103 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:18:01.855610 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:18:01.865071 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:18:01.868077 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:18:01.879686 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:18:01.889200 [debug] [MainThread]: Using postgres connection "master"
09:18:01.898745 [debug] [MainThread]: On master: BEGIN
09:18:01.898745 [debug] [MainThread]: Opening a new connection, currently in state init
09:18:01.985770 [debug] [MainThread]: SQL status: BEGIN in 0.09 seconds
09:18:01.987277 [debug] [MainThread]: Using postgres connection "master"
09:18:01.988768 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:18:03.084644 [debug] [MainThread]: SQL status: SELECT 0 in 1.09 seconds
09:18:03.091090 [debug] [MainThread]: On master: ROLLBACK
09:18:03.096396 [debug] [MainThread]: Using postgres connection "master"
09:18:03.099382 [debug] [MainThread]: On master: BEGIN
09:18:03.108672 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:18:03.109679 [debug] [MainThread]: On master: COMMIT
09:18:03.110554 [debug] [MainThread]: Using postgres connection "master"
09:18:03.110554 [debug] [MainThread]: On master: COMMIT
09:18:03.111575 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:18:03.116196 [debug] [MainThread]: On master: Close
09:18:03.117195 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:18:03.117640 [info ] [MainThread]: 
09:18:03.128640 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:18:03.129642 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:18:03.132684 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.133648 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:18:03.135642 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:18:03.145641 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:18:03.148649 [debug] [Thread-1  ]: finished collecting timing info
09:18:03.150639 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:18:03.272338 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.273339 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp144803251276"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.*, fds1.rtgs_utr_no as rtgs_utr_no from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    CASE WHEN agreement_no is not null then 1
    ELSE
     0
    end as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    CASE WHEN rtgs_utr_no is not null then 1
    ELSE
     0
    END as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:18:03.273339 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:18:03.328053 [debug] [Thread-1  ]: SQL status: SELECT 5 in 0.05 seconds
09:18:03.340041 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.340041 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:18:03.346579 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
09:18:03.347550 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.347550 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp144803251276'
        
      order by ordinal_position

  
09:18:03.360655 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:18:03.368459 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.369468 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:18:03.377834 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:18:03.379836 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.379836 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:18:03.705438 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.32 seconds
09:18:03.739892 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:18:03.741807 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.742713 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp144803251276"
    )
  
09:18:03.749224 [debug] [Thread-1  ]: SQL status: INSERT 0 5 in 0.01 seconds
09:18:03.751221 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:18:03.751221 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:03.759672 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:18:03.764981 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
09:18:03.766020 [debug] [Thread-1  ]: finished collecting timing info
09:18:03.766605 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:18:03.766605 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '207d5547-71f4-4d22-b2c4-d4eacbd7c573', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C3060E8EE0>]}
09:18:03.767634 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 5[0m in 0.63s]
09:18:03.768695 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:18:03.770700 [debug] [MainThread]: Acquiring new postgres connection "master"
09:18:03.771732 [debug] [MainThread]: Using postgres connection "master"
09:18:03.772073 [debug] [MainThread]: On master: BEGIN
09:18:03.772251 [debug] [MainThread]: Opening a new connection, currently in state closed
09:18:03.816335 [debug] [MainThread]: SQL status: BEGIN in 0.04 seconds
09:18:03.817710 [debug] [MainThread]: On master: COMMIT
09:18:03.817710 [debug] [MainThread]: Using postgres connection "master"
09:18:03.818366 [debug] [MainThread]: On master: COMMIT
09:18:03.822874 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:18:03.823568 [debug] [MainThread]: On master: Close
09:18:03.823884 [info ] [MainThread]: 
09:18:03.825117 [info ] [MainThread]: Finished running 1 incremental model in 2.17s.
09:18:03.825889 [debug] [MainThread]: Connection 'master' was properly closed.
09:18:03.825889 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:18:03.826884 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:18:03.826884 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:18:03.835921 [info ] [MainThread]: 
09:18:03.836891 [info ] [MainThread]: [32mCompleted successfully[0m
09:18:03.840046 [info ] [MainThread]: 
09:18:03.841894 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:18:03.842887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C305FC3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C30600CD60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C304B1C0D0>]}


============================== 2022-03-22 09:18:16.455305 | c58e0b34-4c3f-4459-b37a-6656d464d350 ==============================
09:18:16.455305 [info ] [MainThread]: Running with dbt=1.0.3
09:18:16.456305 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:18:16.456378 [debug] [MainThread]: Tracking: tracking
09:18:16.480115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029355BC91C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029355BC9220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029355BC9490>]}
09:18:16.542043 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:18:16.543034 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:18:16.549044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c58e0b34-4c3f-4459-b37a-6656d464d350', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029356D8C0D0>]}
09:18:16.554320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c58e0b34-4c3f-4459-b37a-6656d464d350', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029356D13AF0>]}
09:18:16.554320 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:18:16.556006 [info ] [MainThread]: 
09:18:16.557006 [debug] [MainThread]: Acquiring new postgres connection "master"
09:18:16.559006 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:18:16.573027 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:18:16.573027 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:18:16.573027 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:18:16.628416 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.06 seconds
09:18:16.631523 [debug] [ThreadPool]: On list_recon-cortex: Close
09:18:16.635443 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:18:16.644403 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:18:16.645920 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:18:16.645920 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:18:16.754198 [debug] [ThreadPool]: SQL status: BEGIN in 0.11 seconds
09:18:16.755596 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:18:16.756598 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:18:16.766232 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:18:16.768635 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:18:16.786535 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:18:16.804522 [debug] [MainThread]: Using postgres connection "master"
09:18:16.805274 [debug] [MainThread]: On master: BEGIN
09:18:16.805523 [debug] [MainThread]: Opening a new connection, currently in state init
09:18:16.869169 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
09:18:16.871394 [debug] [MainThread]: Using postgres connection "master"
09:18:16.872565 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:18:17.946934 [debug] [MainThread]: SQL status: SELECT 0 in 1.07 seconds
09:18:17.954041 [debug] [MainThread]: On master: ROLLBACK
09:18:17.959289 [debug] [MainThread]: Using postgres connection "master"
09:18:17.960086 [debug] [MainThread]: On master: BEGIN
09:18:17.970680 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:18:17.971685 [debug] [MainThread]: On master: COMMIT
09:18:17.971685 [debug] [MainThread]: Using postgres connection "master"
09:18:17.972683 [debug] [MainThread]: On master: COMMIT
09:18:17.976313 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:18:17.977319 [debug] [MainThread]: On master: Close
09:18:17.978384 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:18:17.980224 [info ] [MainThread]: 
09:18:17.990255 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:18:17.991224 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:18:17.994245 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:18:17.996268 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:18:17.998234 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:18:18.014708 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:18:18.015223 [debug] [Thread-1  ]: finished collecting timing info
09:18:18.016220 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:18:18.092222 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:18.092222 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp144818070220"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.*, fds1.rtgs_utr_no as rtgs_utr_no from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    CASE WHEN agreement_no is not null then 1
    ELSE
     0
    end as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    CASE WHEN rtgs_utr_no is not null then 1
    ELSE
     0
    END as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:18:18.093245 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:18:18.148022 [debug] [Thread-1  ]: SQL status: SELECT 5 in 0.05 seconds
09:18:18.161053 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:18.161053 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:18:18.166665 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
09:18:18.167021 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:18.168021 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp144818070220'
        
      order by ordinal_position

  
09:18:18.179194 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:18:18.189316 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:18.189316 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:18:18.199387 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:18:18.211394 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:18.211394 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:18:18.239252 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.03 seconds
09:18:18.249494 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:18:18.250123 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:18.250123 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp144818070220"
    )
  
09:18:18.256083 [debug] [Thread-1  ]: SQL status: INSERT 0 5 in 0.01 seconds
09:18:18.263218 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:18:18.264237 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:18:18.264237 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:18:18.272602 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
09:18:18.273844 [debug] [Thread-1  ]: finished collecting timing info
09:18:18.274601 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:18:18.275591 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c58e0b34-4c3f-4459-b37a-6656d464d350', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029356E4E130>]}
09:18:18.276591 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 5[0m in 0.28s]
09:18:18.278610 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:18:18.280590 [debug] [MainThread]: Acquiring new postgres connection "master"
09:18:18.281591 [debug] [MainThread]: Using postgres connection "master"
09:18:18.281591 [debug] [MainThread]: On master: BEGIN
09:18:18.281591 [debug] [MainThread]: Opening a new connection, currently in state closed
09:18:18.346100 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
09:18:18.347047 [debug] [MainThread]: On master: COMMIT
09:18:18.347047 [debug] [MainThread]: Using postgres connection "master"
09:18:18.348048 [debug] [MainThread]: On master: COMMIT
09:18:18.351796 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:18:18.351796 [debug] [MainThread]: On master: Close
09:18:18.352599 [info ] [MainThread]: 
09:18:18.353574 [info ] [MainThread]: Finished running 1 incremental model in 1.80s.
09:18:18.354574 [debug] [MainThread]: Connection 'master' was properly closed.
09:18:18.354574 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:18:18.354574 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:18:18.355573 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:18:18.361576 [info ] [MainThread]: 
09:18:18.362575 [info ] [MainThread]: [32mCompleted successfully[0m
09:18:18.364581 [info ] [MainThread]: 
09:18:18.365577 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:18:18.367574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029356E384F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029356DA7250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029356E00A60>]}


============================== 2022-03-22 09:27:30.435870 | 9350ce1f-2a70-4433-8960-847362019676 ==============================
09:27:30.435870 [info ] [MainThread]: Running with dbt=1.0.3
09:27:30.447743 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:27:30.447743 [debug] [MainThread]: Tracking: tracking
09:27:30.483803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E708AD8B80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E708AD82E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E708AD8310>]}
09:27:30.634033 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:27:30.640790 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:27:30.642823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9350ce1f-2a70-4433-8960-847362019676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E708CCC0D0>]}
09:27:30.650547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9350ce1f-2a70-4433-8960-847362019676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E708C5AAC0>]}
09:27:30.651547 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:27:30.653677 [info ] [MainThread]: 
09:27:30.655151 [debug] [MainThread]: Acquiring new postgres connection "master"
09:27:30.656549 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:27:30.672545 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:27:30.673547 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:27:30.673547 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:27:30.753014 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.08 seconds
09:27:30.754756 [debug] [ThreadPool]: On list_recon-cortex: Close
09:27:30.756728 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:27:30.764723 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:27:30.765647 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:27:30.765721 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:27:30.842712 [debug] [ThreadPool]: SQL status: BEGIN in 0.08 seconds
09:27:30.843415 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:27:30.845242 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:27:30.854439 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.01 seconds
09:27:30.861487 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:27:30.870264 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:27:30.881303 [debug] [MainThread]: Using postgres connection "master"
09:27:30.881303 [debug] [MainThread]: On master: BEGIN
09:27:30.885442 [debug] [MainThread]: Opening a new connection, currently in state init
09:27:31.316920 [debug] [MainThread]: SQL status: BEGIN in 0.43 seconds
09:27:31.318905 [debug] [MainThread]: Using postgres connection "master"
09:27:31.320585 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:27:32.280923 [debug] [MainThread]: SQL status: SELECT 0 in 0.96 seconds
09:27:32.284326 [debug] [MainThread]: On master: ROLLBACK
09:27:32.313261 [debug] [MainThread]: Using postgres connection "master"
09:27:32.314340 [debug] [MainThread]: On master: BEGIN
09:27:32.323745 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:27:32.323745 [debug] [MainThread]: On master: COMMIT
09:27:32.324790 [debug] [MainThread]: Using postgres connection "master"
09:27:32.324790 [debug] [MainThread]: On master: COMMIT
09:27:32.353485 [debug] [MainThread]: SQL status: COMMIT in 0.03 seconds
09:27:32.354130 [debug] [MainThread]: On master: Close
09:27:32.354496 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:27:32.355496 [info ] [MainThread]: 
09:27:32.365502 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:27:32.368840 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:27:32.371616 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.371616 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:27:32.372496 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:27:32.383500 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:27:32.387510 [debug] [Thread-1  ]: finished collecting timing info
09:27:32.388502 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:27:32.463495 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.464506 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp145732440531"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.*, fds1.rtgs_utr_no as rtgs_utr_no from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    CASE WHEN agreement_no is not null then 1
    ELSE
     0
    end as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    CASE WHEN rtgs_utr_no is not null then 1
    ELSE
     0
    END as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:27:32.464506 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:27:32.514454 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.05 seconds
09:27:32.524063 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.525065 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:27:32.533736 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
09:27:32.534742 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.534742 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp145732440531'
        
      order by ordinal_position

  
09:27:32.546340 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:27:32.554621 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.554621 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:27:32.564286 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:27:32.577480 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.578468 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:27:32.589312 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:27:32.609122 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:27:32.611123 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.612124 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp145732440531"
    )
  
09:27:32.617575 [debug] [Thread-1  ]: SQL status: INSERT 0 2 in 0.01 seconds
09:27:32.626908 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:27:32.628046 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:27:32.628046 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:27:32.635792 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
09:27:32.635792 [debug] [Thread-1  ]: finished collecting timing info
09:27:32.636899 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:27:32.637901 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9350ce1f-2a70-4433-8960-847362019676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E709D5D370>]}
09:27:32.638901 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 2[0m in 0.27s]
09:27:32.639178 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:27:32.641264 [debug] [MainThread]: Acquiring new postgres connection "master"
09:27:32.641264 [debug] [MainThread]: Using postgres connection "master"
09:27:32.642263 [debug] [MainThread]: On master: BEGIN
09:27:32.642715 [debug] [MainThread]: Opening a new connection, currently in state closed
09:27:32.686417 [debug] [MainThread]: SQL status: BEGIN in 0.04 seconds
09:27:32.687373 [debug] [MainThread]: On master: COMMIT
09:27:32.689266 [debug] [MainThread]: Using postgres connection "master"
09:27:32.690265 [debug] [MainThread]: On master: COMMIT
09:27:32.695504 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:27:32.695504 [debug] [MainThread]: On master: Close
09:27:32.696263 [info ] [MainThread]: 
09:27:32.697262 [info ] [MainThread]: Finished running 1 incremental model in 2.04s.
09:27:32.698263 [debug] [MainThread]: Connection 'master' was properly closed.
09:27:32.698263 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:27:32.699262 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:27:32.699262 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:27:32.708266 [info ] [MainThread]: 
09:27:32.709267 [info ] [MainThread]: [32mCompleted successfully[0m
09:27:32.711263 [info ] [MainThread]: 
09:27:32.712289 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:27:32.713264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E709D48550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E709CB7220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E709D0F250>]}


============================== 2022-03-22 09:28:07.828095 | d2686654-fdae-4efd-a80d-1df3130b05ed ==============================
09:28:07.828095 [info ] [MainThread]: Running with dbt=1.0.3
09:28:07.836407 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='C:\\Users\\Rajendra\\.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tb_txn_recon_data'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:28:07.836407 [debug] [MainThread]: Tracking: tracking
09:28:08.565370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAAE7B20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAAE7FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAAE70D0>]}
09:28:08.600581 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:28:08.616172 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:28:08.619561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd2686654-fdae-4efd-a80d-1df3130b05ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BABEB0D0>]}
09:28:08.627244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd2686654-fdae-4efd-a80d-1df3130b05ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAB73B20>]}
09:28:08.627244 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 165 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:28:08.630243 [info ] [MainThread]: 
09:28:08.631521 [debug] [MainThread]: Acquiring new postgres connection "master"
09:28:08.633712 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex"
09:28:08.638810 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex"
09:28:08.638810 [debug] [ThreadPool]: On list_recon-cortex: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex"} */

    select distinct nspname from pg_namespace
  
09:28:08.644479 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:28:08.719540 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.08 seconds
09:28:08.722536 [debug] [ThreadPool]: On list_recon-cortex: Close
09:28:08.723535 [debug] [ThreadPool]: Acquiring new postgres connection "list_recon-cortex_public"
09:28:08.730655 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:28:08.731550 [debug] [ThreadPool]: On list_recon-cortex_public: BEGIN
09:28:08.731550 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:28:08.829505 [debug] [ThreadPool]: SQL status: BEGIN in 0.1 seconds
09:28:08.830989 [debug] [ThreadPool]: Using postgres connection "list_recon-cortex_public"
09:28:08.831984 [debug] [ThreadPool]: On list_recon-cortex_public: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "list_recon-cortex_public"} */
select
      'recon-cortex' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'recon-cortex' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
09:28:08.851330 [debug] [ThreadPool]: SQL status: SELECT 56 in 0.02 seconds
09:28:08.854474 [debug] [ThreadPool]: On list_recon-cortex_public: ROLLBACK
09:28:08.864179 [debug] [ThreadPool]: On list_recon-cortex_public: Close
09:28:08.875437 [debug] [MainThread]: Using postgres connection "master"
09:28:08.875437 [debug] [MainThread]: On master: BEGIN
09:28:08.881362 [debug] [MainThread]: Opening a new connection, currently in state init
09:28:08.956862 [debug] [MainThread]: SQL status: BEGIN in 0.08 seconds
09:28:08.960922 [debug] [MainThread]: Using postgres connection "master"
09:28:08.962411 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
09:28:09.880524 [debug] [MainThread]: SQL status: SELECT 0 in 0.92 seconds
09:28:09.884127 [debug] [MainThread]: On master: ROLLBACK
09:28:09.891692 [debug] [MainThread]: Using postgres connection "master"
09:28:09.899080 [debug] [MainThread]: On master: BEGIN
09:28:09.911128 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
09:28:09.912178 [debug] [MainThread]: On master: COMMIT
09:28:09.913750 [debug] [MainThread]: Using postgres connection "master"
09:28:09.914798 [debug] [MainThread]: On master: COMMIT
09:28:09.918788 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
09:28:09.922876 [debug] [MainThread]: On master: Close
09:28:09.925112 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
09:28:09.928943 [info ] [MainThread]: 
09:28:09.950088 [debug] [Thread-1  ]: Began running node model.dataset2.tb_txn_recon_data
09:28:09.953089 [info ] [Thread-1  ]: 1 of 1 START incremental model public.tb_txn_recon_data......................... [RUN]
09:28:09.958086 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dataset2.tb_txn_recon_data"
09:28:09.960099 [debug] [Thread-1  ]: Began compiling node model.dataset2.tb_txn_recon_data
09:28:09.961082 [debug] [Thread-1  ]: Compiling model.dataset2.tb_txn_recon_data
09:28:09.977080 [debug] [Thread-1  ]: Writing injected SQL for node "model.dataset2.tb_txn_recon_data"
09:28:09.978079 [debug] [Thread-1  ]: finished collecting timing info
09:28:09.978079 [debug] [Thread-1  ]: Began executing node model.dataset2.tb_txn_recon_data
09:28:10.043332 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:28:10.044082 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

    

  create temporary table "tb_txn_recon_data__dbt_tmp145810022122"
  as (
    


with filter_data_source_1 as (

    select s.*, right(s.txt_txn_desc,22) as rtgs_utr_no from set2_hdfc_auto s 

),
filter_data_source_2 as (
    select s.* from set2_los_rtgs_report s
),
filter_matched_data_source_1 as (
    select fds1.*, fds2.app_id_c as agreement_no from filter_data_source_1 fds1 left outer join filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
    and fds1.cod_drcr = 'D' and fds1.txt_txn_desc like 'RTGS%'
),
filter_matched_data_source_2 as (
    select fds2.*, fds1.rtgs_utr_no as rtgs_utr_no from filter_data_source_1 fds1 right outer join  filter_data_source_2 fds2
     on fds1.amt_txn = fds2.disb_amount_n
     and fds1.rtgs_utr_no = fds2.utr
)

select
    223 as recon_unit_id,
    amt_txn::text as column1,
    dat_txn as column2,
    dat_value as column3,
    ref_chq_no as column4,
    cod_acct_no as column5,
    cod_auth_id as column6,
    amt_od_limit as column7,
    txt_txn_desc as column8,
    bal_available as column9,
    cod_cc_brn_txn as column10,
    cod_txn_literal as column11,
    cod_txn_mnemonic as column12,
    rtgs_utr_no as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    1 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    agreement_no as recon_link_id,
    CASE WHEN agreement_no is not null then 1
    ELSE
     0
    end as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_1
union all
select
    223 as recon_unit_id,
    utr as column1,
    app_id_c as column2,
    las_edit_d as column3,
    disb_amount_n as column4,
    disb_msg_gen_date as column5,
    null as column6,
    null as column7,
    null as column8,
    null as column9,
    null as column10,
    null as column11,
    null as column12,
    null as column13,
    null as column14,
    null as column15,
    null as column16,
    null as column17,
    null as column18,
    null as column19,
    null as column20,
    null as column21,
    null as column22,
    null as column23,
    null as column24,
    null as column25,
    null as column26,
    null as column27,
    null as column28,
    null as column29,
    null as column30,
    99 as created_by,
    now() as created_date,
    2 as data_src_config_id,
    false as is_deleted,
    'O' as oc_status,
    app_id_c as recon_link_id,
    CASE WHEN rtgs_utr_no is not null then 1
    ELSE
     0
    END as recon_status_id,
    null as recon_notes,
    0 as updated_by,
    now() as updated_date,
    false as case_open,
    null as case_status,
    nextval('raw_data_id_seq') as raw_data_id
from filter_matched_data_source_2



  -- this filter will only be applied on an incremental run
  --where event_time > (select max(event_time) from "recon-cortex"."public"."tb_txn_recon_data")


  );
  
09:28:10.044082 [debug] [Thread-1  ]: Opening a new connection, currently in state init
09:28:11.121214 [debug] [Thread-1  ]: SQL status: SELECT 2 in 1.08 seconds
09:28:11.136065 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:28:11.136065 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: BEGIN
09:28:11.153735 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
09:28:11.154833 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:28:11.154833 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data__dbt_tmp145810022122'
        
      order by ordinal_position

  
09:28:11.166625 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.01 seconds
09:28:11.173806 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:28:11.173806 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:28:11.490757 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.31 seconds
09:28:11.496528 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:28:11.496528 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "recon-cortex".INFORMATION_SCHEMA.columns
      where table_name = 'tb_txn_recon_data'
        
        and table_schema = 'public'
        
      order by ordinal_position

  
09:28:11.519328 [debug] [Thread-1  ]: SQL status: SELECT 44 in 0.0 seconds
09:28:11.521331 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dataset2.tb_txn_recon_data"
09:28:11.535977 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:28:11.536977 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: /* {"app": "dbt", "dbt_version": "1.0.3", "profile_name": "dataset2", "target_name": "dev", "node_id": "model.dataset2.tb_txn_recon_data"} */

      

    insert into "recon-cortex"."public"."tb_txn_recon_data" ("raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status")
    (
        select "raw_data_id", "case_open", "column1", "column10", "column11", "column12", "column13", "column14", "column15", "column16", "column17", "column18", "column19", "column2", "column20", "column21", "column22", "column23", "column24", "column25", "column26", "column27", "column28", "column29", "column3", "column30", "column4", "column5", "column6", "column7", "column8", "column9", "created_by", "created_date", "data_src_config_id", "is_deleted", "recon_link_id", "recon_notes", "recon_status_id", "updated_by", "updated_date", "recon_unit_id", "oc_status", "case_status"
        from "tb_txn_recon_data__dbt_tmp145810022122"
    )
  
09:28:11.542525 [debug] [Thread-1  ]: SQL status: INSERT 0 2 in 0.01 seconds
09:28:11.546491 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:28:11.546491 [debug] [Thread-1  ]: Using postgres connection "model.dataset2.tb_txn_recon_data"
09:28:11.552827 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: COMMIT
09:28:11.555089 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
09:28:11.561919 [debug] [Thread-1  ]: finished collecting timing info
09:28:11.563002 [debug] [Thread-1  ]: On model.dataset2.tb_txn_recon_data: Close
09:28:11.564040 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2686654-fdae-4efd-a80d-1df3130b05ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAC985E0>]}
09:28:11.564040 [info ] [Thread-1  ]: 1 of 1 OK created incremental model public.tb_txn_recon_data.................... [[32mINSERT 0 2[0m in 1.61s]
09:28:11.566000 [debug] [Thread-1  ]: Finished running node model.dataset2.tb_txn_recon_data
09:28:11.569003 [debug] [MainThread]: Acquiring new postgres connection "master"
09:28:11.569609 [debug] [MainThread]: Using postgres connection "master"
09:28:11.570002 [debug] [MainThread]: On master: BEGIN
09:28:11.570002 [debug] [MainThread]: Opening a new connection, currently in state closed
09:28:11.616590 [debug] [MainThread]: SQL status: BEGIN in 0.05 seconds
09:28:11.618092 [debug] [MainThread]: On master: COMMIT
09:28:11.618571 [debug] [MainThread]: Using postgres connection "master"
09:28:11.618571 [debug] [MainThread]: On master: COMMIT
09:28:11.624812 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
09:28:11.625830 [debug] [MainThread]: On master: Close
09:28:11.626828 [info ] [MainThread]: 
09:28:11.626828 [info ] [MainThread]: Finished running 1 incremental model in 3.00s.
09:28:11.630831 [debug] [MainThread]: Connection 'master' was properly closed.
09:28:11.631832 [debug] [MainThread]: Connection 'list_recon-cortex' was properly closed.
09:28:11.632835 [debug] [MainThread]: Connection 'list_recon-cortex_public' was properly closed.
09:28:11.633927 [debug] [MainThread]: Connection 'model.dataset2.tb_txn_recon_data' was properly closed.
09:28:11.640829 [info ] [MainThread]: 
09:28:11.642262 [info ] [MainThread]: [32mCompleted successfully[0m
09:28:11.643851 [info ] [MainThread]: 
09:28:11.644852 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:28:11.648828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAB735B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAC07580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273BAC5FC70>]}
